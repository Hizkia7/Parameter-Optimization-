{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_linear(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_relu(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_sigmoid(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_tanh(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 429us/step - loss: 15223.4480 - val_loss: 14503.5150\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12169.4578 - val_loss: 8452.9648\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4186.6585 - val_loss: 685.0840\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 135.6061 - val_loss: 47.2485\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 30.1869 - val_loss: 27.3136\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.8413 - val_loss: 26.3549\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3814 - val_loss: 26.6426\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1531 - val_loss: 26.6232\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0292 - val_loss: 26.6671\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9139 - val_loss: 26.6265\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.7635 - val_loss: 26.5814\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7873 - val_loss: 26.4683\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6890 - val_loss: 26.5494\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6911 - val_loss: 26.4282\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6433 - val_loss: 26.5068\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7090 - val_loss: 26.0506\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1082 - val_loss: 26.4283\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.7842 - val_loss: 26.6112\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7561 - val_loss: 26.5721\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.6601 - val_loss: 26.4887\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.5493 - val_loss: 26.7851\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 21.7662 - val_loss: 26.5560\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7578 - val_loss: 26.2065\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7322 - val_loss: 25.8590\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.5339 - val_loss: 26.3301\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.5354 - val_loss: 26.0652\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.5675 - val_loss: 27.1062\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7692 - val_loss: 25.8618\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.4613 - val_loss: 25.9177\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.5881 - val_loss: 26.4398\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.5802 - val_loss: 26.1741\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9483 - val_loss: 26.2632\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8814 - val_loss: 25.6372\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.4613 - val_loss: 25.9049\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7054 - val_loss: 25.7571\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5343 - val_loss: 26.4078\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.7228 - val_loss: 25.6666\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.4810 - val_loss: 25.9191\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.4637 - val_loss: 25.5815\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7955 - val_loss: 26.2058\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8477 - val_loss: 25.6566\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8769 - val_loss: 25.6637\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.4073 - val_loss: 26.0266\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5693 - val_loss: 26.3064\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6512 - val_loss: 26.1297\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.7232 - val_loss: 26.1543\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8199 - val_loss: 26.2570\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8219 - val_loss: 25.7084\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.5421 - val_loss: 25.6593\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.6847 - val_loss: 25.8442\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8034 - val_loss: 25.5140\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.4533 - val_loss: 26.0218\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.5490 - val_loss: 25.9775\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.5464 - val_loss: 25.9158\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1051 - val_loss: 25.5634\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8639 - val_loss: 26.2819\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.4253 - val_loss: 26.3256\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.5950 - val_loss: 25.7499\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7454 - val_loss: 26.3044\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8316 - val_loss: 25.7172\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0188 - val_loss: 25.4387\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 21.6951 - val_loss: 25.5545\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6311 - val_loss: 25.7347\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7792 - val_loss: 25.5992\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9651 - val_loss: 25.3850\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8116 - val_loss: 29.3978\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1934 - val_loss: 25.6305\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8690 - val_loss: 26.2343\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7796 - val_loss: 25.5725\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8667 - val_loss: 25.8748\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0244 - val_loss: 25.8892\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8208 - val_loss: 25.7035\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0221 - val_loss: 25.4590\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.4622 - val_loss: 26.5261\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7974 - val_loss: 26.7182\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8006 - val_loss: 25.5259\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9699 - val_loss: 25.9815\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7592 - val_loss: 25.6946\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8906 - val_loss: 26.8274\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8871 - val_loss: 25.7894\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0330 - val_loss: 25.9391\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6072 - val_loss: 25.3394\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.7661 - val_loss: 26.6899\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1046 - val_loss: 26.7784\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8522 - val_loss: 26.5325\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1405 - val_loss: 26.1023\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.4409 - val_loss: 26.8204\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0033 - val_loss: 25.9538\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.5922 - val_loss: 26.4004\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1545 - val_loss: 26.5759\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3961 - val_loss: 26.2190\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.2563 - val_loss: 26.6472\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0109 - val_loss: 27.1326\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.2509 - val_loss: 26.1602\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8718 - val_loss: 26.1992\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.4317 - val_loss: 25.8816\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9694 - val_loss: 26.1165\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1765 - val_loss: 27.7066\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8874 - val_loss: 26.8098\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7353 - val_loss: 25.4530\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.4188 - val_loss: 25.5948\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6491 - val_loss: 25.3129\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9043 - val_loss: 26.7858\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.2243 - val_loss: 25.7877\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8399 - val_loss: 25.8445\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1832 - val_loss: 25.8398\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6993 - val_loss: 27.3902\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1491 - val_loss: 25.4464\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6056 - val_loss: 25.8452\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0429 - val_loss: 26.0004\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6093 - val_loss: 25.7905\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1694 - val_loss: 27.0898\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3739 - val_loss: 25.4725\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.7295 - val_loss: 26.6280\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9669 - val_loss: 26.7354\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2355 - val_loss: 27.0508\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5349 - val_loss: 25.5724\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.4492 - val_loss: 25.4555\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.5972 - val_loss: 27.5129\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.2889 - val_loss: 25.9349\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8088 - val_loss: 26.3286\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6044 - val_loss: 26.0187\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0612 - val_loss: 25.3351\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.7162 - val_loss: 27.0211\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3776 - val_loss: 25.4543\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.4628 - val_loss: 25.6414\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9371 - val_loss: 26.2738\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.4440 - val_loss: 25.5188\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.1218 - val_loss: 26.6329\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8302 - val_loss: 26.1565\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1257 - val_loss: 26.1223\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8223 - val_loss: 25.6252\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1544 - val_loss: 25.3309\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.1156 - val_loss: 26.0946\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.4912 - val_loss: 26.2409\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.8750 - val_loss: 25.7405\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.4255 - val_loss: 25.9337\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 21.8430 - val_loss: 27.8978\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 22.4848 - val_loss: 25.2473\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.3693 - val_loss: 26.2098\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5061 - val_loss: 25.7131\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.7576 - val_loss: 27.6968\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.0703 - val_loss: 26.2173\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 133us/step - loss: 22.2969 - val_loss: 27.7425\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.7929 - val_loss: 26.5636\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 22.7204 - val_loss: 31.5281\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.5542 - val_loss: 28.2188\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 24.1712 - val_loss: 30.6777\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.8840 - val_loss: 26.0075\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.2991 - val_loss: 25.5941\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8414 - val_loss: 26.8564\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0131 - val_loss: 27.3977\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9344 - val_loss: 26.6134\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.8162 - val_loss: 26.1810\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.5557 - val_loss: 26.1687\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.7441 - val_loss: 26.0266\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.3038 - val_loss: 27.2123\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8766 - val_loss: 25.8714\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6540 - val_loss: 25.5054\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0150 - val_loss: 25.6818\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6596 - val_loss: 25.3673\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.2877 - val_loss: 25.5523\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7537 - val_loss: 28.4875\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.0725 - val_loss: 27.2686\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.8951 - val_loss: 25.5257\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.4310 - val_loss: 25.5937\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.6293 - val_loss: 25.7283\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 21.9210 - val_loss: 26.2122\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.0063 - val_loss: 26.4455\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.4052 - val_loss: 25.4346\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.9297 - val_loss: 24.7699\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.3003 - val_loss: 25.8216\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.6772 - val_loss: 24.9851\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.3586 - val_loss: 24.7591\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.0754 - val_loss: 24.6153\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.4032 - val_loss: 24.9881\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.3629 - val_loss: 24.6523\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7298 - val_loss: 24.9373\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 20.4728 - val_loss: 24.4008\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.7723 - val_loss: 25.1803\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.3053 - val_loss: 24.3035\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.4827 - val_loss: 23.5065\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.9844 - val_loss: 23.8333\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.3261 - val_loss: 24.4562\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.5092 - val_loss: 23.9288\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.8797 - val_loss: 23.6628\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.4958 - val_loss: 23.3762\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.3070 - val_loss: 23.3238\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.1481 - val_loss: 23.5102\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.5809 - val_loss: 24.9323\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1305 - val_loss: 23.8809\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6966 - val_loss: 25.4214\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 19.1679 - val_loss: 21.7917\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0356 - val_loss: 21.5875\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.6953 - val_loss: 22.1915\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7671 - val_loss: 23.1677\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4742 - val_loss: 24.2742\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8497 - val_loss: 21.4242\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6769 - val_loss: 22.2314\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6500 - val_loss: 21.3534\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6480 - val_loss: 20.5834\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2615 - val_loss: 20.6506\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9352 - val_loss: 22.7708\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8270 - val_loss: 21.0355\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5078 - val_loss: 21.0063\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4974 - val_loss: 19.6846\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9833 - val_loss: 22.7142\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5186 - val_loss: 19.8144\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.8521 - val_loss: 19.5943\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1948 - val_loss: 19.2304\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.8471 - val_loss: 18.6343\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.8453 - val_loss: 20.5738\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.9219 - val_loss: 19.3199\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0724 - val_loss: 21.0503\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2726 - val_loss: 19.2029\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.4174 - val_loss: 19.3248\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.7267 - val_loss: 19.3729\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.4312 - val_loss: 18.4173\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 16.4186 - val_loss: 19.0748\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.7203 - val_loss: 20.0916\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.2242 - val_loss: 18.2771\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.9064 - val_loss: 17.7510\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.3491 - val_loss: 18.4951\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.8231 - val_loss: 18.6213\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.2701 - val_loss: 19.2385\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.6791 - val_loss: 19.2035\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.8392 - val_loss: 19.4209\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.7328 - val_loss: 17.6966\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.7590 - val_loss: 21.0858\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.3097 - val_loss: 17.6101\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.5864 - val_loss: 18.2233\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.2356 - val_loss: 17.5632\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.5186 - val_loss: 18.1828\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.4299 - val_loss: 17.9838\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.0139 - val_loss: 17.1907\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.6242 - val_loss: 18.4498\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.2221 - val_loss: 17.5560\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.8053 - val_loss: 18.8392\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.1495 - val_loss: 19.6011\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.0392 - val_loss: 17.1781\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.7239 - val_loss: 18.9399\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.7001 - val_loss: 17.2474\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4643 - val_loss: 18.9403\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.5534 - val_loss: 17.5687\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.3469 - val_loss: 17.9029\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.6342 - val_loss: 17.0715\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8920 - val_loss: 16.9133\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8554 - val_loss: 17.4566\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6976 - val_loss: 17.0570\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2430 - val_loss: 17.0739\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.0699 - val_loss: 19.9831\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.2020 - val_loss: 16.9854\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7509 - val_loss: 16.8169\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7253 - val_loss: 17.7167\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.1051 - val_loss: 16.7474\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8103 - val_loss: 17.0079\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.5615 - val_loss: 16.5408\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.0473 - val_loss: 16.0108\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.9263 - val_loss: 16.0412\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.1945 - val_loss: 16.4291\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7138 - val_loss: 16.7770\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.8516 - val_loss: 16.8639\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.3427 - val_loss: 16.1235\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.9718 - val_loss: 15.3999\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.0312 - val_loss: 15.5840\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.2179 - val_loss: 17.1465\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8416 - val_loss: 17.7191\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6636 - val_loss: 17.2678\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.2030 - val_loss: 15.3272\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.4203 - val_loss: 16.4450\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5927 - val_loss: 15.4603\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.7990 - val_loss: 15.1064\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7810 - val_loss: 14.9525\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.8059 - val_loss: 16.7469\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2054 - val_loss: 16.0474\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2803 - val_loss: 14.7441\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.3622 - val_loss: 15.5224\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1590 - val_loss: 14.5782\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9350 - val_loss: 15.2014\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8932 - val_loss: 15.9692\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5550 - val_loss: 16.2989\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9818 - val_loss: 14.4957\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.8297 - val_loss: 14.3428\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8584 - val_loss: 14.7214\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3979 - val_loss: 14.8759\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3248 - val_loss: 16.2088\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5944 - val_loss: 15.3971\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2579 - val_loss: 14.2257\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4170 - val_loss: 17.8470\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3370 - val_loss: 14.1722\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.0912 - val_loss: 14.1255\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7083 - val_loss: 14.7940\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1083 - val_loss: 16.1120\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1559 - val_loss: 15.7417\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6085 - val_loss: 15.7791\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1280 - val_loss: 14.2517\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3246 - val_loss: 13.3019\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4776 - val_loss: 16.5308\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4961 - val_loss: 13.4225\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.4273 - val_loss: 15.9735\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.5066 - val_loss: 14.4223\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9044 - val_loss: 13.3742\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.5811 - val_loss: 14.2030\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.6187 - val_loss: 13.7549\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9617 - val_loss: 13.1261\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2177 - val_loss: 13.1212\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.1578 - val_loss: 15.2509\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 11.4436 - val_loss: 13.1173\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.0751 - val_loss: 13.0206\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.1221 - val_loss: 13.3066\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.6773 - val_loss: 13.1434\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.4556 - val_loss: 13.1547\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.4032 - val_loss: 13.1776\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.7888 - val_loss: 13.3050\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.3932 - val_loss: 18.4661\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7780 - val_loss: 12.4973\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3322 - val_loss: 14.0538\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3754 - val_loss: 12.6918\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.1369 - val_loss: 12.4063\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1207 - val_loss: 12.7139\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0603 - val_loss: 12.4809\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2021 - val_loss: 12.9630\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0744 - val_loss: 12.9343\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9368 - val_loss: 12.9891\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7658 - val_loss: 12.8678\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.8976 - val_loss: 13.3093\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.3509 - val_loss: 13.4542\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1984 - val_loss: 14.6590\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 10.0269 - val_loss: 13.8276\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8295 - val_loss: 13.0776\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7953 - val_loss: 13.4490\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 11.10 - 0s 87us/step - loss: 10.4574 - val_loss: 12.2014\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5785 - val_loss: 11.7636\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9643 - val_loss: 12.6276\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9841 - val_loss: 12.7177\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7640 - val_loss: 12.3411\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6343 - val_loss: 14.0404\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2037 - val_loss: 11.7842\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1266 - val_loss: 12.8438\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7689 - val_loss: 14.0014\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2573 - val_loss: 12.1101\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8541 - val_loss: 13.6224\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8879 - val_loss: 12.7936\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8760 - val_loss: 12.8829\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4592 - val_loss: 12.6790\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4794 - val_loss: 11.6066\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7027 - val_loss: 12.4815\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0430 - val_loss: 12.4608\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.7029 - val_loss: 12.0228\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.5435 - val_loss: 12.0849\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4889 - val_loss: 12.0058\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8592 - val_loss: 13.6176\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3024 - val_loss: 11.6334\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4541 - val_loss: 12.5997\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1787 - val_loss: 12.0643\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4367 - val_loss: 12.8263\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6463 - val_loss: 11.8213\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2549 - val_loss: 11.6035\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0118 - val_loss: 12.1443\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3876 - val_loss: 12.1423\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6825 - val_loss: 12.7507\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4605 - val_loss: 11.4309\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6704 - val_loss: 13.2758\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.9859 - val_loss: 11.8156\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6127 - val_loss: 13.2868\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6204 - val_loss: 13.6358\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4715 - val_loss: 11.4739\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9273 - val_loss: 11.7422\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9338 - val_loss: 11.3360\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4973 - val_loss: 13.1645\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.1519 - val_loss: 11.7848\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9726 - val_loss: 11.0081\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3800 - val_loss: 13.6966\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.3485 - val_loss: 10.9806\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0777 - val_loss: 12.5118\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9699 - val_loss: 12.1061\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2141 - val_loss: 11.7594\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1383 - val_loss: 11.5617\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5108 - val_loss: 11.6613\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2693 - val_loss: 12.5008\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 9.3593 - val_loss: 10.9299\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3706 - val_loss: 13.6014\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2708 - val_loss: 10.7114\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1826 - val_loss: 11.9307\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3595 - val_loss: 11.6130\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8375 - val_loss: 10.8842\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1332 - val_loss: 10.7809\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0551 - val_loss: 10.7571\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2444 - val_loss: 11.3312\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2521 - val_loss: 14.6106\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2353 - val_loss: 11.1621\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2978 - val_loss: 11.6788\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0367 - val_loss: 12.1420\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0320 - val_loss: 10.8613\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4112 - val_loss: 11.1020\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5386 - val_loss: 12.7478\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9573 - val_loss: 10.9936\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2556 - val_loss: 10.7778\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9157 - val_loss: 11.9312\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0181 - val_loss: 11.0468\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7924 - val_loss: 11.7027\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4440 - val_loss: 12.2229\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6225 - val_loss: 10.7790\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7394 - val_loss: 10.8677\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7669 - val_loss: 10.2791\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7966 - val_loss: 11.3777\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1909 - val_loss: 12.3806\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4666 - val_loss: 11.3998\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0120 - val_loss: 10.9028\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7417 - val_loss: 10.5119\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0980 - val_loss: 10.4535\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6614 - val_loss: 11.1268\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0410 - val_loss: 11.3910\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9900 - val_loss: 11.7983\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4019 - val_loss: 10.7665\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8333 - val_loss: 10.6537\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7345 - val_loss: 11.4848\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8210 - val_loss: 12.4745\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8425 - val_loss: 11.3385\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7172 - val_loss: 11.7075\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2762 - val_loss: 11.6806\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0172 - val_loss: 10.4832\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8670 - val_loss: 10.4624\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9372 - val_loss: 10.8973\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1215 - val_loss: 12.1724\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8606 - val_loss: 10.1648\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6847 - val_loss: 11.8062\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8701 - val_loss: 10.5394\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7628 - val_loss: 11.0495\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8253 - val_loss: 11.0196\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9026 - val_loss: 10.6137\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6193 - val_loss: 10.3895\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 8.5789 - val_loss: 10.4249\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0606 - val_loss: 10.5296\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6754 - val_loss: 9.9907\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5750 - val_loss: 10.5728\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6347 - val_loss: 13.5489\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7911 - val_loss: 10.2173\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5085 - val_loss: 11.2025\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0692 - val_loss: 12.2219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6996 - val_loss: 10.8718\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7239 - val_loss: 10.3888\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1479 - val_loss: 11.1242\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7767 - val_loss: 10.2389\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8353 - val_loss: 10.4627\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8333 - val_loss: 10.8187\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8089 - val_loss: 10.9676\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4251 - val_loss: 10.3957\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4635 - val_loss: 10.1323\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6321 - val_loss: 11.0033\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8925 - val_loss: 10.2657\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8545 - val_loss: 10.6867\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9222 - val_loss: 10.4553\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1137 - val_loss: 11.4374\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6099 - val_loss: 10.8125\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6244 - val_loss: 10.4029\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3370 - val_loss: 10.4585\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7278 - val_loss: 10.2589\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5273 - val_loss: 11.8638\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6146 - val_loss: 11.1044\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4260 - val_loss: 10.7037\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6598 - val_loss: 11.0705\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7137 - val_loss: 10.1978\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4802 - val_loss: 10.0105\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6989 - val_loss: 10.3046\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4621 - val_loss: 10.9890\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5827 - val_loss: 10.2097\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5669 - val_loss: 10.3073\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0275 - val_loss: 11.5848\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8327 - val_loss: 11.4195\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6964 - val_loss: 9.9797\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2782 - val_loss: 10.0899\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9774 - val_loss: 10.7840\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4536 - val_loss: 10.2757\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6152 - val_loss: 9.8858\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7371 - val_loss: 10.7509\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.6983 - val_loss: 10.1274\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9253 - val_loss: 10.8955\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9365 - val_loss: 10.8538\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6859 - val_loss: 10.2341\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.5996 - val_loss: 10.2212\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.1973 - val_loss: 10.6614\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8227 - val_loss: 10.4339\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.5785 - val_loss: 11.0434\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6064 - val_loss: 12.5376\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6591 - val_loss: 10.8389\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4731 - val_loss: 10.6846\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5450 - val_loss: 10.4765\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6183 - val_loss: 11.0325\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5879 - val_loss: 10.5520\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4248 - val_loss: 10.3625\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6864 - val_loss: 10.1585\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5450 - val_loss: 10.2183\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3412 - val_loss: 10.2576\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5149 - val_loss: 10.2503\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6406 - val_loss: 10.0084\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5012 - val_loss: 10.1793\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6234 - val_loss: 10.6919\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0661 - val_loss: 15.7146\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9727 - val_loss: 10.1060\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5087 - val_loss: 10.7477\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9551 - val_loss: 12.5966\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6248 - val_loss: 10.4112\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9771 - val_loss: 10.4334\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5582 - val_loss: 10.0081\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9383 - val_loss: 11.3968\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4112 - val_loss: 10.4379\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3534 - val_loss: 10.9085\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5152 - val_loss: 11.2767\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1277 - val_loss: 9.8522\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6295 - val_loss: 10.3066\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4353 - val_loss: 10.0255\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2274 - val_loss: 10.2393\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6610 - val_loss: 9.9562\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6519 - val_loss: 9.7862\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6143 - val_loss: 10.3241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4852 - val_loss: 10.0128\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8544 - val_loss: 10.2110\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8361 - val_loss: 10.3348\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4110 - val_loss: 10.0330\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8551 - val_loss: 10.3817\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3275 - val_loss: 10.0554\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5183 - val_loss: 10.3975\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0738 - val_loss: 10.5924\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2307 - val_loss: 9.7437\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7984 - val_loss: 10.1701\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5028 - val_loss: 10.4827\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5561 - val_loss: 10.7652\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6935 - val_loss: 10.2015\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5201 - val_loss: 9.8891\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3940 - val_loss: 10.4027\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5412 - val_loss: 10.3729\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3351 - val_loss: 10.3575\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7612 - val_loss: 12.4436\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5782 - val_loss: 11.0696\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6165 - val_loss: 9.9156\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5221 - val_loss: 10.6642\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4064 - val_loss: 10.3059\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6100 - val_loss: 10.3211\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6667 - val_loss: 10.6387\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7836 - val_loss: 10.5005\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3580 - val_loss: 9.6194\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4241 - val_loss: 9.9127\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7794 - val_loss: 10.2379\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7743 - val_loss: 10.2875\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4535 - val_loss: 9.7343\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1700 - val_loss: 10.7189\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7442 - val_loss: 10.5379\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3415 - val_loss: 10.2265\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5840 - val_loss: 10.3053\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5431 - val_loss: 9.7421\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4181 - val_loss: 10.8666\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3927 - val_loss: 10.1152\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4043 - val_loss: 10.5770\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7498 - val_loss: 9.8338\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6190 - val_loss: 10.6699\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5570 - val_loss: 11.3342\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6660 - val_loss: 9.9844\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3950 - val_loss: 11.6377\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2965 - val_loss: 11.0271\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4242 - val_loss: 9.7601\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7046 - val_loss: 9.9178\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4745 - val_loss: 10.1495\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6761 - val_loss: 10.0906\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7330 - val_loss: 9.6835\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6628 - val_loss: 10.8659\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6446 - val_loss: 9.6481\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0732 - val_loss: 10.5142\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6042 - val_loss: 11.3867\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8164 - val_loss: 10.0697\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3416 - val_loss: 10.1584\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5305 - val_loss: 11.2337\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6303 - val_loss: 9.7091\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6599 - val_loss: 10.4471\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5237 - val_loss: 9.8839\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3389 - val_loss: 10.0436\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5460 - val_loss: 10.0297\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2956 - val_loss: 9.7354\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3198 - val_loss: 9.8841\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2357 - val_loss: 9.4656\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6077 - val_loss: 9.7800\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7515 - val_loss: 9.6792\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6352 - val_loss: 11.5459\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9408 - val_loss: 9.6951\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5910 - val_loss: 9.7321\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7317 - val_loss: 11.0615\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9334 - val_loss: 10.7847\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4179 - val_loss: 10.3076\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3435 - val_loss: 10.8557\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8503 - val_loss: 10.8181\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2513 - val_loss: 10.7674\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5257 - val_loss: 11.6826\n",
      "Epoch 593/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4126 - val_loss: 10.5608\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0547 - val_loss: 9.6861\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5150 - val_loss: 10.2997\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9052 - val_loss: 9.5229\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8265 - val_loss: 10.1365\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3932 - val_loss: 9.6110\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6736 - val_loss: 11.0254\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3473 - val_loss: 10.4018\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2267 - val_loss: 9.7200\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9375 - val_loss: 11.5757\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3759 - val_loss: 9.5622\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4198 - val_loss: 9.9578\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2863 - val_loss: 10.0351\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2492 - val_loss: 10.1251\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4642 - val_loss: 10.2716\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5410 - val_loss: 9.4489\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5613 - val_loss: 9.9610\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3246 - val_loss: 10.2211\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4689 - val_loss: 11.5493\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5461 - val_loss: 10.4780\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5079 - val_loss: 10.3287\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3697 - val_loss: 9.8395\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5020 - val_loss: 9.5470\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2465 - val_loss: 10.5532\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2877 - val_loss: 9.7341\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5741 - val_loss: 10.3542\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6958 - val_loss: 10.7216\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2000 - val_loss: 9.4313\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3862 - val_loss: 9.8420\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5680 - val_loss: 10.1148\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1684 - val_loss: 10.0080\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4066 - val_loss: 10.4097\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5119 - val_loss: 11.4486\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3486 - val_loss: 9.4016\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5306 - val_loss: 10.7853\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4717 - val_loss: 9.6440\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5824 - val_loss: 11.6388\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1267 - val_loss: 10.0991\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5831 - val_loss: 10.8274\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3150 - val_loss: 9.3796\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3585 - val_loss: 9.6059\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7347 - val_loss: 10.4571\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3302 - val_loss: 9.7672\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2575 - val_loss: 10.4885\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.272 - 0s 84us/step - loss: 8.4230 - val_loss: 11.2101\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5546 - val_loss: 10.0719\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5619 - val_loss: 9.5216\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9183 - val_loss: 9.7260\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2079 - val_loss: 9.2961\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4893 - val_loss: 10.2132\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1097 - val_loss: 11.0631\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4358 - val_loss: 10.2918\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2855 - val_loss: 10.7214\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.2614 - val_loss: 10.1698\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 8.1016 - val_loss: 9.7721\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4108 - val_loss: 9.7661\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4760 - val_loss: 10.7901\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2619 - val_loss: 10.0025\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0024 - val_loss: 9.7777\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4188 - val_loss: 10.0321\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1696 - val_loss: 10.6222\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3036 - val_loss: 9.6783\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2818 - val_loss: 9.4379\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3305 - val_loss: 9.7491\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4633 - val_loss: 10.7591\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3049 - val_loss: 10.0670\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3953 - val_loss: 10.0989\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3632 - val_loss: 9.7120\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4126 - val_loss: 10.3053\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2752 - val_loss: 10.5391\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3375 - val_loss: 9.6918\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2528 - val_loss: 9.4240\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3293 - val_loss: 10.0005\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3736 - val_loss: 11.9721\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4138 - val_loss: 9.3107\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1322 - val_loss: 9.4677\n",
      "Epoch 669/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0396 - val_loss: 11.0373\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5751 - val_loss: 9.3707\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6487 - val_loss: 9.7659\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3287 - val_loss: 9.3023\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9177 - val_loss: 9.8464\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.6080 - val_loss: 9.5317\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4155 - val_loss: 9.4150\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5440 - val_loss: 10.9077\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3901 - val_loss: 10.0909\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5579 - val_loss: 11.1146\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2508 - val_loss: 9.6236\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1505 - val_loss: 14.3073\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4164 - val_loss: 9.4939\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.7499 - val_loss: 10.5883\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4070 - val_loss: 9.7235\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3915 - val_loss: 9.3648\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2246 - val_loss: 10.7998\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4872 - val_loss: 10.7400\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2674 - val_loss: 10.2171\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1169 - val_loss: 9.8507\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2446 - val_loss: 10.1848\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2749 - val_loss: 11.5851\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6608 - val_loss: 10.1702\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7923 - val_loss: 10.3515\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5571 - val_loss: 10.1796\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4930 - val_loss: 10.2958\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3898 - val_loss: 9.5185\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3897 - val_loss: 10.7856\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.4998 - val_loss: 10.7744\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3616 - val_loss: 9.9235\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3539 - val_loss: 10.4678\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4768 - val_loss: 9.3793\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5674 - val_loss: 12.3476\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4469 - val_loss: 11.0039\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4216 - val_loss: 9.7529\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5388 - val_loss: 9.7613\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8966 - val_loss: 10.8394\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5053 - val_loss: 9.9580\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6994 - val_loss: 9.3687\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2491 - val_loss: 10.5711\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0730 - val_loss: 9.7653\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7414 - val_loss: 9.6459\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5005 - val_loss: 12.3956\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2566 - val_loss: 9.8788\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9645 - val_loss: 10.0116\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2637 - val_loss: 9.4296\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4442 - val_loss: 11.8435\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2882 - val_loss: 9.5455\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1771 - val_loss: 9.5521\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2621 - val_loss: 10.1439\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4702 - val_loss: 10.8658\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3782 - val_loss: 9.5336\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2578 - val_loss: 9.5159\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7730 - val_loss: 11.1465\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7455 - val_loss: 9.3432\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5176 - val_loss: 10.0394\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3267 - val_loss: 9.5303\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2159 - val_loss: 11.2411\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4691 - val_loss: 9.9564\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5389 - val_loss: 9.6731\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1751 - val_loss: 9.9085\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2937 - val_loss: 11.5235\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6115 - val_loss: 9.7282\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3420 - val_loss: 9.3930\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3288 - val_loss: 9.8954\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9483 - val_loss: 9.7963\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1601 - val_loss: 9.6312\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2677 - val_loss: 9.4514\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4303 - val_loss: 10.1275\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6287 - val_loss: 9.6607\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5171 - val_loss: 10.5513\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2803 - val_loss: 11.2343\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5642 - val_loss: 11.0203\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6383 - val_loss: 9.6079\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2373 - val_loss: 9.2717\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1214 - val_loss: 10.2953\n",
      "Epoch 745/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1894 - val_loss: 9.7923\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1627 - val_loss: 9.6277\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2254 - val_loss: 11.8601\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3113 - val_loss: 9.4921\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2625 - val_loss: 10.5501\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3859 - val_loss: 10.4443\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0816 - val_loss: 9.4323\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0860 - val_loss: 10.4788\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2241 - val_loss: 10.0485\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1103 - val_loss: 9.4794\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5947 - val_loss: 10.4569\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0975 - val_loss: 10.0181\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6234 - val_loss: 9.1530\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5917 - val_loss: 9.9566\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3497 - val_loss: 9.3607\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3906 - val_loss: 9.4063\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5291 - val_loss: 11.3566\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4680 - val_loss: 10.5134\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1445 - val_loss: 10.3805\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3221 - val_loss: 10.0078\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2007 - val_loss: 10.5906\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6254 - val_loss: 9.6491\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2218 - val_loss: 9.8050\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0976 - val_loss: 9.6984\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5980 - val_loss: 9.5817\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6183 - val_loss: 10.3224\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0487 - val_loss: 9.3183\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3677 - val_loss: 9.6156\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3804 - val_loss: 9.1398\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3549 - val_loss: 10.5891\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3340 - val_loss: 9.5658\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6517 - val_loss: 9.7464\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5521 - val_loss: 9.3819\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6844 - val_loss: 9.5168\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7053 - val_loss: 9.7694\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2129 - val_loss: 10.0304\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0643 - val_loss: 9.1702\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1366 - val_loss: 10.5853\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4705 - val_loss: 9.4371\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4471 - val_loss: 9.4438\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.332 - 0s 90us/step - loss: 8.3624 - val_loss: 11.4317\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3257 - val_loss: 10.7670\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8102 - val_loss: 10.1932\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3252 - val_loss: 9.7495\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6568 - val_loss: 9.8444\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4971 - val_loss: 9.4469\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7170 - val_loss: 11.7194\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5736 - val_loss: 11.5613\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2110 - val_loss: 9.4348\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0259 - val_loss: 9.3658\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1178 - val_loss: 9.1204\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2686 - val_loss: 9.9338\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2547 - val_loss: 10.4827\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3344 - val_loss: 10.0870\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9216 - val_loss: 11.1398\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7561 - val_loss: 10.2589\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2532 - val_loss: 10.7928\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0872 - val_loss: 9.4623\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4016 - val_loss: 9.6265\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3331 - val_loss: 11.6712\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6612 - val_loss: 9.0520\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2785 - val_loss: 9.1344\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2730 - val_loss: 11.5206\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2744 - val_loss: 9.5879\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2283 - val_loss: 9.9135\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4800 - val_loss: 9.5258\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0753 - val_loss: 9.7367\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6536 - val_loss: 11.0718\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7484 - val_loss: 10.3496\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5576 - val_loss: 9.4136\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 132us/step - loss: 8.0365 - val_loss: 9.7340\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2003 - val_loss: 9.4861\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3412 - val_loss: 11.0255\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1957 - val_loss: 10.3979\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3019 - val_loss: 9.7970\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1636 - val_loss: 9.6466\n",
      "Epoch 821/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3267 - val_loss: 9.5056\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4923 - val_loss: 11.4442\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.0456 - val_loss: 12.3427\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.3215 - val_loss: 9.3712\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4515 - val_loss: 9.5210\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2456 - val_loss: 10.4553\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1619 - val_loss: 9.0253\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0468 - val_loss: 9.1860\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2014 - val_loss: 9.9225\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1029 - val_loss: 9.4937\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8912 - val_loss: 11.2592\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3353 - val_loss: 12.4684\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8301 - val_loss: 10.1688\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4044 - val_loss: 13.3437\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4160 - val_loss: 9.3067\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.0930 - val_loss: 9.8927\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2752 - val_loss: 9.4310\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5770 - val_loss: 9.1793\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4080 - val_loss: 9.2371\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2326 - val_loss: 10.1220\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1980 - val_loss: 9.0581\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1760 - val_loss: 9.8157\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2018 - val_loss: 10.0096\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4809 - val_loss: 9.8940\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9863 - val_loss: 9.6546\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2445 - val_loss: 11.2768\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3614 - val_loss: 9.1759\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0969 - val_loss: 9.2426\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3360 - val_loss: 10.9254\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4679 - val_loss: 10.3733\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0783 - val_loss: 9.7496\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0760 - val_loss: 9.7376\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2660 - val_loss: 9.2386\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2712 - val_loss: 11.1426\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4373 - val_loss: 10.3884\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0690 - val_loss: 10.3799\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1532 - val_loss: 9.8389\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0814 - val_loss: 10.8491\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4898 - val_loss: 9.2777\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3707 - val_loss: 10.4571\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5894 - val_loss: 10.6110\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3723 - val_loss: 10.5180\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2308 - val_loss: 11.3302\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5533 - val_loss: 9.4313\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7852 - val_loss: 9.8853\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5500 - val_loss: 9.2879\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0364 - val_loss: 10.3083\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0787 - val_loss: 9.8294\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9885 - val_loss: 9.5216\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1800 - val_loss: 11.1668\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7178 - val_loss: 10.4214\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3039 - val_loss: 9.6398\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5467 - val_loss: 9.6745\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0824 - val_loss: 9.7366\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1707 - val_loss: 10.1806\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3947 - val_loss: 9.2499\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2371 - val_loss: 9.8796\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2500 - val_loss: 10.7792\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1970 - val_loss: 9.7940\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3795 - val_loss: 10.0839\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1274 - val_loss: 9.3986\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1640 - val_loss: 10.5671\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7706 - val_loss: 9.8689\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1395 - val_loss: 11.7062\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2829 - val_loss: 10.2746\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2131 - val_loss: 10.0139\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2103 - val_loss: 9.5749\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1594 - val_loss: 11.6602\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.2849 - val_loss: 9.0748\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.9596 - val_loss: 9.5067\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5191 - val_loss: 9.2338\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5043 - val_loss: 9.0503\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5114 - val_loss: 9.3970\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.1345 - val_loss: 9.2489\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.9797 - val_loss: 9.7722\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4028 - val_loss: 9.5150\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8687 - val_loss: 9.1530\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2649 - val_loss: 14.7820\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7883 - val_loss: 9.1157\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 7.9856 - val_loss: 9.1549\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2884 - val_loss: 10.4425\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5000 - val_loss: 9.5787\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0467 - val_loss: 9.8991\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2308 - val_loss: 11.0025\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7651 - val_loss: 9.3578\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2123 - val_loss: 10.3526\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2546 - val_loss: 10.4840\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3264 - val_loss: 9.4737\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3345 - val_loss: 9.1214\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0840 - val_loss: 11.0595\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4513 - val_loss: 9.6358\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0942 - val_loss: 12.1741\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5071 - val_loss: 9.6088\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2996 - val_loss: 9.2817\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0475 - val_loss: 10.8216\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7282 - val_loss: 9.9588\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1765 - val_loss: 9.8741\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0135 - val_loss: 9.2905\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2272 - val_loss: 11.4124\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6908 - val_loss: 10.9408\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3615 - val_loss: 9.3739\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4107 - val_loss: 10.0793\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3408 - val_loss: 9.6926\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5600 - val_loss: 10.5821\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1898 - val_loss: 10.4294\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5229 - val_loss: 9.0614\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2784 - val_loss: 10.2527\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1256 - val_loss: 9.3418\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2067 - val_loss: 9.5138\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9769 - val_loss: 9.2458\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1776 - val_loss: 9.0522\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5382 - val_loss: 11.6192\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1351 - val_loss: 9.2999\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1333 - val_loss: 9.5817\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4513 - val_loss: 9.8779\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5284 - val_loss: 9.1839\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4988 - val_loss: 10.0733\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1188 - val_loss: 9.5386\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4509 - val_loss: 9.4822\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2457 - val_loss: 9.7947\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.0245 - val_loss: 8.9833\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1475 - val_loss: 9.1766\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9524 - val_loss: 10.1035\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4118 - val_loss: 10.7295\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5611 - val_loss: 9.2985\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3064 - val_loss: 10.5767\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1551 - val_loss: 9.2313\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7861 - val_loss: 10.9778\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7939 - val_loss: 9.9615\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3942 - val_loss: 11.1698\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3934 - val_loss: 8.9689\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2063 - val_loss: 9.1671\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0890 - val_loss: 10.0688\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3935 - val_loss: 11.0417\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1029 - val_loss: 9.3340\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3009 - val_loss: 9.9599\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.1017 - val_loss: 10.2863\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5573 - val_loss: 9.3161\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3784 - val_loss: 11.8949\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2746 - val_loss: 9.0429\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 7.9484 - val_loss: 8.9244\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2342 - val_loss: 10.0718\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2810 - val_loss: 9.2126\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.8130 - val_loss: 9.7229\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3927 - val_loss: 10.4924\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1799 - val_loss: 9.4101\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1591 - val_loss: 9.3111\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1461 - val_loss: 9.6600\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9762 - val_loss: 9.5968\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8430 - val_loss: 14.8617\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5812 - val_loss: 9.2533\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6421 - val_loss: 9.2222\n",
      "Epoch 973/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0502 - val_loss: 9.7618\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9501 - val_loss: 10.2994\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2960 - val_loss: 9.4219\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4939 - val_loss: 9.5492\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5250 - val_loss: 10.8732\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1410 - val_loss: 9.3658\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0805 - val_loss: 12.0583\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7922 - val_loss: 10.5071\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3784 - val_loss: 9.5935\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4708 - val_loss: 10.8803\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.1486 - val_loss: 9.1590\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.0248 - val_loss: 9.2545\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3927 - val_loss: 9.4969\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.1340 - val_loss: 9.2729\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3116 - val_loss: 9.1212\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4701 - val_loss: 8.9760\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0729 - val_loss: 10.8258\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1775 - val_loss: 10.1548\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6892 - val_loss: 12.3370\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4163 - val_loss: 10.7275\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5610 - val_loss: 10.4774\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3122 - val_loss: 8.8978\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2044 - val_loss: 8.7781\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9656 - val_loss: 8.8876\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1193 - val_loss: 8.7016\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3867 - val_loss: 10.4552\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0424 - val_loss: 9.1020\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5020 - val_loss: 11.4902\n",
      "9.218888432578703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.8638254 ,  0.1639064 , -0.715536  ,  3.1931274 ,  3.8810928 ],\n",
       "        [-0.49088567,  0.19676493, -1.3901565 , -0.08646253, -0.21229161],\n",
       "        [-0.41498423,  0.26364416, -1.562531  ,  0.0117086 ,  0.73369336],\n",
       "        [-0.03869668, -0.14183575,  0.28012773, -0.05483614, -0.1487281 ],\n",
       "        [ 0.30044258,  0.18166883,  0.30797318,  2.3850937 ,  0.32695815]],\n",
       "       dtype=float32),\n",
       " array([ 1.2829367, -1.4033979, -0.6967152,  4.6676583,  4.8110886],\n",
       "       dtype=float32),\n",
       " array([[-0.2379871 ,  0.05277628,  0.06090817, -0.7977439 , -0.96935934,\n",
       "         -0.8805078 ,  0.93161994,  0.68036294, -0.7954822 ,  0.48415345],\n",
       "        [-2.1818473 , -1.3489575 ,  1.5507106 , -1.3092884 , -1.3966088 ,\n",
       "         -2.2078009 ,  1.9661856 ,  1.2360812 , -1.3530254 ,  1.5751476 ],\n",
       "        [ 0.43510717,  0.65471554, -0.12983209,  0.49125203, -0.40938845,\n",
       "          0.7952666 ,  0.08327661, -0.39176705,  0.3973744 , -0.27732372],\n",
       "        [ 1.671554  ,  2.0393345 , -1.27915   ,  1.4014947 ,  1.9052303 ,\n",
       "          1.6853664 , -1.3387538 , -1.0904391 ,  1.8998944 , -1.2501706 ],\n",
       "        [ 2.030961  ,  1.2832482 , -2.1121938 ,  1.6727846 ,  2.247925  ,\n",
       "          2.2593021 , -2.284415  , -1.9920805 ,  2.2940094 , -2.0276353 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.9243302,  1.8197255, -1.9527371,  1.9351993,  1.8168205,\n",
       "         1.8155757, -1.8761556, -1.9170976,  1.8370333, -1.8313049],\n",
       "       dtype=float32),\n",
       " array([[ 1.848975 ],\n",
       "        [ 2.012733 ],\n",
       "        [-1.8360912],\n",
       "        [ 1.3469095],\n",
       "        [ 2.1560192],\n",
       "        [ 2.1886175],\n",
       "        [-1.8431257],\n",
       "        [-1.6676685],\n",
       "        [ 2.0560136],\n",
       "        [-2.2197118]], dtype=float32),\n",
       " array([1.8331064], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_linear(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_linear.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 197us/step - loss: 7472.3616 - val_loss: 662.5054\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 463.6915 - val_loss: 242.1156\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 184.7020 - val_loss: 119.0660\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 104.5545 - val_loss: 81.3822\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 75.8454 - val_loss: 62.2079\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 61.2485 - val_loss: 55.1735\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 54.5984 - val_loss: 51.2613\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 50.0685 - val_loss: 45.9713\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 46.1848 - val_loss: 43.0154\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 43.6233 - val_loss: 40.6406\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 40.1393 - val_loss: 37.3835\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 37.1999 - val_loss: 34.9482\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 34.1645 - val_loss: 32.7946\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 32.8281 - val_loss: 31.5658\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 30.2320 - val_loss: 29.3324\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 28.1633 - val_loss: 29.6824\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 26.5797 - val_loss: 26.4259\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 24.5684 - val_loss: 25.8253\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.0297 - val_loss: 25.8955\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.0544 - val_loss: 25.1533\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9263 - val_loss: 24.8519\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.9349 - val_loss: 25.0335\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.8198 - val_loss: 24.0677\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.2141 - val_loss: 24.3264\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 20.5525 - val_loss: 23.8351\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.2379 - val_loss: 24.5135\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.2917 - val_loss: 25.2712\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.2794 - val_loss: 24.1895\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.0243 - val_loss: 24.2489\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.5744 - val_loss: 23.3254\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.4150 - val_loss: 24.2998\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 19.8028 - val_loss: 24.2151\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.4216 - val_loss: 23.0751\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.2331 - val_loss: 23.6851\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.8576 - val_loss: 23.0790\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.5280 - val_loss: 22.9416\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.1516 - val_loss: 23.4375\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.3655 - val_loss: 24.8371\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.4389 - val_loss: 22.7437\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.0849 - val_loss: 23.3766\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.6538 - val_loss: 24.7738\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.3805 - val_loss: 23.6145\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.9228 - val_loss: 23.9058\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.1522 - val_loss: 23.8434\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.9441 - val_loss: 24.1542\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.3268 - val_loss: 24.2010\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.2459 - val_loss: 23.2315\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.1836 - val_loss: 23.2179\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.8451 - val_loss: 23.9862\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.8529 - val_loss: 22.3867\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.9245 - val_loss: 23.8106\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.0242 - val_loss: 23.5884\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.9097 - val_loss: 23.1278\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.7693 - val_loss: 23.9706\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.6932 - val_loss: 23.5662\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.0388 - val_loss: 22.9274\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1216 - val_loss: 22.7964\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.8185 - val_loss: 23.5937\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.8885 - val_loss: 23.7161\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.2854 - val_loss: 23.2062\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.0079 - val_loss: 22.6924\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.0611 - val_loss: 22.8315\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.3070 - val_loss: 23.9918\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.3715 - val_loss: 26.9594\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.7189 - val_loss: 23.6002\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.8507 - val_loss: 22.6736\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.6091 - val_loss: 24.8649\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8765 - val_loss: 23.2691\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.9699 - val_loss: 25.1090\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.9907 - val_loss: 24.8850\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 19.0673 - val_loss: 22.6903\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1899 - val_loss: 22.8750\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.4674 - val_loss: 23.5565\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.7787 - val_loss: 23.1890\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.9932 - val_loss: 22.6741\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.2515 - val_loss: 22.7233\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.8738 - val_loss: 22.8028\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6427 - val_loss: 23.1425\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.9940 - val_loss: 23.1688\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.6136 - val_loss: 22.7189\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.4061 - val_loss: 24.2590\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.8680 - val_loss: 23.0748\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.8205 - val_loss: 22.6506\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.7865 - val_loss: 22.9600\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.3293 - val_loss: 22.1240\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.9073 - val_loss: 22.9223\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 19.0381 - val_loss: 22.3542\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.5673 - val_loss: 23.2238\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.2303 - val_loss: 22.8776\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.8105 - val_loss: 22.6999\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.0448 - val_loss: 22.7569\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.7356 - val_loss: 23.7458\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.1468 - val_loss: 23.0286\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 19.0548 - val_loss: 22.4586\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.1570 - val_loss: 23.4980\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.5348 - val_loss: 22.7399\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.9811 - val_loss: 22.9987\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4088 - val_loss: 22.5339\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4345 - val_loss: 22.1062\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.9363 - val_loss: 22.8218\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.1018 - val_loss: 23.0164\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.9303 - val_loss: 22.5829\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.2291 - val_loss: 24.2455\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.4107 - val_loss: 23.1142\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.4068 - val_loss: 24.6883\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.0778 - val_loss: 22.6895\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.0260 - val_loss: 24.1620\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.7437 - val_loss: 24.0250\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.9188 - val_loss: 24.4730\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.7633 - val_loss: 24.3822\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.9601 - val_loss: 25.3082\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1031 - val_loss: 24.1337\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.9048 - val_loss: 23.5310\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8056 - val_loss: 23.0453\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4636 - val_loss: 24.0148\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.0413 - val_loss: 22.9849\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.8188 - val_loss: 23.2270\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6956 - val_loss: 24.0233\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6531 - val_loss: 23.2597\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.7588 - val_loss: 25.6551\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.3981 - val_loss: 24.5250\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.9710 - val_loss: 23.6786\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3845 - val_loss: 23.9884\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.8116 - val_loss: 23.4587\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.8927 - val_loss: 23.2676\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.1656 - val_loss: 23.2021\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6201 - val_loss: 23.3595\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.9374 - val_loss: 23.3320\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.5626 - val_loss: 22.6266\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3797 - val_loss: 23.0680\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1434 - val_loss: 22.9403\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.2409 - val_loss: 23.0005\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.5643 - val_loss: 23.5100\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.5123 - val_loss: 25.0889\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.2229 - val_loss: 24.5243\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.7619 - val_loss: 24.6703\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.1780 - val_loss: 23.4972\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.3327 - val_loss: 24.4454\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.1516 - val_loss: 23.3452\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.6979 - val_loss: 22.6251\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.7496 - val_loss: 23.4350\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.8407 - val_loss: 25.5237\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.6714 - val_loss: 24.3675\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 18.9927 - val_loss: 23.4030\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.4394 - val_loss: 23.8967\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 19.2516 - val_loss: 22.7531\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 19.2544 - val_loss: 25.6530\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.3964 - val_loss: 22.3665\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.8963 - val_loss: 22.6622\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 18.0826 - val_loss: 23.6176\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 19.0220 - val_loss: 25.1169\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.1136 - val_loss: 22.5405\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5921 - val_loss: 23.1271\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.3756 - val_loss: 23.5995\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.3999 - val_loss: 22.5092\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1062 - val_loss: 23.7656\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.5858 - val_loss: 25.2346\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.5404 - val_loss: 22.6747\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.2108 - val_loss: 24.4355\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.0002 - val_loss: 22.3079\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.5195 - val_loss: 24.8953\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.9780 - val_loss: 22.7398\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.6524 - val_loss: 22.7891\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.2215 - val_loss: 22.8295\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.4502 - val_loss: 24.8425\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 18.9230 - val_loss: 22.7429\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 18.3539 - val_loss: 22.8713\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6509 - val_loss: 23.5971\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.8609 - val_loss: 22.7539\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.5156 - val_loss: 22.8486\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3829 - val_loss: 24.8293\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.6763 - val_loss: 22.9480\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.7272 - val_loss: 24.7040\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6125 - val_loss: 22.9788\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.7624 - val_loss: 23.7740\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3750 - val_loss: 23.1454\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 18.9791 - val_loss: 23.4523\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.5649 - val_loss: 22.2738\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.3117 - val_loss: 24.3252\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2575 - val_loss: 23.8781\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5213 - val_loss: 25.6377\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.4916 - val_loss: 24.0783\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 19.9318 - val_loss: 24.2658\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6670 - val_loss: 22.9967\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1602 - val_loss: 22.2990\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.5764 - val_loss: 22.6039\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 20.0292 - val_loss: 25.8163\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2062 - val_loss: 24.0510\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6933 - val_loss: 22.5921\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5158 - val_loss: 23.2071\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1988 - val_loss: 22.5120\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.7961 - val_loss: 23.2421\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1392 - val_loss: 22.9190\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7528 - val_loss: 24.9540\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.4500 - val_loss: 23.4237\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.4643 - val_loss: 24.5750\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4608 - val_loss: 22.7385\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1042 - val_loss: 24.2547\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1791 - val_loss: 22.5244\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2573 - val_loss: 23.0831\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2296 - val_loss: 23.4895\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.8722 - val_loss: 23.0469\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2649 - val_loss: 22.7418\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.9590 - val_loss: 25.4791\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4485 - val_loss: 23.2189\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3225 - val_loss: 24.1470\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4813 - val_loss: 22.8017\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2507 - val_loss: 23.1193\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0787 - val_loss: 22.8279\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.9265 - val_loss: 23.2899\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.2834 - val_loss: 25.4939\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.2766 - val_loss: 24.6290\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4737 - val_loss: 22.3677\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4505 - val_loss: 24.5537\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.3514 - val_loss: 23.0168\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.7011 - val_loss: 23.3123\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4004 - val_loss: 23.0896\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0036 - val_loss: 24.7471\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0089 - val_loss: 24.0889\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1216 - val_loss: 25.2410\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.4518 - val_loss: 23.0331\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.8635 - val_loss: 25.5681\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.8592 - val_loss: 24.1736\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.0623 - val_loss: 24.6744\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3807 - val_loss: 23.6403\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3317 - val_loss: 27.0797\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.6469 - val_loss: 22.6450\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4884 - val_loss: 22.5665\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 18.4072 - val_loss: 23.0619\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.6805 - val_loss: 23.0384\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4703 - val_loss: 23.3654\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.6454 - val_loss: 24.0682\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9969 - val_loss: 23.1223\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.8298 - val_loss: 26.3107\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6645 - val_loss: 22.9194\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4009 - val_loss: 23.2715\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.6325 - val_loss: 23.8115\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.5159 - val_loss: 24.5514\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2594 - val_loss: 23.9455\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4555 - val_loss: 23.5086\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 19.0871 - val_loss: 23.5200\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1325 - val_loss: 23.2488\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.5880 - val_loss: 24.2998\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.9830 - val_loss: 23.5268\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4581 - val_loss: 22.6854\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.3902 - val_loss: 25.6063\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.3460 - val_loss: 25.4397\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.1229 - val_loss: 23.7785\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4349 - val_loss: 22.2723\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7191 - val_loss: 24.0366\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8103 - val_loss: 23.0825\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8685 - val_loss: 22.8581\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9227 - val_loss: 24.1632\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9420 - val_loss: 23.6003\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.3839 - val_loss: 28.8410\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.9013 - val_loss: 23.6564\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.5442 - val_loss: 24.2301\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7032 - val_loss: 23.5517\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.4780 - val_loss: 22.5740\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.5622 - val_loss: 23.9177\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0434 - val_loss: 23.4499\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7283 - val_loss: 24.7386\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6930 - val_loss: 24.7585\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.1605 - val_loss: 25.3471\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4062 - val_loss: 24.0604\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1175 - val_loss: 23.8415\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.7108 - val_loss: 24.2629\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.5200 - val_loss: 23.4959\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0747 - val_loss: 22.9351\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.7883 - val_loss: 22.9617\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6108 - val_loss: 25.0757\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.2707 - val_loss: 24.3230\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3912 - val_loss: 24.3810\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9009 - val_loss: 23.2168\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.4940 - val_loss: 23.1770\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4218 - val_loss: 22.7192\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4682 - val_loss: 23.2567\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8338 - val_loss: 23.7470\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0559 - val_loss: 24.5183\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9794 - val_loss: 25.0158\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5039 - val_loss: 24.9859\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3552 - val_loss: 23.3419\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9432 - val_loss: 23.1651\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2729 - val_loss: 25.2939\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.8897 - val_loss: 22.8489\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3278 - val_loss: 23.3210\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.5049 - val_loss: 22.8946\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8715 - val_loss: 24.4599\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1135 - val_loss: 24.0514\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2838 - val_loss: 22.6400\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8442 - val_loss: 23.4432\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0737 - val_loss: 23.0989\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3108 - val_loss: 23.4530\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8166 - val_loss: 23.9698\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4381 - val_loss: 24.8478\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7881 - val_loss: 23.1262\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.0540 - val_loss: 23.4837\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7296 - val_loss: 23.0830\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4212 - val_loss: 23.0244\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1968 - val_loss: 23.3109\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9452 - val_loss: 23.9407\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6817 - val_loss: 25.2144\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2654 - val_loss: 22.9261\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.5310 - val_loss: 23.5775\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3973 - val_loss: 26.5144\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.9805 - val_loss: 23.3335\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.9413 - val_loss: 22.5435\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.9679 - val_loss: 23.9087\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.1515 - val_loss: 23.9116\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6672 - val_loss: 23.1542\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.7669 - val_loss: 24.6814\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 18.3133 - val_loss: 23.1257\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 17.8130 - val_loss: 23.2116\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8398 - val_loss: 24.5055\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.3137 - val_loss: 23.2957\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.3944 - val_loss: 23.7244\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.2840 - val_loss: 23.5527\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.8776 - val_loss: 22.8188\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6979 - val_loss: 22.5437\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.6074 - val_loss: 23.5640\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6054 - val_loss: 22.9231\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.3607 - val_loss: 26.0013\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0673 - val_loss: 24.3415\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8108 - val_loss: 23.0063\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2240 - val_loss: 23.8659\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3665 - val_loss: 22.6905\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7392 - val_loss: 23.8668\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8619 - val_loss: 22.7684\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8444 - val_loss: 24.9580\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3181 - val_loss: 23.9810\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.1144 - val_loss: 22.6369\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8886 - val_loss: 23.9240\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8195 - val_loss: 23.4831\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0648 - val_loss: 22.6702\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5309 - val_loss: 23.9151\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4876 - val_loss: 23.4812\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9491 - val_loss: 22.5340\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9193 - val_loss: 22.9767\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2169 - val_loss: 23.8460\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6169 - val_loss: 23.3359\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9468 - val_loss: 23.5425\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1809 - val_loss: 23.4513\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8960 - val_loss: 23.6722\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3579 - val_loss: 23.2851\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2910 - val_loss: 22.7487\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6014 - val_loss: 24.6739\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4770 - val_loss: 23.8358\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4289 - val_loss: 23.1404\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4496 - val_loss: 23.9106\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7381 - val_loss: 23.9801\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.7700 - val_loss: 23.1179\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6492 - val_loss: 23.0942\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0256 - val_loss: 22.5281\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.5123 - val_loss: 28.0903\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0171 - val_loss: 23.5056\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1760 - val_loss: 24.4830\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.7760 - val_loss: 23.7153\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7506 - val_loss: 24.8131\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8460 - val_loss: 24.5992\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0526 - val_loss: 25.3702\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1585 - val_loss: 22.6609\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.9792 - val_loss: 22.7713\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.6052 - val_loss: 22.5957\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.2014 - val_loss: 23.4479\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0992 - val_loss: 22.2460\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8174 - val_loss: 23.9729\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2432 - val_loss: 25.4269\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.7223 - val_loss: 24.9758\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5318 - val_loss: 24.4655\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2338 - val_loss: 23.3192\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5209 - val_loss: 23.8350\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5687 - val_loss: 27.9491\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.9354 - val_loss: 23.4656\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.5630 - val_loss: 23.2810\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 17.4748 - val_loss: 22.6295\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.6390 - val_loss: 23.5490\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.1887 - val_loss: 22.9389\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9882 - val_loss: 24.7617\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8845 - val_loss: 23.3189\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1074 - val_loss: 23.6254\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.5171 - val_loss: 23.6939\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 17.8575 - val_loss: 22.5530\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 18.1544 - val_loss: 25.0966\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4880 - val_loss: 23.1423\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7989 - val_loss: 23.1168\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0250 - val_loss: 23.4978\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1473 - val_loss: 24.1434\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4902 - val_loss: 22.9196\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.7807 - val_loss: 24.3811\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8965 - val_loss: 23.8314\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1295 - val_loss: 24.9092\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0051 - val_loss: 24.9828\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8026 - val_loss: 23.3088\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.7254 - val_loss: 22.5407\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5701 - val_loss: 22.5583\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6405 - val_loss: 22.6236\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.2227 - val_loss: 24.2064\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3835 - val_loss: 22.8357\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9412 - val_loss: 23.3632\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1081 - val_loss: 22.9980\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 17.4442 - val_loss: 22.7871\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.6708 - val_loss: 22.4946\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.2531 - val_loss: 22.5870\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3410 - val_loss: 23.8493\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4357 - val_loss: 23.7989\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7869 - val_loss: 23.4778\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0692 - val_loss: 25.7174\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0365 - val_loss: 22.6695\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5108 - val_loss: 23.4313\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2508 - val_loss: 22.8538\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8705 - val_loss: 21.9532\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0338 - val_loss: 23.5188\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 19.1186 - val_loss: 24.2807\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6086 - val_loss: 22.3605\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7598 - val_loss: 23.2396\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6751 - val_loss: 25.2755\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.6563 - val_loss: 23.0365\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7033 - val_loss: 22.1406\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0282 - val_loss: 24.3561\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4081 - val_loss: 26.6378\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.0758 - val_loss: 23.3238\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 18.3436 - val_loss: 23.9068\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.0368 - val_loss: 23.2585\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7584 - val_loss: 23.4782\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1621 - val_loss: 24.6760\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.6350 - val_loss: 23.4297\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6576 - val_loss: 23.7200\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.1244 - val_loss: 23.4663\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5154 - val_loss: 22.7873\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8650 - val_loss: 23.3411\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3187 - val_loss: 22.4436\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0803 - val_loss: 22.2950\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7219 - val_loss: 23.3035\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.6336 - val_loss: 22.5061\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6454 - val_loss: 23.1093\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.3740 - val_loss: 24.1708\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8848 - val_loss: 23.2337\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6579 - val_loss: 23.9163\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8051 - val_loss: 21.9372\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0299 - val_loss: 22.8309\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.0239 - val_loss: 23.2080\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6291 - val_loss: 22.3529\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4593 - val_loss: 22.5602\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8284 - val_loss: 21.9672\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.7853 - val_loss: 22.7254\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9263 - val_loss: 22.2671\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7776 - val_loss: 23.5655\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2641 - val_loss: 23.0775\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7651 - val_loss: 22.5639\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6228 - val_loss: 22.1790\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2151 - val_loss: 22.6853\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9374 - val_loss: 22.9386\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8517 - val_loss: 22.5514\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7488 - val_loss: 24.1207\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3500 - val_loss: 22.4093\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8777 - val_loss: 22.6309\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0367 - val_loss: 23.7778\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9560 - val_loss: 25.1645\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3669 - val_loss: 26.3017\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6839 - val_loss: 23.5930\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9772 - val_loss: 22.8153\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1659 - val_loss: 22.8284\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6718 - val_loss: 23.4170\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3909 - val_loss: 22.4562\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8865 - val_loss: 23.1883\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2471 - val_loss: 23.6524\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1651 - val_loss: 23.3147\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9208 - val_loss: 22.6855\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9704 - val_loss: 24.2911\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4995 - val_loss: 22.7931\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.3902 - val_loss: 23.9427\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.6646 - val_loss: 22.6477\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.6826 - val_loss: 24.5530\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1797 - val_loss: 22.8439\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1474 - val_loss: 23.6320\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1211 - val_loss: 26.6885\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4613 - val_loss: 23.6197\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2372 - val_loss: 22.8158\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.6093 - val_loss: 22.8337\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 18.0799 - val_loss: 25.8843\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.8032 - val_loss: 23.1059\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.7416 - val_loss: 25.8039\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.9802 - val_loss: 23.3363\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 18.2928 - val_loss: 22.9523\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 18.8211 - val_loss: 25.9060\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5341 - val_loss: 23.6220\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6120 - val_loss: 22.6214\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.9440 - val_loss: 23.6560\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.1073 - val_loss: 23.8602\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1016 - val_loss: 23.8145\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9415 - val_loss: 22.8116\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8899 - val_loss: 22.7361\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.5581 - val_loss: 25.4023\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0289 - val_loss: 22.4304\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0158 - val_loss: 23.5731\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.1797 - val_loss: 22.1613\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.0387 - val_loss: 24.3455\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8670 - val_loss: 23.6091\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7117 - val_loss: 23.0589\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.9379 - val_loss: 25.0107\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5518 - val_loss: 21.8294\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.0881 - val_loss: 23.0157\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3827 - val_loss: 24.1294\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9750 - val_loss: 22.9411\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.7369 - val_loss: 22.9977\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3306 - val_loss: 23.6990\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.3268 - val_loss: 24.3728\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.5228 - val_loss: 22.2604\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0702 - val_loss: 21.9072\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4877 - val_loss: 22.3541\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7982 - val_loss: 24.4066\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6606 - val_loss: 23.1503\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.4292 - val_loss: 23.5935\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.6762 - val_loss: 23.4114\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.7911 - val_loss: 23.1518\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8775 - val_loss: 23.2163\n",
      "Epoch 517/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8326 - val_loss: 22.3217\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3703 - val_loss: 23.3419\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4178 - val_loss: 25.0780\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3307 - val_loss: 22.3041\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.2311 - val_loss: 21.9199\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6816 - val_loss: 22.3800\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6691 - val_loss: 22.3810\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.6215 - val_loss: 23.4299\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.5407 - val_loss: 23.3382\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1803 - val_loss: 24.2047\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1767 - val_loss: 21.7998\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3672 - val_loss: 24.2075\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5522 - val_loss: 23.0374\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.7117 - val_loss: 23.6380\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9348 - val_loss: 22.7032\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9746 - val_loss: 23.2887\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5342 - val_loss: 23.2710\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4893 - val_loss: 23.5181\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0157 - val_loss: 22.8424\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7941 - val_loss: 22.6173\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0075 - val_loss: 21.9416\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5644 - val_loss: 22.5310\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6397 - val_loss: 24.3741\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9304 - val_loss: 22.3187\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.6776 - val_loss: 23.3066\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8715 - val_loss: 23.0063\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2028 - val_loss: 22.3518\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5536 - val_loss: 23.9258\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6186 - val_loss: 22.7732\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2778 - val_loss: 21.9031\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.4129 - val_loss: 23.0799\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7627 - val_loss: 22.6681\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8579 - val_loss: 22.8803\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.1311 - val_loss: 24.1101\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8668 - val_loss: 25.3637\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.0014 - val_loss: 25.0246\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.8555 - val_loss: 22.4757\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9698 - val_loss: 24.8054\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6464 - val_loss: 22.9516\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4118 - val_loss: 25.1890\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7906 - val_loss: 25.7906\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6323 - val_loss: 24.5107\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0341 - val_loss: 22.5533\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6511 - val_loss: 23.4335\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5460 - val_loss: 22.9741\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6172 - val_loss: 22.6894\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0105 - val_loss: 25.3581\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8600 - val_loss: 22.7272\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3942 - val_loss: 22.5430\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6338 - val_loss: 23.4024\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7793 - val_loss: 24.2702\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1268 - val_loss: 23.2550\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5414 - val_loss: 22.4893\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7241 - val_loss: 23.3745\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5863 - val_loss: 24.5018\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8801 - val_loss: 22.5991\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2082 - val_loss: 25.0114\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6130 - val_loss: 22.5437\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0425 - val_loss: 22.8191\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7459 - val_loss: 23.0745\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4099 - val_loss: 23.0855\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9565 - val_loss: 22.2299\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.7460 - val_loss: 22.7496\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3456 - val_loss: 24.2379\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.0130 - val_loss: 23.5620\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.4981 - val_loss: 22.5808\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7209 - val_loss: 23.0008\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8587 - val_loss: 24.6285\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3724 - val_loss: 23.3954\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8929 - val_loss: 23.2032\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4001 - val_loss: 23.8065\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8835 - val_loss: 22.3916\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4202 - val_loss: 26.4307\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.7105 - val_loss: 22.4390\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5101 - val_loss: 25.4059\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1149 - val_loss: 23.2457\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2934 - val_loss: 23.1497\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6739 - val_loss: 24.1724\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.4280 - val_loss: 22.2595\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5628 - val_loss: 24.6862\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9599 - val_loss: 23.9743\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7033 - val_loss: 24.3566\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9249 - val_loss: 23.3226\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.6888 - val_loss: 22.6753\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.0627 - val_loss: 23.0734\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0434 - val_loss: 25.4197\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0703 - val_loss: 22.2682\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6872 - val_loss: 22.9635\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.2045 - val_loss: 23.3883\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.5497 - val_loss: 23.0296\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.3081 - val_loss: 22.3453\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4888 - val_loss: 23.1710\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4340 - val_loss: 23.9052\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3397 - val_loss: 22.8190\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4211 - val_loss: 22.3439\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7628 - val_loss: 23.2673\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2201 - val_loss: 26.5533\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.5865 - val_loss: 22.3593\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1929 - val_loss: 22.5665\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4635 - val_loss: 23.3409\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.3731 - val_loss: 23.2186\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.6301 - val_loss: 23.1014\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6964 - val_loss: 23.4029\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1728 - val_loss: 23.3727\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.2146 - val_loss: 21.8854\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6234 - val_loss: 23.7861\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0077 - val_loss: 22.5571\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3335 - val_loss: 22.9080\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3082 - val_loss: 24.2362\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6679 - val_loss: 25.2539\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7812 - val_loss: 23.4495\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0079 - val_loss: 23.3489\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9995 - val_loss: 22.5269\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.5212 - val_loss: 24.1211\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5352 - val_loss: 23.1486\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7584 - val_loss: 22.2151\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9737 - val_loss: 23.1274\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7023 - val_loss: 22.0497\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.5817 - val_loss: 22.6683\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.1184 - val_loss: 22.1866\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1196 - val_loss: 22.6220\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5895 - val_loss: 22.6015\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.0128 - val_loss: 28.0402\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.7036 - val_loss: 24.4077\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3677 - val_loss: 24.1067\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2997 - val_loss: 24.0620\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4368 - val_loss: 22.4990\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8085 - val_loss: 24.9851\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1987 - val_loss: 23.4044\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.9444 - val_loss: 23.8144\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 18.0581 - val_loss: 24.5487\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.3840 - val_loss: 22.6122\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 18.0739 - val_loss: 22.1975\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.9558 - val_loss: 23.0122\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.5759 - val_loss: 23.1243\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.4126 - val_loss: 23.5955\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.5397 - val_loss: 25.1370\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.5419 - val_loss: 23.4246\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0783 - val_loss: 22.3964\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8835 - val_loss: 23.1642\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0085 - val_loss: 23.0833\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7495 - val_loss: 23.5203\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5478 - val_loss: 23.1224\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8424 - val_loss: 24.5443\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8721 - val_loss: 22.8414\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.7562 - val_loss: 24.7754\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5721 - val_loss: 22.3185\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4525 - val_loss: 23.0440\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8340 - val_loss: 22.5576\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3859 - val_loss: 23.1242\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6163 - val_loss: 24.1397\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.7327 - val_loss: 23.0409\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.1708 - val_loss: 31.2594\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.3789 - val_loss: 22.5693\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6043 - val_loss: 23.2503\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8093 - val_loss: 23.2026\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5502 - val_loss: 23.9883\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6628 - val_loss: 23.3305\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7665 - val_loss: 22.7691\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1053 - val_loss: 22.4418\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.0481 - val_loss: 22.4840\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6858 - val_loss: 24.7811\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4787 - val_loss: 22.9407\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8423 - val_loss: 22.5132\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.5787 - val_loss: 22.9972\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5259 - val_loss: 22.8935\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1878 - val_loss: 23.2454\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2299 - val_loss: 23.7450\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.9505 - val_loss: 23.0155\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4471 - val_loss: 22.2155\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8167 - val_loss: 22.2215\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5336 - val_loss: 22.5229\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.0123 - val_loss: 24.5013\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8771 - val_loss: 22.4326\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.7523 - val_loss: 22.5823\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.8883 - val_loss: 23.8171\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5110 - val_loss: 24.3242\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9029 - val_loss: 23.2877\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9706 - val_loss: 23.5161\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7938 - val_loss: 22.5708\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.9340 - val_loss: 24.5803\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4461 - val_loss: 24.2372\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9613 - val_loss: 24.2302\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3423 - val_loss: 22.4463\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.9571 - val_loss: 24.1734\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.7016 - val_loss: 24.0737\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9064 - val_loss: 22.4971\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8213 - val_loss: 23.2567\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0705 - val_loss: 24.2146\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7558 - val_loss: 22.5971\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6591 - val_loss: 25.1204\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.0347 - val_loss: 22.2875\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.2047 - val_loss: 22.4382\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4328 - val_loss: 22.5852\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8982 - val_loss: 23.1402\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.4689 - val_loss: 23.5429\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7680 - val_loss: 22.7930\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8618 - val_loss: 23.4943\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7267 - val_loss: 23.2614\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8578 - val_loss: 26.0344\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0765 - val_loss: 22.7165\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.2461 - val_loss: 23.4803\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.6094 - val_loss: 22.3965\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2342 - val_loss: 23.5407\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4525 - val_loss: 23.7397\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3063 - val_loss: 25.1421\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.2049 - val_loss: 25.2438\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.9861 - val_loss: 23.0784\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.7147 - val_loss: 22.3071\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9596 - val_loss: 22.9299\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4189 - val_loss: 30.4822\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.1379 - val_loss: 22.6147\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3858 - val_loss: 24.2836\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6024 - val_loss: 24.1874\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.6297 - val_loss: 24.1348\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7577 - val_loss: 24.3666\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7819 - val_loss: 23.0758\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1634 - val_loss: 22.2190\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5481 - val_loss: 22.4691\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3457 - val_loss: 22.7813\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1100 - val_loss: 22.7626\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4350 - val_loss: 22.6000\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.3265 - val_loss: 24.2002\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.8284 - val_loss: 23.4047\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.3183 - val_loss: 24.4367\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4524 - val_loss: 23.8550\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.9867 - val_loss: 23.6623\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3689 - val_loss: 23.3000\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0193 - val_loss: 22.5045\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4881 - val_loss: 23.0956\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9758 - val_loss: 22.0127\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5869 - val_loss: 22.0602\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4085 - val_loss: 22.5778\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5721 - val_loss: 23.1412\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9680 - val_loss: 22.7260\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5470 - val_loss: 24.0354\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6055 - val_loss: 23.3532\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.0628 - val_loss: 22.5479\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7771 - val_loss: 23.4210\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6872 - val_loss: 22.9414\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5344 - val_loss: 22.8452\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1250 - val_loss: 29.2534\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.2213 - val_loss: 23.1144\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5033 - val_loss: 23.5835\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8748 - val_loss: 24.5261\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4944 - val_loss: 22.7129\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7104 - val_loss: 23.0789\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4744 - val_loss: 24.1616\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7477 - val_loss: 22.9980\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.3173 - val_loss: 24.3861\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8851 - val_loss: 22.3012\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5221 - val_loss: 22.8627\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7299 - val_loss: 22.3537\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9002 - val_loss: 22.1224\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0759 - val_loss: 23.2971\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.3858 - val_loss: 22.5406\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8230 - val_loss: 23.9151\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4241 - val_loss: 22.6975\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9985 - val_loss: 23.0712\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7960 - val_loss: 22.7575\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8999 - val_loss: 24.1549\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.3221 - val_loss: 27.0119\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0948 - val_loss: 22.5825\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2541 - val_loss: 22.2290\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9848 - val_loss: 24.0916\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5640 - val_loss: 22.7041\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4515 - val_loss: 23.6050\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9879 - val_loss: 23.3859\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4703 - val_loss: 22.7556\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8121 - val_loss: 25.2064\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3154 - val_loss: 22.5293\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4796 - val_loss: 22.9226\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5577 - val_loss: 22.2814\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0795 - val_loss: 23.1416\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6443 - val_loss: 22.6612\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6021 - val_loss: 23.5227\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7628 - val_loss: 22.6343\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.7112 - val_loss: 23.3529\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4822 - val_loss: 23.7323\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8097 - val_loss: 26.1674\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4993 - val_loss: 24.3883\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.1306 - val_loss: 24.2288\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1420 - val_loss: 23.8312\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6812 - val_loss: 23.6584\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.7574 - val_loss: 26.1075\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.6749 - val_loss: 23.1193\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5825 - val_loss: 24.4604\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1508 - val_loss: 22.7310\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6841 - val_loss: 22.7816\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4524 - val_loss: 22.3428\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.4169 - val_loss: 24.4605\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4174 - val_loss: 23.5393\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7136 - val_loss: 21.8972\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5645 - val_loss: 23.1204\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6395 - val_loss: 23.8256\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0234 - val_loss: 24.0178\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7301 - val_loss: 22.6139\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.9049 - val_loss: 23.0978\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 18.0164 - val_loss: 21.7951\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.2984 - val_loss: 22.2258\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.5731 - val_loss: 23.9988\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.5288 - val_loss: 22.1363\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.6424 - val_loss: 24.1391\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.7341 - val_loss: 23.8850\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.8150 - val_loss: 26.1230\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.8896 - val_loss: 22.7722\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 18.4015 - val_loss: 26.4955\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2239 - val_loss: 24.1581\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6421 - val_loss: 22.6474\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.2527 - val_loss: 23.3155\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7790 - val_loss: 22.8991\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4986 - val_loss: 22.2308\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1204 - val_loss: 23.4151\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 18.48 - 0s 87us/step - loss: 18.1737 - val_loss: 24.3206\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.7331 - val_loss: 22.8994\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8618 - val_loss: 23.4607\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.8405 - val_loss: 22.2853\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3434 - val_loss: 23.8225\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3778 - val_loss: 23.2503\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5550 - val_loss: 23.0097\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7991 - val_loss: 22.9558\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4552 - val_loss: 24.5344\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.8254 - val_loss: 23.1721\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0579 - val_loss: 22.7130\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7349 - val_loss: 22.1368\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5348 - val_loss: 24.0201\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0423 - val_loss: 23.3390\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8598 - val_loss: 25.2008\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5280 - val_loss: 23.5660\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2931 - val_loss: 23.7469\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9331 - val_loss: 23.8581\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.7507 - val_loss: 22.6440\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.1323 - val_loss: 24.0158\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.7588 - val_loss: 23.3932\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5019 - val_loss: 22.2275\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1028 - val_loss: 23.3285\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8099 - val_loss: 23.1211\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7285 - val_loss: 24.4211\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7852 - val_loss: 25.4184\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.3439 - val_loss: 22.5208\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.5746 - val_loss: 23.2943\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5850 - val_loss: 24.1389\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4322 - val_loss: 22.7147\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5919 - val_loss: 22.6025\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.8251 - val_loss: 24.0024\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1602 - val_loss: 23.4992\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.8980 - val_loss: 22.8197\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1187 - val_loss: 23.7386\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8212 - val_loss: 23.1909\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9551 - val_loss: 23.5313\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.3329 - val_loss: 22.4241\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6738 - val_loss: 25.3682\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.5650 - val_loss: 23.2476\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.2088 - val_loss: 23.9577\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5985 - val_loss: 23.6585\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8534 - val_loss: 24.9883\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9034 - val_loss: 22.8177\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6558 - val_loss: 22.2954\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7041 - val_loss: 22.2843\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4446 - val_loss: 23.8762\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8157 - val_loss: 23.7128\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.5067 - val_loss: 24.1886\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.3940 - val_loss: 23.6044\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3403 - val_loss: 22.9655\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.6824 - val_loss: 25.8491\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0990 - val_loss: 22.6892\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.4706 - val_loss: 22.9094\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8718 - val_loss: 21.8675\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5373 - val_loss: 22.7403\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.0445 - val_loss: 22.3229\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8681 - val_loss: 25.4569\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.1834 - val_loss: 23.7944\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.6861 - val_loss: 22.4683\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4267 - val_loss: 22.1475\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2604 - val_loss: 23.6105\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.4374 - val_loss: 24.1421\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.7899 - val_loss: 23.1036\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6469 - val_loss: 25.4508\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.9692 - val_loss: 22.6275\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.1545 - val_loss: 23.9534\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4990 - val_loss: 22.6944\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1235 - val_loss: 22.5012\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2697 - val_loss: 23.4017\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1736 - val_loss: 24.2999\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.5235 - val_loss: 23.6094\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1190 - val_loss: 22.7799\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6208 - val_loss: 22.4253\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6570 - val_loss: 22.7229\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6998 - val_loss: 22.8946\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0747 - val_loss: 24.5112\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8306 - val_loss: 23.2971\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7399 - val_loss: 23.2579\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5282 - val_loss: 21.8265\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5718 - val_loss: 22.2539\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3149 - val_loss: 22.7210\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3211 - val_loss: 23.5515\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6877 - val_loss: 23.2794\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.7579 - val_loss: 26.2206\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.7889 - val_loss: 23.5704\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0299 - val_loss: 22.9785\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1980 - val_loss: 22.6647\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3151 - val_loss: 23.7984\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9065 - val_loss: 22.5016\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4550 - val_loss: 22.8187\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5287 - val_loss: 23.5398\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6836 - val_loss: 23.4750\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8269 - val_loss: 24.1065\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.2101 - val_loss: 23.6880\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3151 - val_loss: 22.5867\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3432 - val_loss: 23.6094\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.9638 - val_loss: 23.1941\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8081 - val_loss: 22.7783\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3888 - val_loss: 24.5761\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3144 - val_loss: 23.9261\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 18.1540 - val_loss: 23.3121\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.3255 - val_loss: 22.5798\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.8690 - val_loss: 22.5702\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.0501 - val_loss: 23.2391\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 17.8087 - val_loss: 23.4811\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0933 - val_loss: 25.1260\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1630 - val_loss: 26.1726\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 18.5364 - val_loss: 23.8589\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 17.7184 - val_loss: 22.5198\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 17.6176 - val_loss: 22.7058\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.5038 - val_loss: 22.6637\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.5995 - val_loss: 22.9507\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 18.3864 - val_loss: 22.8703\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.1965 - val_loss: 22.8231\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6486 - val_loss: 24.9369\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.7735 - val_loss: 25.8618\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.3922 - val_loss: 22.1381\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5983 - val_loss: 24.1395\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2560 - val_loss: 23.1534\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6972 - val_loss: 25.2767\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.4336 - val_loss: 24.6427\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2584 - val_loss: 25.9359\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5418 - val_loss: 24.2013\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0555 - val_loss: 22.8487\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.4324 - val_loss: 22.4932\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.1882 - val_loss: 22.9634\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1229 - val_loss: 23.0258\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.6923 - val_loss: 24.6180\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.5377 - val_loss: 22.4451\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.0451 - val_loss: 24.2053\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.9392 - val_loss: 23.3292\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8338 - val_loss: 23.9326\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5331 - val_loss: 22.9270\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8516 - val_loss: 26.2850\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.7722 - val_loss: 22.3316\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8051 - val_loss: 23.9414\n",
      "Epoch 967/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4591 - val_loss: 22.2500\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4499 - val_loss: 23.3783\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6752 - val_loss: 22.7124\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6930 - val_loss: 22.8038\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.5350 - val_loss: 22.5018\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0203 - val_loss: 23.3153\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.2777 - val_loss: 22.3422\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9178 - val_loss: 23.2263\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.5177 - val_loss: 21.9174\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7048 - val_loss: 23.1597\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8926 - val_loss: 23.0901\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2916 - val_loss: 24.4561\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.1452 - val_loss: 23.2819\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7793 - val_loss: 23.4360\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.3341 - val_loss: 23.1801\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 17.7952 - val_loss: 22.3764\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.9765 - val_loss: 23.0929\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 18.1625 - val_loss: 23.1860\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 17.9293 - val_loss: 22.4090\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3849 - val_loss: 23.2166\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7420 - val_loss: 22.8001\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6407 - val_loss: 23.1152\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.6504 - val_loss: 22.3049\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1607 - val_loss: 22.5493\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7808 - val_loss: 23.7736\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5209 - val_loss: 22.3693\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7271 - val_loss: 23.9304\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.2049 - val_loss: 22.7288\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8061 - val_loss: 23.4815\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7499 - val_loss: 22.4414\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.6028 - val_loss: 22.5558\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2296 - val_loss: 23.9287\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.8712 - val_loss: 26.2022\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9494 - val_loss: 22.6259\n",
      "16.242687070264225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.4313079 , -0.5755791 ,  1.1346074 , -0.88518184,  0.43457228],\n",
       "        [ 0.10045746,  0.6870582 ,  0.04544015, -0.45137876, -0.22606158],\n",
       "        [ 1.6977961 , -1.1310892 , -0.14690782, -0.5273249 ,  0.66535527],\n",
       "        [ 0.04359696, -0.08885802, -1.7213228 ,  0.9039439 ,  0.7039312 ],\n",
       "        [ 0.5705196 ,  0.18823008, -0.25185987, -0.08480511, -0.5094209 ]],\n",
       "       dtype=float32),\n",
       " array([1.2833037, 2.9856753, 2.9979653, 3.7760198, 2.7569432],\n",
       "       dtype=float32),\n",
       " array([[-0.17001174, -0.7456337 ,  0.774461  , -0.80970097, -0.82522374,\n",
       "          0.6942219 , -0.07551395,  0.46930197,  0.94493407, -0.42742705],\n",
       "        [ 0.6941941 , -0.31660804,  1.381496  , -0.29886764, -0.38701934,\n",
       "          0.5662989 , -0.71652395,  1.3411285 , -1.558683  , -0.96018946],\n",
       "        [ 1.3507706 , -0.22618209,  1.2008104 , -1.0089983 , -0.35673243,\n",
       "          1.3853384 , -0.65936214,  0.21846403,  0.04516637, -0.913339  ],\n",
       "        [ 1.4837462 , -1.1211915 ,  1.9726819 , -0.22480687, -0.5010503 ,\n",
       "          1.8718252 , -0.46510062,  0.68632644,  1.1984361 , -0.25649154],\n",
       "        [ 1.1209185 , -0.23482567,  0.88461435, -0.40292907, -0.40390047,\n",
       "          0.8513798 , -0.87424356,  0.25868383,  0.04653121, -0.38884494]],\n",
       "       dtype=float32),\n",
       " array([ 3.83133   , -0.764589  ,  3.8496082 , -0.74268115, -0.46607757,\n",
       "         3.8449082 , -0.5807521 ,  3.8184302 ,  3.2359684 , -0.71035165],\n",
       "       dtype=float32),\n",
       " array([[ 1.3351538 ],\n",
       "        [ 0.30498895],\n",
       "        [ 1.7945716 ],\n",
       "        [ 0.36213472],\n",
       "        [ 0.02623999],\n",
       "        [ 1.6749405 ],\n",
       "        [-0.1509796 ],\n",
       "        [ 1.2979028 ],\n",
       "        [ 0.97984374],\n",
       "        [ 0.2824032 ]], dtype=float32),\n",
       " array([3.9011686], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_relu(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 213us/step - loss: 13791.7832 - val_loss: 11632.9796\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9772.4450 - val_loss: 8235.1939\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7145.3871 - val_loss: 6252.2024\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5523.5851 - val_loss: 4923.3966\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4389.8893 - val_loss: 3953.0314\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 3542.2875 - val_loss: 3213.4838\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 2886.8255 - val_loss: 2631.3285\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 2367.3597 - val_loss: 2165.5352\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 1949.7352 - val_loss: 1788.5301\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 1610.5688 - val_loss: 1481.1893\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 1333.3789 - val_loss: 1228.8547\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 1105.5053 - val_loss: 1021.2150\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 917.9772 - val_loss: 848.8789\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 762.8058 - val_loss: 706.5551\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 634.5420 - val_loss: 588.9352\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 122us/step - loss: 528.4760 - val_loss: 491.7416\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 440.8684 - val_loss: 411.0425\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 368.4956 - val_loss: 343.9803\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 308.0093 - val_loss: 286.0430\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 248.5756 - val_loss: 219.0573\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 185.4876 - val_loss: 163.4488\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 141.2332 - val_loss: 126.6742\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 122us/step - loss: 111.6743 - val_loss: 101.3160\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 91.3451 - val_loss: 84.0046\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 77.4282 - val_loss: 71.8194\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 67.5826 - val_loss: 63.3364\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 60.4851 - val_loss: 56.4514\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 53.3321 - val_loss: 49.7818\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 125us/step - loss: 46.7204 - val_loss: 44.2109\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 40.7178 - val_loss: 39.9855\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 36.9723 - val_loss: 36.6858\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 34.1271 - val_loss: 34.4480\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 31.9977 - val_loss: 32.6396\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 30.4370 - val_loss: 31.2002\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 29.2194 - val_loss: 30.0448\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 28.3123 - val_loss: 29.1602\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 27.4231 - val_loss: 28.6447\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 26.8089 - val_loss: 28.0612\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 26.3449 - val_loss: 27.5149\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 25.8375 - val_loss: 27.1931\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 25.2500 - val_loss: 25.4406\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.8342 - val_loss: 25.6258\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.4073 - val_loss: 24.2305\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 20.7649 - val_loss: 23.6286\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.7129 - val_loss: 23.0689\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.1710 - val_loss: 22.7847\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.5654 - val_loss: 22.8716\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.1689 - val_loss: 22.3266\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9131 - val_loss: 22.1668\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6381 - val_loss: 21.7681\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5117 - val_loss: 21.6732\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2571 - val_loss: 21.4673\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.0172 - val_loss: 20.8390\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.6713 - val_loss: 20.6906\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.4757 - val_loss: 20.2762\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.2486 - val_loss: 20.3839\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.9517 - val_loss: 19.9477\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.8379 - val_loss: 20.0272\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.7679 - val_loss: 19.5796\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.6699 - val_loss: 19.2538\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.4180 - val_loss: 19.1607\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.3207 - val_loss: 19.2038\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.1973 - val_loss: 18.8299\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.0546 - val_loss: 18.4724\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.9277 - val_loss: 18.2273\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.8175 - val_loss: 18.1374\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6533 - val_loss: 18.0064\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.6679 - val_loss: 17.6862\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.4701 - val_loss: 17.5783\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.4486 - val_loss: 17.6370\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3719 - val_loss: 17.5454\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2545 - val_loss: 17.6194\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2744 - val_loss: 17.3881\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2300 - val_loss: 17.3332\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2480 - val_loss: 17.3003\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.1785 - val_loss: 17.4871\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.1345 - val_loss: 17.2962\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.2151 - val_loss: 17.2983\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1298 - val_loss: 17.2947\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1318 - val_loss: 17.2005\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.1194 - val_loss: 17.3272\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1333 - val_loss: 17.5506\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.0919 - val_loss: 17.2865\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.1152 - val_loss: 17.3243\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1254 - val_loss: 17.4166\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1665 - val_loss: 17.2164\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0658 - val_loss: 17.4970\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.1190 - val_loss: 17.3987\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1054 - val_loss: 17.1809\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.1618 - val_loss: 17.2745\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.0934 - val_loss: 17.4201\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0707 - val_loss: 17.1737\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0787 - val_loss: 17.2811\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0895 - val_loss: 17.3006\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1033 - val_loss: 17.2861\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.0318 - val_loss: 17.5203\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.0495 - val_loss: 17.3260\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0551 - val_loss: 17.2284\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.1156 - val_loss: 17.3614\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.0692 - val_loss: 17.5163\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0374 - val_loss: 17.2187\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0884 - val_loss: 17.2306\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0909 - val_loss: 17.3421\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0093 - val_loss: 17.4709\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0332 - val_loss: 17.1184\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.0658 - val_loss: 17.2588\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9862 - val_loss: 17.4055\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0107 - val_loss: 17.2746\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0168 - val_loss: 17.2496\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0345 - val_loss: 17.2663\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.0003 - val_loss: 17.4293\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.0664 - val_loss: 17.4499\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1254 - val_loss: 17.2187\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9638 - val_loss: 17.2394\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9689 - val_loss: 17.4190\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9625 - val_loss: 17.5428\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.8637 - val_loss: 17.2887\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.0094 - val_loss: 17.3430\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9646 - val_loss: 17.3808\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9211 - val_loss: 17.5486\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8690 - val_loss: 17.6449\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.9278 - val_loss: 17.7862\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8881 - val_loss: 17.5539\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8389 - val_loss: 17.4714\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9217 - val_loss: 17.4067\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.0168 - val_loss: 17.5579\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8920 - val_loss: 17.5055\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.7920 - val_loss: 17.6074\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8903 - val_loss: 17.6077\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8817 - val_loss: 17.6713\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8069 - val_loss: 17.4774\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9135 - val_loss: 17.7229\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9188 - val_loss: 17.5840\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8826 - val_loss: 18.0653\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8638 - val_loss: 17.9903\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8199 - val_loss: 18.0552\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.9391 - val_loss: 17.5665\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.9353 - val_loss: 17.5124\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7924 - val_loss: 17.6537\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.7838 - val_loss: 17.8216\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 99us/step - loss: 13.7982 - val_loss: 17.6498\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 13.7532 - val_loss: 17.8397\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.8238 - val_loss: 17.4855\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.8068 - val_loss: 17.5196\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.7911 - val_loss: 17.7708\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.8288 - val_loss: 17.6457\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 13.6923 - val_loss: 18.0247\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.8014 - val_loss: 17.6107\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8079 - val_loss: 17.4782\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6828 - val_loss: 17.5788\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.7606 - val_loss: 17.7583\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.6850 - val_loss: 17.8317\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6906 - val_loss: 17.4647\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7006 - val_loss: 17.5791\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.7257 - val_loss: 17.6118\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7244 - val_loss: 17.8027\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6769 - val_loss: 17.7601\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7642 - val_loss: 17.5822\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6731 - val_loss: 17.5151\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7384 - val_loss: 17.4764\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8041 - val_loss: 17.4501\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6734 - val_loss: 17.4471\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7203 - val_loss: 17.5088\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6890 - val_loss: 17.6217\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7038 - val_loss: 17.5084\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.6645 - val_loss: 17.4907\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6600 - val_loss: 17.6206\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6569 - val_loss: 17.5990\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7423 - val_loss: 17.5309\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.6943 - val_loss: 17.5445\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6437 - val_loss: 17.5141\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6736 - val_loss: 17.3987\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.7012 - val_loss: 17.4786\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6985 - val_loss: 17.6883\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7393 - val_loss: 18.0144\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.6272 - val_loss: 17.5815\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.6140 - val_loss: 17.6876\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6471 - val_loss: 17.9244\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.7462 - val_loss: 17.8106\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6428 - val_loss: 17.7396\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.6549 - val_loss: 17.5631\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6486 - val_loss: 17.4878\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.6662 - val_loss: 17.4987\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.5020 - val_loss: 18.0186\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7279 - val_loss: 17.7570\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6031 - val_loss: 17.6175\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.6060 - val_loss: 17.5106\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6305 - val_loss: 17.4977\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 13.6457 - val_loss: 17.5646\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.6170 - val_loss: 17.8621\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6295 - val_loss: 17.5032\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.7254 - val_loss: 17.5218\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5793 - val_loss: 17.8932\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6246 - val_loss: 17.5897\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5725 - val_loss: 17.6269\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6025 - val_loss: 17.6218\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.6132 - val_loss: 17.4907\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.6564 - val_loss: 17.6147\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6442 - val_loss: 17.4972\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7310 - val_loss: 17.5202\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6414 - val_loss: 17.4804\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6047 - val_loss: 17.6829\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.5876 - val_loss: 17.6851\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.5510 - val_loss: 17.6777\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.5579 - val_loss: 17.7743\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6462 - val_loss: 17.5508\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.5664 - val_loss: 17.4990\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5560 - val_loss: 17.7520\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6027 - val_loss: 17.6584\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6167 - val_loss: 17.5617\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.5322 - val_loss: 17.5281\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.5936 - val_loss: 17.6149\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.5762 - val_loss: 17.6885\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.5203 - val_loss: 17.5508\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5165 - val_loss: 17.5210\n",
      "Epoch 216/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.5464 - val_loss: 17.5455\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5789 - val_loss: 17.5835\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5443 - val_loss: 17.6942\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5631 - val_loss: 17.5835\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.4805 - val_loss: 17.6309\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5587 - val_loss: 17.4522\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.4645 - val_loss: 17.6199\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.5112 - val_loss: 17.5227\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.5473 - val_loss: 17.7722\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.5240 - val_loss: 17.9607\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.4955 - val_loss: 17.7182\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7315 - val_loss: 17.7461\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.4889 - val_loss: 17.8079\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5235 - val_loss: 17.5899\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.4634 - val_loss: 17.5761\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5773 - val_loss: 17.8697\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.4447 - val_loss: 17.5385\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.4908 - val_loss: 17.7761\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.4452 - val_loss: 17.8593\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.4346 - val_loss: 17.5412\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.4280 - val_loss: 17.7493\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.3707 - val_loss: 17.5381\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.4435 - val_loss: 17.5678\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.3939 - val_loss: 17.5592\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.3901 - val_loss: 17.8329\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.4602 - val_loss: 17.4813\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.4014 - val_loss: 17.4168\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.3953 - val_loss: 17.4772\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.3710 - val_loss: 17.6568\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.4864 - val_loss: 17.7918\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5315 - val_loss: 17.5672\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.4146 - val_loss: 17.7692\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5104 - val_loss: 17.5295\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.3893 - val_loss: 17.7121\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.4676 - val_loss: 17.5606\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.3596 - val_loss: 17.4588\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.3084 - val_loss: 17.4144\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.2934 - val_loss: 17.6889\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.2409 - val_loss: 17.6688\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.2702 - val_loss: 17.6505\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3235 - val_loss: 17.5439\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.3271 - val_loss: 17.8110\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.3338 - val_loss: 17.9036\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.4804 - val_loss: 17.6865\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.4647 - val_loss: 17.7819\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.2212 - val_loss: 17.8685\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.3289 - val_loss: 17.8187\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.2096 - val_loss: 17.7724\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.3181 - val_loss: 17.6530\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.1700 - val_loss: 17.5938\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.1254 - val_loss: 17.8023\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.3594 - val_loss: 17.5498\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.1925 - val_loss: 17.7504\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.1690 - val_loss: 17.7558\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.2592 - val_loss: 17.7002\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.3086 - val_loss: 17.8149\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.2435 - val_loss: 17.5883\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.2041 - val_loss: 17.9223\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.1875 - val_loss: 17.7623\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1646 - val_loss: 17.8953\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.2890 - val_loss: 18.0522\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.0937 - val_loss: 18.0267\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1472 - val_loss: 18.3839\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.8106 - val_loss: 17.8963\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5709 - val_loss: 17.8067\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.5818 - val_loss: 17.9061\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.3998 - val_loss: 17.6699\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.2006 - val_loss: 17.6897\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.1751 - val_loss: 17.5391\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.1161 - val_loss: 17.3304\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0223 - val_loss: 17.3330\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.0291 - val_loss: 17.1710\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9989 - val_loss: 17.0976\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.9115 - val_loss: 17.2015\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8956 - val_loss: 16.9559\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8757 - val_loss: 16.9229\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7952 - val_loss: 16.9244\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8010 - val_loss: 16.9240\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7833 - val_loss: 16.8274\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8202 - val_loss: 16.7940\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7385 - val_loss: 16.6719\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7352 - val_loss: 16.9556\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8331 - val_loss: 16.6063\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6328 - val_loss: 16.9629\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6744 - val_loss: 16.6825\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7050 - val_loss: 16.9287\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6567 - val_loss: 16.6808\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6331 - val_loss: 16.6978\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7374 - val_loss: 16.4921\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6107 - val_loss: 16.6136\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5888 - val_loss: 16.5008\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 11.5939 - val_loss: 16.5427\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.6074 - val_loss: 16.5800\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.5475 - val_loss: 16.5137\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 11.4810 - val_loss: 16.4724\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.5920 - val_loss: 16.5102\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.5108 - val_loss: 16.3397\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.5093 - val_loss: 16.3242\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 11.4547 - val_loss: 16.2682\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.5494 - val_loss: 16.5404\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5512 - val_loss: 16.6167\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3918 - val_loss: 16.2657\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4388 - val_loss: 16.2435\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4847 - val_loss: 16.3039\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4063 - val_loss: 16.4108\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3725 - val_loss: 16.1094\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.3482 - val_loss: 16.2938\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5058 - val_loss: 16.2678\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3692 - val_loss: 16.1248\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4877 - val_loss: 16.5539\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.6034 - val_loss: 16.0981\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.3410 - val_loss: 16.1071\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.3862 - val_loss: 16.2889\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3444 - val_loss: 15.8050\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3303 - val_loss: 15.9997\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.2764 - val_loss: 15.7744\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3358 - val_loss: 15.6785\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.2002 - val_loss: 15.7317\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1503 - val_loss: 15.5399\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1921 - val_loss: 15.1331\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.9127 - val_loss: 14.5456\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9902 - val_loss: 14.9783\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9527 - val_loss: 14.4878\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 10.7351 - val_loss: 14.4417\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7276 - val_loss: 14.2789\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.6969 - val_loss: 14.2818\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6442 - val_loss: 14.2196\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6224 - val_loss: 14.2921\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.5488 - val_loss: 14.2978\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4268 - val_loss: 14.6365\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.4321 - val_loss: 13.9625\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.4859 - val_loss: 13.7465\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.3992 - val_loss: 14.0965\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4347 - val_loss: 13.8009\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2500 - val_loss: 13.7290\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.1579 - val_loss: 13.8626\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3003 - val_loss: 13.8808\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1958 - val_loss: 13.5548\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.2415 - val_loss: 13.1041\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1842 - val_loss: 13.6373\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1051 - val_loss: 13.3684\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9712 - val_loss: 13.4544\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.0051 - val_loss: 13.0420\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9329 - val_loss: 13.8559\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9370 - val_loss: 13.2704\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9653 - val_loss: 12.8812\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8779 - val_loss: 12.8040\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8755 - val_loss: 12.8624\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9305 - val_loss: 13.2380\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9021 - val_loss: 12.7314\n",
      "Epoch 366/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8133 - val_loss: 12.5023\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8148 - val_loss: 12.5707\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8500 - val_loss: 12.5359\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8281 - val_loss: 12.7353\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7885 - val_loss: 12.6341\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7690 - val_loss: 12.4292\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6666 - val_loss: 12.4237\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6780 - val_loss: 12.3492\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7215 - val_loss: 12.3602\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6175 - val_loss: 12.4037\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6151 - val_loss: 12.2464\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6265 - val_loss: 12.4815\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7284 - val_loss: 12.5173\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6486 - val_loss: 12.2161\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6118 - val_loss: 12.4133\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6472 - val_loss: 12.5430\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7101 - val_loss: 12.3766\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7173 - val_loss: 12.2396\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6187 - val_loss: 12.4371\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5483 - val_loss: 12.2328\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5182 - val_loss: 12.1563\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6225 - val_loss: 12.4162\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6030 - val_loss: 12.2260\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5872 - val_loss: 12.0659\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5174 - val_loss: 12.1122\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6988 - val_loss: 12.2632\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4876 - val_loss: 12.1633\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5072 - val_loss: 12.2021\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5514 - val_loss: 12.2766\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5283 - val_loss: 11.9989\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4835 - val_loss: 12.1123\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4668 - val_loss: 12.0566\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4701 - val_loss: 11.9315\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3891 - val_loss: 12.0208\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3625 - val_loss: 12.2233\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4566 - val_loss: 12.0101\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4759 - val_loss: 12.1498\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4972 - val_loss: 12.0809\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5278 - val_loss: 11.8483\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.3968 - 0s 89us/step - loss: 9.5213 - val_loss: 12.0341\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4246 - val_loss: 12.2304\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4359 - val_loss: 11.8840\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3515 - val_loss: 12.1530\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4211 - val_loss: 11.8203\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4341 - val_loss: 11.8584\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2907 - val_loss: 11.8083\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.3056 - val_loss: 12.1991\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4153 - val_loss: 12.1268\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3900 - val_loss: 12.0410\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4224 - val_loss: 11.7415\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2751 - val_loss: 11.6519\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3650 - val_loss: 11.8198\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2373 - val_loss: 11.8149\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3169 - val_loss: 12.0216\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3040 - val_loss: 11.8427\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3993 - val_loss: 11.9431\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3073 - val_loss: 11.7211\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2605 - val_loss: 11.8194\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3297 - val_loss: 11.8455\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2354 - val_loss: 11.7386\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2595 - val_loss: 11.7252\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2054 - val_loss: 11.5649\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2169 - val_loss: 11.7029\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3372 - val_loss: 11.8241\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3816 - val_loss: 11.6720\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3368 - val_loss: 11.4946\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2761 - val_loss: 11.6425\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2331 - val_loss: 11.5457\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1801 - val_loss: 11.9784\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1652 - val_loss: 11.4378\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2224 - val_loss: 11.7856\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2170 - val_loss: 11.5874\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2237 - val_loss: 11.5393\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1416 - val_loss: 11.5214\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0975 - val_loss: 11.4941\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1777 - val_loss: 11.5533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1157 - val_loss: 11.7589\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2072 - val_loss: 11.4696\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2736 - val_loss: 11.5315\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1000 - val_loss: 11.5893\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0828 - val_loss: 11.4222\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1728 - val_loss: 11.5753\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2431 - val_loss: 11.8229\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2050 - val_loss: 11.3875\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1330 - val_loss: 11.3494\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0948 - val_loss: 11.7043\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0498 - val_loss: 11.3752\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0942 - val_loss: 11.3936\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1126 - val_loss: 11.4826\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1069 - val_loss: 11.4794\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0888 - val_loss: 11.4187\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0535 - val_loss: 11.3900\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1515 - val_loss: 11.5112\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1814 - val_loss: 11.4589\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0460 - val_loss: 11.3152\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0219 - val_loss: 11.1808\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0533 - val_loss: 11.7029\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0657 - val_loss: 11.3207\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0064 - val_loss: 11.4463\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9338 - val_loss: 11.2339\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9555 - val_loss: 11.1926\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1340 - val_loss: 11.8546\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2314 - val_loss: 11.3038\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0039 - val_loss: 11.2697\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0013 - val_loss: 11.2690\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9794 - val_loss: 11.1217\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9229 - val_loss: 11.2143\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9329 - val_loss: 11.1551\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9381 - val_loss: 11.2191\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.8423 - val_loss: 11.0975\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.9925 - val_loss: 11.3738\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0855 - val_loss: 11.7031\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0194 - val_loss: 11.1229\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.8508 - val_loss: 11.0580\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9688 - val_loss: 11.2838\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9468 - val_loss: 11.5170\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9804 - val_loss: 11.1882\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8685 - val_loss: 11.1747\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8664 - val_loss: 11.1906\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9506 - val_loss: 11.1761\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8872 - val_loss: 11.2740\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8980 - val_loss: 11.1805\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8803 - val_loss: 11.1576\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8476 - val_loss: 11.2087\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9194 - val_loss: 11.1049\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7308 - val_loss: 11.3615\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8931 - val_loss: 11.1522\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9122 - val_loss: 11.4594\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8811 - val_loss: 11.2184\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8594 - val_loss: 11.0803\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8172 - val_loss: 11.5134\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8305 - val_loss: 12.0343\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7919 - val_loss: 11.1116\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8410 - val_loss: 11.0776\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7998 - val_loss: 11.3415\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9619 - val_loss: 11.2690\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9862 - val_loss: 11.2996\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7924 - val_loss: 11.0196\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6888 - val_loss: 11.1780\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7728 - val_loss: 10.9277\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7782 - val_loss: 11.0374\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7399 - val_loss: 11.0132\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6816 - val_loss: 11.2324\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7604 - val_loss: 11.1699\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7021 - val_loss: 11.2615\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8299 - val_loss: 10.9391\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7029 - val_loss: 10.7996\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7508 - val_loss: 10.9846\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7631 - val_loss: 11.1674\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6364 - val_loss: 10.8690\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6469 - val_loss: 10.8909\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6656 - val_loss: 11.0234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7767 - val_loss: 10.7794\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7053 - val_loss: 11.0266\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7190 - val_loss: 10.8320\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6117 - val_loss: 10.8075\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7533 - val_loss: 11.0952\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5935 - val_loss: 10.7922\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5301 - val_loss: 10.5930\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5839 - val_loss: 10.6941\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5720 - val_loss: 10.7739\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5532 - val_loss: 10.7124\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5572 - val_loss: 11.4825\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6383 - val_loss: 10.8594\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5803 - val_loss: 10.6403\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5778 - val_loss: 10.7065\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5353 - val_loss: 10.6102\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5783 - val_loss: 10.9899\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8836 - val_loss: 11.4128\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7879 - val_loss: 10.8114\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6352 - val_loss: 11.2537\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6945 - val_loss: 10.7619\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5358 - val_loss: 11.2531\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5456 - val_loss: 10.7222\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6085 - val_loss: 10.9691\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5902 - val_loss: 11.0046\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5306 - val_loss: 10.7845\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5416 - val_loss: 10.8240\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6638 - val_loss: 10.7231\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5418 - val_loss: 10.7227\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4424 - val_loss: 10.5659\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5960 - val_loss: 10.6958\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7102 - val_loss: 10.6872\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4863 - val_loss: 10.7687\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4979 - val_loss: 10.6994\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5041 - val_loss: 10.6667\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5816 - val_loss: 10.7253\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4348 - val_loss: 10.8035\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5076 - val_loss: 10.6320\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5225 - val_loss: 10.9633\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4464 - val_loss: 10.7235\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4441 - val_loss: 10.7264\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4819 - val_loss: 10.4855\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3745 - val_loss: 10.9219\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4198 - val_loss: 10.6935\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4814 - val_loss: 10.6705\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5466 - val_loss: 10.4925\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3978 - val_loss: 10.5196\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4156 - val_loss: 10.6604\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.4638 - val_loss: 10.4598\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3566 - val_loss: 10.9000\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5833 - val_loss: 10.7157\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4849 - val_loss: 10.6453\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3528 - val_loss: 10.7448\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4967 - val_loss: 10.5961\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3985 - val_loss: 10.7372\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4006 - val_loss: 10.5716\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5247 - val_loss: 11.0160\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5006 - val_loss: 10.7555\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4689 - val_loss: 10.7086\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4260 - val_loss: 10.5420\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4518 - val_loss: 10.4631\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3678 - val_loss: 10.4241\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3248 - val_loss: 10.5408\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4735 - val_loss: 10.6801\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3822 - val_loss: 10.5030\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5140 - val_loss: 10.7061\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4344 - val_loss: 10.4291\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2977 - val_loss: 10.6545\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3704 - val_loss: 10.6017\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5259 - val_loss: 10.6528\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4261 - val_loss: 10.7057\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5254 - val_loss: 10.5762\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4295 - val_loss: 10.5623\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3997 - val_loss: 10.5696\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5867 - val_loss: 10.4892\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4430 - val_loss: 10.6076\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3335 - val_loss: 10.6466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4954 - val_loss: 10.6281\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4302 - val_loss: 10.4522\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3660 - val_loss: 10.4868\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3545 - val_loss: 10.4420\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2790 - val_loss: 10.5411\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3449 - val_loss: 10.5362\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4022 - val_loss: 10.6703\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3974 - val_loss: 10.3404\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3329 - val_loss: 10.4731\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3993 - val_loss: 10.7298\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5164 - val_loss: 10.4097\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4337 - val_loss: 10.5312\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3779 - val_loss: 10.5135\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3352 - val_loss: 10.5832\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4422 - val_loss: 10.7931\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4069 - val_loss: 10.5723\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4201 - val_loss: 10.4807\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3299 - val_loss: 10.4177\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3377 - val_loss: 10.6982\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5044 - val_loss: 10.4220\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3621 - val_loss: 10.4594\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4611 - val_loss: 10.5539\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5852 - val_loss: 10.9336\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4324 - val_loss: 10.5030\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3394 - val_loss: 10.5371\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3240 - val_loss: 10.6631\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3381 - val_loss: 10.5375\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4130 - val_loss: 10.5202\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3013 - val_loss: 10.8289\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4469 - val_loss: 10.6269\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4357 - val_loss: 10.7130\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3522 - val_loss: 10.4779\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4910 - val_loss: 10.4596\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2190 - val_loss: 10.6052\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3177 - val_loss: 10.5786\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3206 - val_loss: 10.3873\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4481 - val_loss: 10.4461\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3505 - val_loss: 10.5244\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3343 - val_loss: 10.3238\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3480 - val_loss: 10.5952\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3209 - val_loss: 10.4916\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3840 - val_loss: 10.5451\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2946 - val_loss: 10.4714\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2926 - val_loss: 10.5911\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3047 - val_loss: 10.5750\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.3718 - val_loss: 10.4083\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2785 - val_loss: 10.5468\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3878 - val_loss: 10.4214\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2684 - val_loss: 10.7686\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.5044 - val_loss: 10.6906\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3443 - val_loss: 10.5906\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3286 - val_loss: 10.3130\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.3335 - val_loss: 10.4877\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4079 - val_loss: 10.4551\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 8.2711 - val_loss: 10.4176\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.3670 - val_loss: 10.8603\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.4371 - val_loss: 10.5105\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3334 - val_loss: 10.5989\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4452 - val_loss: 10.3636\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4616 - val_loss: 10.8314\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.3292 - val_loss: 10.4745\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3253 - val_loss: 10.6428\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4785 - val_loss: 10.6407\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2734 - val_loss: 10.3676\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4282 - val_loss: 10.6183\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3721 - val_loss: 10.3477\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.4064 - val_loss: 10.7234\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5044 - val_loss: 10.6849\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3780 - val_loss: 10.6541\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4943 - val_loss: 10.6686\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2627 - val_loss: 10.7258\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5215 - val_loss: 10.6191\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3428 - val_loss: 10.3570\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2778 - val_loss: 10.4956\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3517 - val_loss: 10.5802\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3230 - val_loss: 10.5065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3927 - val_loss: 10.7802\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5079 - val_loss: 10.5381\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3683 - val_loss: 10.8436\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2754 - val_loss: 10.5858\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3031 - val_loss: 10.4574\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4037 - val_loss: 10.6712\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3046 - val_loss: 10.5873\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4254 - val_loss: 10.6118\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 8.3075 - val_loss: 10.5231\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 7.951 - 0s 94us/step - loss: 8.2852 - val_loss: 10.4748\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3711 - val_loss: 10.4335\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3967 - val_loss: 10.9671\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5020 - val_loss: 10.4475\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3027 - val_loss: 10.6116\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2702 - val_loss: 10.5531\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3201 - val_loss: 10.4999\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5246 - val_loss: 10.8713\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3862 - val_loss: 10.5249\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3617 - val_loss: 10.9305\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2562 - val_loss: 10.5782\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3436 - val_loss: 10.6059\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3018 - val_loss: 10.4526\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3668 - val_loss: 10.4399\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2792 - val_loss: 10.5709\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2298 - val_loss: 10.5445\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2636 - val_loss: 10.5989\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3776 - val_loss: 10.4618\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2700 - val_loss: 10.4690\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4409 - val_loss: 10.5356\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3606 - val_loss: 10.8517\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2866 - val_loss: 10.5644\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3402 - val_loss: 10.5951\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3624 - val_loss: 10.8610\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2978 - val_loss: 10.6324\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5022 - val_loss: 10.5873\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.4304 - val_loss: 10.4309\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3208 - val_loss: 10.4108\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3036 - val_loss: 10.5359\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4207 - val_loss: 10.4687\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3287 - val_loss: 10.5588\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5781 - val_loss: 10.6162\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4279 - val_loss: 10.4572\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2537 - val_loss: 10.5305\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3604 - val_loss: 10.4971\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3302 - val_loss: 10.3746\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3523 - val_loss: 10.6142\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3767 - val_loss: 10.4981\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3644 - val_loss: 10.6775\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5199 - val_loss: 10.5350\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3671 - val_loss: 10.4980\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3224 - val_loss: 10.6346\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3183 - val_loss: 10.5663\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4445 - val_loss: 10.8341\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2862 - val_loss: 10.5646\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3306 - val_loss: 10.8843\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3574 - val_loss: 10.5496\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4268 - val_loss: 10.5174\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3186 - val_loss: 10.4498\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4860 - val_loss: 10.4544\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3889 - val_loss: 10.5483\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3658 - val_loss: 10.4735\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2417 - val_loss: 10.7384\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2490 - val_loss: 10.7262\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2890 - val_loss: 10.8848\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2122 - val_loss: 10.7766\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3409 - val_loss: 10.5288\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2947 - val_loss: 10.5710\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3286 - val_loss: 10.8172\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3626 - val_loss: 10.7766\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4135 - val_loss: 10.5137\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3309 - val_loss: 10.5092\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3380 - val_loss: 10.5625\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4008 - val_loss: 10.6659\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2493 - val_loss: 10.5580\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2782 - val_loss: 10.4100\n",
      "Epoch 745/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3143 - val_loss: 10.5459\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4444 - val_loss: 10.7813\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3080 - val_loss: 10.5710\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2612 - val_loss: 10.7222\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3538 - val_loss: 10.4721\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2982 - val_loss: 10.4723\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3213 - val_loss: 10.4729\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2338 - val_loss: 10.6431\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3059 - val_loss: 10.5394\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2886 - val_loss: 10.6316\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2825 - val_loss: 10.7555\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3789 - val_loss: 10.6913\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4052 - val_loss: 10.7491\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3703 - val_loss: 10.5399\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3012 - val_loss: 10.5597\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3064 - val_loss: 11.0213\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2489 - val_loss: 10.4619\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3512 - val_loss: 10.4135\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2742 - val_loss: 10.5389\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4938 - val_loss: 10.7816\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3133 - val_loss: 11.0046\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6376 - val_loss: 10.6392\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5195 - val_loss: 10.4728\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2801 - val_loss: 10.7049\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3097 - val_loss: 10.5996\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3466 - val_loss: 10.4331\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3799 - val_loss: 10.4737\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3715 - val_loss: 11.0653\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4318 - val_loss: 10.6834\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3055 - val_loss: 10.4661\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2975 - val_loss: 10.4776\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2403 - val_loss: 10.4342\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3379 - val_loss: 10.4480\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4005 - val_loss: 10.6805\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2792 - val_loss: 10.5612\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3249 - val_loss: 10.6400\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2387 - val_loss: 10.4922\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2789 - val_loss: 10.5624\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2896 - val_loss: 10.7028\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2913 - val_loss: 10.7195\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2930 - val_loss: 10.4943\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3720 - val_loss: 10.4342\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2703 - val_loss: 10.5150\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2452 - val_loss: 10.5575\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3022 - val_loss: 10.6474\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3305 - val_loss: 10.6055\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2768 - val_loss: 10.5230\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2972 - val_loss: 10.7203\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2868 - val_loss: 10.6233\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3297 - val_loss: 10.7434\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2943 - val_loss: 11.0990\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5307 - val_loss: 10.5441\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2956 - val_loss: 10.7814\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2398 - val_loss: 10.6920\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3248 - val_loss: 10.5262\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3517 - val_loss: 10.5612\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3798 - val_loss: 10.9168\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4131 - val_loss: 10.6798\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2670 - val_loss: 10.5994\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3990 - val_loss: 10.6802\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3256 - val_loss: 10.9140\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3239 - val_loss: 10.7722\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3109 - val_loss: 10.5377\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2349 - val_loss: 10.5256\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2288 - val_loss: 10.7809\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.3802 - val_loss: 10.8384\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.2839 - val_loss: 10.5376\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.4247 - val_loss: 10.9820\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.3565 - val_loss: 10.7875\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.5065 - val_loss: 10.6303\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3485 - val_loss: 10.9076\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.3942 - val_loss: 10.9301\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3211 - val_loss: 10.5660\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2450 - val_loss: 10.7148\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3277 - val_loss: 10.8260\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2395 - val_loss: 10.6466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3372 - val_loss: 10.8247\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3523 - val_loss: 10.8167\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5364 - val_loss: 10.7834\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4676 - val_loss: 10.4898\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2528 - val_loss: 10.8519\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2503 - val_loss: 10.6381\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2656 - val_loss: 10.7787\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2645 - val_loss: 10.4602\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3560 - val_loss: 10.7292\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4032 - val_loss: 10.4706\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.3317 - val_loss: 10.8601\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5514 - val_loss: 10.6505\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3119 - val_loss: 10.9464\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4135 - val_loss: 10.5622\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3831 - val_loss: 11.0740\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3052 - val_loss: 10.8418\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2413 - val_loss: 11.5764\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3882 - val_loss: 10.9023\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4546 - val_loss: 11.1123\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3892 - val_loss: 10.6738\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2671 - val_loss: 10.5491\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2857 - val_loss: 11.0286\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2731 - val_loss: 10.6657\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2032 - val_loss: 10.5803\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2975 - val_loss: 10.7292\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2560 - val_loss: 10.6746\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2404 - val_loss: 10.6068\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4163 - val_loss: 10.5823\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3324 - val_loss: 10.6608\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2099 - val_loss: 10.7229\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.2489 - val_loss: 10.5603\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1755 - val_loss: 10.5933\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3896 - val_loss: 10.7601\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2155 - val_loss: 10.9183\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2635 - val_loss: 10.6537\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2932 - val_loss: 10.8329\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2348 - val_loss: 10.9375\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3526 - val_loss: 10.8727\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2331 - val_loss: 10.7765\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2953 - val_loss: 10.7011\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2663 - val_loss: 10.5976\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2841 - val_loss: 10.5269\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2717 - val_loss: 10.9328\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3043 - val_loss: 10.5433\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1896 - val_loss: 10.5251\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2248 - val_loss: 10.5797\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2995 - val_loss: 10.6377\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2248 - val_loss: 10.7558\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1945 - val_loss: 10.6791\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1143 - val_loss: 10.6306\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3074 - val_loss: 10.8773\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2119 - val_loss: 10.8203\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2531 - val_loss: 10.6315\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2243 - val_loss: 10.6067\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2305 - val_loss: 10.6281\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1893 - val_loss: 11.1143\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3072 - val_loss: 10.5337\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1966 - val_loss: 10.7456\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4059 - val_loss: 10.9050\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4893 - val_loss: 10.7805\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4274 - val_loss: 10.8222\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2277 - val_loss: 10.6025\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2793 - val_loss: 10.4982\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2639 - val_loss: 10.7557\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2330 - val_loss: 10.5659\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2032 - val_loss: 10.6375\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2268 - val_loss: 10.7888\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3024 - val_loss: 10.6137\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3839 - val_loss: 10.7321\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3784 - val_loss: 10.7931\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1146 - val_loss: 10.6372\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1820 - val_loss: 10.9617\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2191 - val_loss: 10.8886\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3210 - val_loss: 11.2826\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3517 - val_loss: 12.2144\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5438 - val_loss: 10.7140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2483 - val_loss: 10.8264\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2910 - val_loss: 11.2869\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2890 - val_loss: 10.9351\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2028 - val_loss: 10.4451\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1662 - val_loss: 10.5545\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2180 - val_loss: 10.7695\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.2988 - val_loss: 10.5869\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2638 - val_loss: 10.9780\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1514 - val_loss: 10.6279\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1538 - val_loss: 10.6084\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1983 - val_loss: 10.7209\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1875 - val_loss: 10.8763\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3046 - val_loss: 10.6471\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2205 - val_loss: 10.6234\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1871 - val_loss: 10.5626\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3224 - val_loss: 10.9143\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1635 - val_loss: 10.7154\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2273 - val_loss: 10.6826\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1139 - val_loss: 10.7388\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3386 - val_loss: 10.7345\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2227 - val_loss: 10.9228\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3194 - val_loss: 10.7429\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1774 - val_loss: 10.7334\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2508 - val_loss: 10.9555\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2791 - val_loss: 10.5311\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3407 - val_loss: 10.8798\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2180 - val_loss: 10.5285\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1932 - val_loss: 10.8602\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2823 - val_loss: 10.9229\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3031 - val_loss: 10.9678\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2435 - val_loss: 10.8299\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2427 - val_loss: 10.7426\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2148 - val_loss: 10.9584\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1876 - val_loss: 10.9445\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1981 - val_loss: 11.0253\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3935 - val_loss: 10.8812\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0930 - val_loss: 10.9223\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1373 - val_loss: 10.5466\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2577 - val_loss: 10.6668\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2118 - val_loss: 12.0241\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3471 - val_loss: 10.7063\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2273 - val_loss: 10.8040\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2253 - val_loss: 10.9694\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2226 - val_loss: 10.7083\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2359 - val_loss: 10.6607\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1544 - val_loss: 10.7105\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0878 - val_loss: 10.9700\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.8650 - 0s 94us/step - loss: 8.3629 - val_loss: 10.5491\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2965 - val_loss: 10.6301\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2957 - val_loss: 11.0379\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4012 - val_loss: 10.8198\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2970 - val_loss: 10.8599\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0795 - val_loss: 10.7219\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2281 - val_loss: 10.5919\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2766 - val_loss: 10.8838\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2278 - val_loss: 10.9733\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2075 - val_loss: 10.8545\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2390 - val_loss: 11.0745\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.426 - 0s 92us/step - loss: 8.3527 - val_loss: 10.6674\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.3769 - val_loss: 10.6139\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1664 - val_loss: 10.6229\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1622 - val_loss: 10.7107\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2836 - val_loss: 10.7183\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.3364 - val_loss: 10.6108\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1945 - val_loss: 10.7175\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2155 - val_loss: 10.9444\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1634 - val_loss: 10.6405\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1659 - val_loss: 11.2723\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3011 - val_loss: 10.9440\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2724 - val_loss: 10.6380\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1521 - val_loss: 10.8452\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1270 - val_loss: 10.9601\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2207 - val_loss: 10.9665\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2847 - val_loss: 10.9593\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2519 - val_loss: 10.8123\n",
      "Epoch 972/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2373 - val_loss: 10.7003\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.1910 - val_loss: 10.9013\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3135 - val_loss: 11.5302\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2964 - val_loss: 10.7704\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2142 - val_loss: 10.6427\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2847 - val_loss: 10.6719\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.1392 - val_loss: 10.6355\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2557 - val_loss: 10.7419\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.2872 - val_loss: 10.8496\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.1844 - val_loss: 10.7523\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.1421 - val_loss: 10.6793\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.1532 - val_loss: 10.7058\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.1478 - val_loss: 10.6691\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1434 - val_loss: 10.6384\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.2325 - val_loss: 10.6966\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0919 - val_loss: 10.4951\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2606 - val_loss: 10.7827\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2558 - val_loss: 10.6567\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1364 - val_loss: 10.6015\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3233 - val_loss: 10.7603\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0680 - val_loss: 10.8644\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3503 - val_loss: 11.2911\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2103 - val_loss: 10.5569\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0492 - val_loss: 10.5162\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2477 - val_loss: 10.7837\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1586 - val_loss: 10.6436\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1898 - val_loss: 10.6533\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2626 - val_loss: 11.3077\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2229 - val_loss: 10.6931\n",
      "8.27684711618761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 4.989541  ,  2.623077  , -3.8776383 ,  3.0839887 , -0.06285875],\n",
       "        [ 1.9265463 , -0.27901173,  3.0607364 ,  0.39723295, -0.8127175 ],\n",
       "        [ 1.0656755 ,  0.10134008, -1.1309854 , -2.9467993 ,  0.5733735 ],\n",
       "        [-0.47882223,  0.15672569,  0.20729707, -0.2368906 , -0.05178694],\n",
       "        [ 0.19829467, -0.15238367, -1.1392518 ,  0.50907165, -4.247547  ]],\n",
       "       dtype=float32),\n",
       " array([ 2.4111297 ,  2.4953732 , -1.4907146 , -2.0458539 ,  0.43988156],\n",
       "       dtype=float32),\n",
       " array([[ 3.6179123 , -4.494039  , -1.4151912 ,  4.464202  ,  2.5764902 ,\n",
       "          2.9332721 , -1.3160638 ,  1.9622064 ,  3.0377512 ,  2.4631321 ],\n",
       "        [-1.8154657 ,  1.4245684 ,  1.3658127 , -2.461364  , 14.219907  ,\n",
       "         13.6921425 ,  1.5137846 , -1.9327594 , 12.884217  , 18.351583  ],\n",
       "        [ 3.6338792 , -0.9631596 ,  0.7320871 ,  2.5601392 ,  2.046581  ,\n",
       "          2.2853544 ,  3.7865114 ,  1.6380951 ,  2.4592948 ,  1.9585941 ],\n",
       "        [ 5.8923416 ,  5.000535  ,  0.7600016 , -2.6649756 ,  4.5245943 ,\n",
       "          1.1584078 ,  0.55888784, -1.3192502 , -0.6068798 ,  9.968602  ],\n",
       "        [ 1.8005749 , -1.5559714 , -0.10680714, 12.090714  ,  6.776637  ,\n",
       "          9.02229   ,  0.3121983 ,  2.2366292 ,  7.845374  ,  1.7707224 ]],\n",
       "       dtype=float32),\n",
       " array([-0.79849344,  4.1519065 ,  1.3953428 , -3.8973079 ,  0.5818494 ,\n",
       "        -2.0608437 ,  4.630702  ,  0.4627838 ,  0.58809084, -1.1732624 ],\n",
       "       dtype=float32),\n",
       " array([[12.966791 ],\n",
       "        [11.307885 ],\n",
       "        [11.0659075],\n",
       "        [12.4438505],\n",
       "        [13.07274  ],\n",
       "        [12.9717865],\n",
       "        [12.655198 ],\n",
       "        [11.678359 ],\n",
       "        [13.088634 ],\n",
       "        [13.140743 ]], dtype=float32),\n",
       " array([11.85939], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_sigmoid(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_sigmoid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 222us/step - loss: 12845.1433 - val_loss: 10258.7141\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8585.4935 - val_loss: 7239.6355\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6250.9737 - val_loss: 5432.2812\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4758.1031 - val_loss: 4203.0674\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 3707.5568 - val_loss: 3303.9760\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 2926.4284 - val_loss: 2625.0255\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 2329.6634 - val_loss: 2099.2373\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 1864.7284 - val_loss: 1687.0182\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 1498.5065 - val_loss: 1359.6606\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 1207.6378 - val_loss: 1097.7819\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 974.7798 - val_loss: 888.8634\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 788.5072 - val_loss: 720.6637\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 639.2156 - val_loss: 584.3570\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 518.4148 - val_loss: 476.2228\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 422.1568 - val_loss: 388.2405\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 344.4382 - val_loss: 318.0514\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 282.3252 - val_loss: 261.4901\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 232.6054 - val_loss: 216.1052\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 192.9498 - val_loss: 179.6895\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 161.2049 - val_loss: 151.1025\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 136.1982 - val_loss: 128.1124\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 116.4455 - val_loss: 109.6417\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 100.7994 - val_loss: 95.1564\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 88.5092 - val_loss: 83.8950\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 78.9241 - val_loss: 75.1038\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 71.5002 - val_loss: 68.1130\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 65.7379 - val_loss: 62.5537\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 61.2538 - val_loss: 58.3012\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 57.8106 - val_loss: 55.0539\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 55.2120 - val_loss: 52.4942\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 53.2292 - val_loss: 50.4773\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 51.7292 - val_loss: 48.9435\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 50.5830 - val_loss: 47.8056\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 49.7229 - val_loss: 46.9347\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 49.0866 - val_loss: 46.2358\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 48.6091 - val_loss: 45.7006\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 48.2709 - val_loss: 45.2735\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 48.0043 - val_loss: 44.9946\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.8205 - val_loss: 44.7557\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.6890 - val_loss: 44.5386\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.5848 - val_loss: 44.4216\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 47.5332 - val_loss: 44.2780\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.4697 - val_loss: 44.2199\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.4340 - val_loss: 44.1639\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 47.4089 - val_loss: 44.1063\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.3949 - val_loss: 44.0492\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3770 - val_loss: 44.0206\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3725 - val_loss: 44.0226\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.3565 - val_loss: 43.9896\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.3559 - val_loss: 43.9725\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 47.3385 - val_loss: 43.9642\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 47.3227 - val_loss: 43.9528\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 47.2978 - val_loss: 43.9088\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 47.2358 - val_loss: 43.8829\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 47.1143 - val_loss: 43.8141\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 46.6983 - val_loss: 42.7622\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 43.7880 - val_loss: 39.3834\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 40.7394 - val_loss: 38.6831\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 39.5329 - val_loss: 38.0215\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 37.7694 - val_loss: 37.5837\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 37.2102 - val_loss: 36.4699\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 36.9893 - val_loss: 37.0084\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 37.1038 - val_loss: 36.4965\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 36.7551 - val_loss: 36.2967\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 35.2889 - val_loss: 35.0303\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 32.0551 - val_loss: 32.6438\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 25.7419 - val_loss: 26.9788\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9036 - val_loss: 25.8662\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.5272 - val_loss: 24.1737\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.6914 - val_loss: 23.6462\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.0184 - val_loss: 22.9237\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.4788 - val_loss: 22.5961\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0543 - val_loss: 21.9285\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.6322 - val_loss: 21.5578\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.0880 - val_loss: 21.0174\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 16.6954 - val_loss: 20.4229\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.3151 - val_loss: 20.1845\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.0691 - val_loss: 20.0055\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.6664 - val_loss: 19.8798\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.7609 - val_loss: 20.0832\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.4973 - val_loss: 19.3651\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.0543 - val_loss: 18.9647\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.8776 - val_loss: 19.0589\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5743 - val_loss: 18.7170\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3146 - val_loss: 18.5817\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.9656 - val_loss: 18.3219\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6393 - val_loss: 17.8791\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.7314 - val_loss: 17.9574\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5853 - val_loss: 17.7232\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.3615 - val_loss: 17.7498\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.1680 - val_loss: 17.9466\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.1798 - val_loss: 18.0055\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.9805 - val_loss: 17.4138\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.7511 - val_loss: 17.5429\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4372 - val_loss: 17.3788\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.5907 - val_loss: 17.0930\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.5041 - val_loss: 17.2809\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.7055 - val_loss: 18.0020\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1662 - val_loss: 17.4988\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3580 - val_loss: 17.1106\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.5426 - val_loss: 17.1272\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4256 - val_loss: 17.0198\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0144 - val_loss: 17.1132\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.0043 - val_loss: 17.3155\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.0981 - val_loss: 17.0584\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.8472 - val_loss: 17.2119\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.7005 - val_loss: 16.7808\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7631 - val_loss: 16.7057\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.6231 - val_loss: 16.8605\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5588 - val_loss: 16.9880\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.7418 - val_loss: 16.9491\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.5880 - val_loss: 16.7526\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.4489 - val_loss: 17.2218\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4563 - val_loss: 16.7532\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.5013 - val_loss: 16.7145\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.3035 - val_loss: 17.0595\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4752 - val_loss: 16.6622\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3503 - val_loss: 16.3753\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3809 - val_loss: 16.5515\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2593 - val_loss: 16.5473\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3614 - val_loss: 16.4503\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.1898 - val_loss: 16.7203\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3505 - val_loss: 16.6645\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1421 - val_loss: 16.5631\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2997 - val_loss: 16.5243\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1939 - val_loss: 16.0968\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.0892 - val_loss: 16.1413\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.0188 - val_loss: 15.7866\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.9828 - val_loss: 16.2590\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0342 - val_loss: 15.6857\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9631 - val_loss: 15.8376\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 11.1602 - val_loss: 15.2409\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.0272 - val_loss: 15.2536\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.9610 - val_loss: 15.5181\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.7975 - val_loss: 14.7477\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 134us/step - loss: 10.6051 - val_loss: 14.8934\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.7997 - val_loss: 15.5091\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.4944 - val_loss: 13.6053\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.0794 - val_loss: 13.1368\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.7825 - val_loss: 12.5881\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.7227 - val_loss: 11.5290\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2986 - val_loss: 11.0755\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.3776 - val_loss: 11.4658\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.0659 - val_loss: 11.5905\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9270 - val_loss: 11.0524\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2709 - val_loss: 11.1385\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0548 - val_loss: 10.9102\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9897 - val_loss: 10.8635\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5484 - val_loss: 11.6294\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6256 - val_loss: 10.5987\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5955 - val_loss: 10.1441\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3925 - val_loss: 9.9795\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4717 - val_loss: 9.7981\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2998 - val_loss: 10.1362\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5789 - val_loss: 9.6199\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.3626 - val_loss: 9.5996\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2978 - val_loss: 9.4953\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5241 - val_loss: 9.9579\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1283 - val_loss: 9.7975\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.4765 - val_loss: 9.3595\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6757 - val_loss: 9.7221\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2331 - val_loss: 10.0250\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2292 - val_loss: 9.3517\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.9463 - val_loss: 9.2816\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.9358 - val_loss: 9.2073\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0902 - val_loss: 9.2322\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8837 - val_loss: 9.5641\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.0273 - val_loss: 9.3315\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0488 - val_loss: 9.0694\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9073 - val_loss: 9.0216\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.8164 - val_loss: 8.8033\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1752 - val_loss: 9.0896\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0274 - val_loss: 8.9604\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9654 - val_loss: 9.2739\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.9724 - val_loss: 9.2149\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.7383 - val_loss: 9.2050\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9479 - val_loss: 8.8775\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.7620 - val_loss: 8.9743\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1253 - val_loss: 9.1012\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.7921 - val_loss: 9.2145\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.5518 - val_loss: 9.2093\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.7140 - val_loss: 9.1958\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.6669 - val_loss: 9.0373\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.6097 - val_loss: 9.0415\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6222 - val_loss: 8.7989\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4963 - val_loss: 9.0378\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.4780 - val_loss: 8.7008\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.8439 - val_loss: 9.4246\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.5734 - val_loss: 8.8209\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.4504 - val_loss: 8.3878\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.6830 - val_loss: 8.7622\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 7.5033 - val_loss: 9.0846\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 7.4185 - val_loss: 8.6692\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.2594 - val_loss: 9.3884\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.1456 - val_loss: 9.0617\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.2080 - val_loss: 8.5303\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.3124 - val_loss: 8.2030\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.4463 - val_loss: 8.6630\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.1040 - val_loss: 8.1849\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1321 - val_loss: 8.7765\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.2336 - val_loss: 8.4143\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.0807 - val_loss: 8.1157\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.0443 - val_loss: 8.3906\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.9980 - val_loss: 8.1100\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.1393 - val_loss: 9.1419\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 7.2873 - val_loss: 8.1894\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.8828 - val_loss: 8.5784\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 7.1309 - val_loss: 8.0133\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.6893 - val_loss: 8.1379\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.0440 - val_loss: 7.7852\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.7157 - val_loss: 8.2380\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.7546 - val_loss: 8.1131\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.9448 - val_loss: 7.8838\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.7562 - val_loss: 7.8603\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9946 - val_loss: 8.1937\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.7711 - val_loss: 7.6518\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7354 - val_loss: 8.1154\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8893 - val_loss: 7.5149\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.5221 - val_loss: 7.8466\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7919 - val_loss: 9.5748\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.8296 - val_loss: 7.7005\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.6259 - val_loss: 7.7017\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3801 - val_loss: 7.7086\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4586 - val_loss: 7.4793\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.4794 - val_loss: 7.7231\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.8737 - val_loss: 7.9316\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.7649 - val_loss: 7.4821\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2966 - val_loss: 7.8937\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4181 - val_loss: 7.4538\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3422 - val_loss: 7.6346\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.3234 - val_loss: 7.3288\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3300 - val_loss: 7.5827\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.4130 - val_loss: 7.3205\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3062 - val_loss: 7.4592\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.2560 - val_loss: 8.0492\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4317 - val_loss: 7.7245\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3775 - val_loss: 7.3807\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.4351 - val_loss: 7.9622\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.9533 - val_loss: 7.6836\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2508 - val_loss: 7.2798\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2467 - val_loss: 7.8740\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.5567 - val_loss: 8.5468\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.3270 - val_loss: 7.3261\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.3013 - val_loss: 8.4236\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.4348 - val_loss: 7.9114\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2054 - val_loss: 7.3104\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.2909 - val_loss: 7.6177\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1765 - val_loss: 7.6142\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.3828 - val_loss: 7.4087\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1769 - val_loss: 7.5494\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2918 - val_loss: 7.0918\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1343 - val_loss: 7.4010\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1799 - val_loss: 7.9711\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9901 - val_loss: 6.8823\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1780 - val_loss: 7.7589\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.2076 - val_loss: 7.3922\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9841 - val_loss: 7.2689\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2197 - val_loss: 8.3331\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1637 - val_loss: 7.1036\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2556 - val_loss: 7.7985\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.3378 - val_loss: 6.9723\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1960 - val_loss: 7.2733\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0811 - val_loss: 7.0429\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.1020 - val_loss: 7.2446\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0788 - val_loss: 6.8044\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1168 - val_loss: 7.1846\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.0312 - val_loss: 6.9360\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1040 - val_loss: 7.0889\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.0243 - val_loss: 7.0846\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1863 - val_loss: 7.4142\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0928 - val_loss: 7.2699\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0078 - val_loss: 7.1733\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2868 - val_loss: 6.8191\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8933 - val_loss: 7.0082\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9715 - val_loss: 6.7636\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0350 - val_loss: 6.9643\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9950 - val_loss: 6.6511\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9998 - val_loss: 7.0539\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1969 - val_loss: 7.6822\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9952 - val_loss: 8.0565\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.1695 - val_loss: 6.8636\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0919 - val_loss: 6.8302\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0698 - val_loss: 7.0346\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9556 - val_loss: 6.6882\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2611 - val_loss: 7.0923\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 6.1482 - val_loss: 7.0877\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0902 - val_loss: 7.1428\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6894 - val_loss: 6.5694\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8853 - val_loss: 7.2341\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0888 - val_loss: 7.1943\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1462 - val_loss: 7.1196\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0811 - val_loss: 6.8281\n",
      "Epoch 293/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9377 - val_loss: 7.0347\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.8600 - val_loss: 7.1096\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.0625 - val_loss: 7.4540\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.1676 - val_loss: 7.2754\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8991 - val_loss: 6.9443\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9644 - val_loss: 7.8493\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.1844 - val_loss: 7.3522\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8588 - val_loss: 6.6960\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8754 - val_loss: 7.1466\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.0686 - val_loss: 6.9725\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.8273 - val_loss: 6.5820\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.0251 - val_loss: 6.7460\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.8187 - val_loss: 6.9442\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.9779 - val_loss: 7.0398\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.1102 - val_loss: 6.7865\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.8694 - val_loss: 6.8245\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.8470 - val_loss: 6.8819\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 6.0993 - val_loss: 6.9003\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9233 - val_loss: 6.7583\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7918 - val_loss: 6.9452\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7662 - val_loss: 7.1441\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8828 - val_loss: 6.7971\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9432 - val_loss: 7.6287\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8004 - val_loss: 6.7560\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9355 - val_loss: 7.0683\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0974 - val_loss: 6.7560\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8144 - val_loss: 6.7573\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9087 - val_loss: 6.4775\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8074 - val_loss: 6.4905\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8286 - val_loss: 6.7291\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 6.2064 - val_loss: 7.0146\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0404 - val_loss: 7.0327\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8835 - val_loss: 6.7414\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7372 - val_loss: 7.4223\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9584 - val_loss: 6.3683\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2243 - val_loss: 7.0186\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.9448 - val_loss: 6.8562\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0384 - val_loss: 7.3013\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.2130 - val_loss: 6.8241\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8858 - val_loss: 7.1454\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9463 - val_loss: 7.1294\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8913 - val_loss: 6.9270\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7269 - val_loss: 7.4406\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7649 - val_loss: 6.8529\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8215 - val_loss: 6.7887\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0052 - val_loss: 6.9657\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8810 - val_loss: 6.6057\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7626 - val_loss: 6.5672\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9515 - val_loss: 6.5371\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8120 - val_loss: 6.6656\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8258 - val_loss: 6.4984\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.2313 - val_loss: 6.9532\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1737 - val_loss: 6.5514\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7977 - val_loss: 7.0123\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7969 - val_loss: 7.6378\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7901 - val_loss: 7.0273\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8650 - val_loss: 6.8050\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7626 - val_loss: 6.8074\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1874 - val_loss: 6.9721\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0612 - val_loss: 6.9189\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8901 - val_loss: 7.3447\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8627 - val_loss: 7.2216\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8378 - val_loss: 6.9489\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8439 - val_loss: 6.8619\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8317 - val_loss: 7.0391\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.9563 - val_loss: 6.9442\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0135 - val_loss: 7.1777\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7543 - val_loss: 6.8180\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8221 - val_loss: 7.5891\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9847 - val_loss: 7.3968\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 6.2964 - val_loss: 6.8488\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0007 - val_loss: 6.9944\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8183 - val_loss: 6.9974\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9504 - val_loss: 7.0574\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8861 - val_loss: 6.7855\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9608 - val_loss: 6.6123\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8540 - val_loss: 6.9483\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9248 - val_loss: 7.9339\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.0211 - val_loss: 7.1388\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7585 - val_loss: 6.7566\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7505 - val_loss: 6.7007\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.9758 - val_loss: 7.2384\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8487 - val_loss: 7.2199\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8611 - val_loss: 6.6719\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8616 - val_loss: 7.2872\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8137 - val_loss: 7.1676\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9825 - val_loss: 7.7343\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9426 - val_loss: 7.0695\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.0044 - val_loss: 7.3009\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7691 - val_loss: 6.5771\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7592 - val_loss: 7.8115\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8535 - val_loss: 6.6643\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9135 - val_loss: 6.6655\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8737 - val_loss: 6.5672\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9966 - val_loss: 7.3800\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9768 - val_loss: 6.3267\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0413 - val_loss: 6.4349\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7935 - val_loss: 7.0756\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8033 - val_loss: 6.7274\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7029 - val_loss: 6.7391\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8269 - val_loss: 6.5902\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8844 - val_loss: 6.6307\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8041 - val_loss: 6.6032\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8694 - val_loss: 6.6412\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6152 - val_loss: 6.8777\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7040 - val_loss: 6.5210\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 5.894 - 0s 89us/step - loss: 5.6705 - val_loss: 6.7267\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7888 - val_loss: 6.6498\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7431 - val_loss: 6.6808\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8311 - val_loss: 6.5540\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8962 - val_loss: 6.6337\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7484 - val_loss: 6.8457\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7883 - val_loss: 7.0629\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.9808 - val_loss: 6.5721\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8915 - val_loss: 6.8459\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7992 - val_loss: 6.9689\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9983 - val_loss: 6.7108\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7708 - val_loss: 6.7399\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7717 - val_loss: 6.4038\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6813 - val_loss: 6.6859\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7986 - val_loss: 6.8234\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.8116 - val_loss: 6.5023\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.6435 - val_loss: 7.1005\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8704 - val_loss: 6.5575\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7861 - val_loss: 7.0695\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9064 - val_loss: 6.5657\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9199 - val_loss: 6.4864\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8693 - val_loss: 7.6802\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7767 - val_loss: 6.9844\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.0399 - val_loss: 7.5922\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9130 - val_loss: 7.0575\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.9710 - val_loss: 6.9173\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8796 - val_loss: 7.0930\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6930 - val_loss: 6.5666\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7363 - val_loss: 6.8110\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8032 - val_loss: 6.8912\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8878 - val_loss: 7.2650\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.9001 - val_loss: 6.4646\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7192 - val_loss: 6.6779\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8614 - val_loss: 6.3857\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 5.8110 - val_loss: 6.7431\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4301 - val_loss: 7.8646\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8802 - val_loss: 6.8908\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9134 - val_loss: 7.0540\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 6.0129 - val_loss: 7.0385\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1491 - val_loss: 7.9997\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9266 - val_loss: 6.5856\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9127 - val_loss: 6.4042\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6528 - val_loss: 7.4353\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7410 - val_loss: 6.9057\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7281 - val_loss: 6.4671\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8306 - val_loss: 6.6323\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7863 - val_loss: 7.1358\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7816 - val_loss: 7.4064\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8670 - val_loss: 7.0215\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9993 - val_loss: 6.7922\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7766 - val_loss: 6.7201\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8009 - val_loss: 7.3522\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.9720 - val_loss: 6.7595\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8279 - val_loss: 7.1245\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9856 - val_loss: 6.4688\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7126 - val_loss: 6.8292\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6498 - val_loss: 6.7259\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7541 - val_loss: 6.5360\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7724 - val_loss: 6.6200\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5126 - val_loss: 6.7261\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7956 - val_loss: 6.9223\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7272 - val_loss: 6.6107\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.9667 - val_loss: 7.2274\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8535 - val_loss: 7.1971\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9113 - val_loss: 7.9382\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8356 - val_loss: 6.6556\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6424 - val_loss: 6.6842\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6762 - val_loss: 6.6930\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 5.8948 - val_loss: 7.0609\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.8442 - val_loss: 6.8473\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 5.7003 - val_loss: 7.0385\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.7537 - val_loss: 6.8356\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.7611 - val_loss: 6.5854\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.7147 - val_loss: 7.2624\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.8484 - val_loss: 6.8892\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.8237 - val_loss: 7.2372\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7341 - val_loss: 7.4039\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7628 - val_loss: 6.9866\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8204 - val_loss: 6.7874\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.9079 - val_loss: 6.6471\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8157 - val_loss: 6.8032\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.9297 - val_loss: 6.5831\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.8236 - val_loss: 6.7050\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6001 - val_loss: 7.3496\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.6423 - val_loss: 6.7676\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7916 - val_loss: 7.2072\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8667 - val_loss: 6.6067\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8592 - val_loss: 6.5763\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.8711 - val_loss: 6.5824\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6976 - val_loss: 6.7669\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7884 - val_loss: 6.8007\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7343 - val_loss: 6.8893\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7608 - val_loss: 6.8533\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7235 - val_loss: 6.5573\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7268 - val_loss: 7.2387\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7716 - val_loss: 7.1206\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.7853 - val_loss: 6.7238\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6183 - val_loss: 6.6089\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6788 - val_loss: 6.7775\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6990 - val_loss: 6.5150\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5715 - val_loss: 6.4702\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5812 - val_loss: 6.7540\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6058 - val_loss: 7.7962\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6961 - val_loss: 7.1525\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7574 - val_loss: 6.5532\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6499 - val_loss: 6.4838\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5601 - val_loss: 6.7835\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6208 - val_loss: 7.8521\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8803 - val_loss: 7.6217\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8049 - val_loss: 6.4469\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6946 - val_loss: 7.3094\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7491 - val_loss: 6.9046\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6608 - val_loss: 6.9886\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8588 - val_loss: 6.9278\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5647 - val_loss: 6.7919\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8904 - val_loss: 6.5411\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5820 - val_loss: 6.6858\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8358 - val_loss: 6.6794\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5385 - val_loss: 7.0739\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5660 - val_loss: 6.4188\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6735 - val_loss: 6.6384\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6551 - val_loss: 7.0159\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.5780 - val_loss: 6.5269\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.7160 - val_loss: 6.6730\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6412 - val_loss: 6.5690\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7833 - val_loss: 7.0644\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.8936 - val_loss: 7.0358\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7648 - val_loss: 6.9968\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7298 - val_loss: 6.6177\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7225 - val_loss: 7.1802\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6973 - val_loss: 6.3130\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4670 - val_loss: 7.1013\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6694 - val_loss: 6.8756\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8266 - val_loss: 6.7434\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7035 - val_loss: 7.1515\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7402 - val_loss: 6.6116\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5507 - val_loss: 6.7058\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.8195 - val_loss: 6.9319\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8758 - val_loss: 6.4949\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6895 - val_loss: 6.6861\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.6268 - val_loss: 6.8138\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7736 - val_loss: 7.3751\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7539 - val_loss: 6.6809\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8016 - val_loss: 7.1800\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6985 - val_loss: 6.3111\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8950 - val_loss: 6.9170\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.8245 - val_loss: 7.1087\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.7048 - val_loss: 6.5273\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5975 - val_loss: 7.1010\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8145 - val_loss: 6.8925\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5917 - val_loss: 6.6559\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6859 - val_loss: 6.8575\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6098 - val_loss: 6.9308\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5654 - val_loss: 7.1161\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6149 - val_loss: 6.6542\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.8842 - val_loss: 6.8810\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6795 - val_loss: 6.9680\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6441 - val_loss: 6.7334\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5424 - val_loss: 6.2078\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7186 - val_loss: 6.3988\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.7426 - val_loss: 6.7105\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.5452 - val_loss: 6.6292\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6634 - val_loss: 6.5532\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5890 - val_loss: 6.5035\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5592 - val_loss: 7.2409\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7209 - val_loss: 6.7816\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.6687 - val_loss: 6.5220\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5401 - val_loss: 6.3845\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4818 - val_loss: 6.8087\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.6432 - val_loss: 7.1033\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6989 - val_loss: 6.6925\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6663 - val_loss: 6.4544\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6489 - val_loss: 6.9519\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.8040 - val_loss: 7.3138\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7808 - val_loss: 6.6848\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6671 - val_loss: 6.6521\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.6619 - val_loss: 7.0074\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.5137 - val_loss: 6.4692\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.5142 - val_loss: 6.6354\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7265 - val_loss: 6.7127\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.9212 - val_loss: 6.2321\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.7614 - val_loss: 6.6062\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7634 - val_loss: 7.1523\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4259 - val_loss: 6.5264\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.6415 - val_loss: 6.4287\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5960 - val_loss: 6.1766\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.3714 - val_loss: 6.8225\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6866 - val_loss: 6.2305\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5606 - val_loss: 6.4917\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6446 - val_loss: 7.2483\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5177 - val_loss: 6.5170\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.4064 - val_loss: 6.5819\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5764 - val_loss: 6.0748\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.5073 - val_loss: 6.3962\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.4679 - val_loss: 6.0810\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.5433 - val_loss: 6.2667\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5445 - val_loss: 6.2405\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4341 - val_loss: 6.1200\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.4008 - val_loss: 6.7204\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5410 - val_loss: 6.2550\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8246 - val_loss: 6.3908\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3444 - val_loss: 6.5043\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4325 - val_loss: 6.0245\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2815 - val_loss: 6.5750\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.5050 - val_loss: 6.8780\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3927 - val_loss: 6.3724\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3785 - val_loss: 5.8388\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2967 - val_loss: 6.1476\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3989 - val_loss: 6.6932\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3010 - val_loss: 6.1288\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.3980 - val_loss: 6.3564\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2969 - val_loss: 5.8588\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4421 - val_loss: 6.1001\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7078 - val_loss: 6.5091\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4673 - val_loss: 6.9791\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5016 - val_loss: 6.0575\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.4332 - val_loss: 5.7460\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.5393 - val_loss: 6.0700\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2918 - val_loss: 6.3301\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4663 - val_loss: 6.9833\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.8027 - val_loss: 6.7705\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2433 - val_loss: 5.6835\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3122 - val_loss: 6.0294\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2770 - val_loss: 6.4388\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5972 - val_loss: 6.9015\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.6712 - val_loss: 5.7950\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2490 - val_loss: 5.7484\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.2809 - val_loss: 6.4116\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.4093 - val_loss: 5.9055\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1351 - val_loss: 5.8112\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.0900 - val_loss: 5.7652\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.5622 - val_loss: 5.7765\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1603 - val_loss: 5.6638\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.1726 - val_loss: 6.2748\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.3531 - val_loss: 5.4498\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.0812 - val_loss: 6.0227\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 5.1599 - val_loss: 5.8038\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 5.1500 - val_loss: 5.5876\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.1648 - val_loss: 5.8605\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.0636 - val_loss: 5.5030\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 5.0549 - val_loss: 6.5870\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.1577 - val_loss: 5.7184\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.9909 - val_loss: 5.6323\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0498 - val_loss: 5.7966\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9624 - val_loss: 5.3305\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0914 - val_loss: 5.5447\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.0864 - val_loss: 5.8291\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2413 - val_loss: 5.5520\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5374 - val_loss: 5.9053\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1193 - val_loss: 5.6418\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.2009 - val_loss: 6.1226\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1446 - val_loss: 5.3401\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1056 - val_loss: 5.7071\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0804 - val_loss: 5.4139\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2437 - val_loss: 5.4277\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0504 - val_loss: 5.4931\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.1631 - val_loss: 5.4634\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1161 - val_loss: 5.8338\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1237 - val_loss: 6.1773\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0825 - val_loss: 5.7633\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3134 - val_loss: 6.1832\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2683 - val_loss: 5.2417\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1517 - val_loss: 5.7631\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2618 - val_loss: 5.7032\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.1096 - val_loss: 5.7631\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1209 - val_loss: 5.5376\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.0028 - val_loss: 5.8179\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.1655 - val_loss: 5.6422\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.0241 - val_loss: 6.0195\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2886 - val_loss: 5.3415\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 5.1590 - val_loss: 5.8598\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.8854 - val_loss: 5.5129\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9501 - val_loss: 5.8201\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1291 - val_loss: 5.5771\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0356 - val_loss: 5.2298\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9703 - val_loss: 5.3714\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0081 - val_loss: 6.3447\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.2060 - val_loss: 5.6478\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2132 - val_loss: 5.8479\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9796 - val_loss: 5.5181\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8732 - val_loss: 5.6590\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9961 - val_loss: 5.1837\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8091 - val_loss: 5.9359\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.1208 - val_loss: 5.5331\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8960 - val_loss: 5.4715\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9061 - val_loss: 5.4470\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.8847 - val_loss: 6.4136\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1225 - val_loss: 5.9732\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9950 - val_loss: 5.4619\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8116 - val_loss: 5.6874\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8975 - val_loss: 5.5781\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8975 - val_loss: 5.3097\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2705 - val_loss: 5.2873\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.0028 - val_loss: 6.0650\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.9332 - val_loss: 5.9327\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0009 - val_loss: 5.6235\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.9429 - val_loss: 5.9303\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.1447 - val_loss: 6.1167\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9781 - val_loss: 5.7431\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.8719 - val_loss: 5.2853\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.8131 - val_loss: 5.7385\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9971 - val_loss: 5.7964\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0959 - val_loss: 5.7423\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.9356 - val_loss: 5.3307\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1487 - val_loss: 5.3815\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.8777 - val_loss: 5.2404\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9072 - val_loss: 5.9749\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.2149 - val_loss: 5.5677\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.2490 - val_loss: 6.3025\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9287 - val_loss: 5.4227\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.1094 - val_loss: 5.8879\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2102 - val_loss: 6.1217\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2449 - val_loss: 5.4598\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9964 - val_loss: 5.5104\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.1787 - val_loss: 5.9214\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.9846 - val_loss: 5.3360\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9405 - val_loss: 5.6438\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.9958 - val_loss: 5.9773\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0386 - val_loss: 5.6962\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8679 - val_loss: 5.6408\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.3485 - val_loss: 6.4269\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.2062 - val_loss: 6.2936\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8042 - val_loss: 5.4274\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0797 - val_loss: 6.1648\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.9380 - val_loss: 5.5800\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8332 - val_loss: 5.8401\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.8916 - val_loss: 5.5448\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9354 - val_loss: 5.5794\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9231 - val_loss: 5.3914\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.4185 - val_loss: 6.7365\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.3536 - val_loss: 5.3102\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0865 - val_loss: 5.4277\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.0750 - val_loss: 5.2732\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9636 - val_loss: 6.2126\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.9949 - val_loss: 5.1429\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8889 - val_loss: 5.4583\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.9366 - val_loss: 5.2152\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7492 - val_loss: 5.6251\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8844 - val_loss: 6.0607\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7350 - val_loss: 5.7520\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.9011 - val_loss: 5.1952\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.1029 - val_loss: 5.4447\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.0919 - val_loss: 6.0486\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.0760 - val_loss: 5.3881\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9099 - val_loss: 5.3612\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.7326 - val_loss: 5.1933\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.7695 - val_loss: 5.2132\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8196 - val_loss: 6.4875\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.0818 - val_loss: 5.1408\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7656 - val_loss: 5.5037\n",
      "Epoch 749/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1461 - val_loss: 5.3810\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0561 - val_loss: 6.1187\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.2466 - val_loss: 5.2886\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8302 - val_loss: 5.2880\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.9184 - val_loss: 5.8006\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7800 - val_loss: 4.9658\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.0531 - val_loss: 5.4530\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.0942 - val_loss: 5.0884\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0995 - val_loss: 5.3078\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0122 - val_loss: 5.7748\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.9964 - val_loss: 5.6263\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.0020 - val_loss: 5.2544\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8513 - val_loss: 5.9791\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8421 - val_loss: 5.9592\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.0096 - val_loss: 5.3702\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7862 - val_loss: 4.8268\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8113 - val_loss: 5.6934\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.9316 - val_loss: 5.6899\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.0506 - val_loss: 5.3212\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 5.0688 - val_loss: 5.0615\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.1528 - val_loss: 6.0770\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.1421 - val_loss: 5.0930\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.9673 - val_loss: 5.2266\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8337 - val_loss: 5.4567\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.9239 - val_loss: 5.0719\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0956 - val_loss: 6.1176\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9603 - val_loss: 5.4183\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.9175 - val_loss: 5.0908\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0183 - val_loss: 5.1061\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9339 - val_loss: 6.0432\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.8450 - val_loss: 5.2294\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8926 - val_loss: 4.8702\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.8855 - val_loss: 5.5282\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.8485 - val_loss: 5.2822\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.8434 - val_loss: 5.5802\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0632 - val_loss: 5.5713\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.9278 - val_loss: 4.9001\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.7889 - val_loss: 4.9805\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.9168 - val_loss: 5.1068\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9689 - val_loss: 5.2445\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8297 - val_loss: 5.3447\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.8987 - val_loss: 5.8838\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9863 - val_loss: 5.3276\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9378 - val_loss: 5.3055\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.8444 - val_loss: 5.1378\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.9652 - val_loss: 5.8041\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.0101 - val_loss: 5.0608\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.8110 - val_loss: 5.4593\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7603 - val_loss: 5.3710\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 5.0512 - val_loss: 5.6416\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.6788 - val_loss: 5.2468\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 4.7886 - val_loss: 5.3500\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 4.7351 - val_loss: 5.2576\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 4.7609 - val_loss: 4.7294\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.8493 - val_loss: 5.1166\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8916 - val_loss: 4.6450\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7706 - val_loss: 5.3249\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.7761 - val_loss: 4.9037\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0417 - val_loss: 5.5886\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9080 - val_loss: 5.7011\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9029 - val_loss: 5.0536\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7593 - val_loss: 5.7382\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8781 - val_loss: 5.1579\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.8083 - val_loss: 5.5063\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.9460 - val_loss: 5.5794\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9696 - val_loss: 5.9050\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.0576 - val_loss: 5.8255\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.8908 - val_loss: 5.0209\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.8240 - val_loss: 5.3829\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9319 - val_loss: 5.5364\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.1254 - val_loss: 5.8255\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.8979 - val_loss: 5.6478\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8565 - val_loss: 5.3300\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.8568 - val_loss: 5.7266\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9112 - val_loss: 5.2938\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.7902 - val_loss: 4.9810\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.9946 - val_loss: 5.6644\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.9606 - val_loss: 5.1540\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0002 - val_loss: 5.1165\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0194 - val_loss: 6.0770\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.8842 - val_loss: 5.2754\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.0093 - val_loss: 5.6995\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1215 - val_loss: 4.8710\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.8323 - val_loss: 5.3841\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7966 - val_loss: 4.7452\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.6886 - val_loss: 5.5803\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.7734 - val_loss: 5.3409\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6518 - val_loss: 4.7157\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.9526 - val_loss: 5.2969\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9276 - val_loss: 5.0294\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.0579 - val_loss: 5.4096\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.6787 - val_loss: 4.8969\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9036 - val_loss: 4.8919\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9259 - val_loss: 5.2340\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.8962 - val_loss: 5.0678\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8681 - val_loss: 5.0637\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.7338 - val_loss: 5.0240\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 4.8306 - val_loss: 4.7080\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7093 - val_loss: 5.1225\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6046 - val_loss: 5.1388\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9634 - val_loss: 5.0842\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.8236 - val_loss: 5.3263\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7846 - val_loss: 4.8615\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7110 - val_loss: 4.9043\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.9749 - val_loss: 5.0426\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6007 - val_loss: 5.0582\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6814 - val_loss: 5.1467\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8929 - val_loss: 5.2691\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.7663 - val_loss: 5.8626\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.9748 - val_loss: 5.4624\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7535 - val_loss: 5.5564\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.8245 - val_loss: 5.4978\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7834 - val_loss: 5.4033\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.0638 - val_loss: 5.4630\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8638 - val_loss: 5.1333\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.0573 - val_loss: 5.7101\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.8396 - val_loss: 5.6513\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.9301 - val_loss: 5.2321\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7177 - val_loss: 5.2258\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.6971 - val_loss: 5.3128\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8396 - val_loss: 5.2733\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9093 - val_loss: 5.5673\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.8481 - val_loss: 4.8691\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.8470 - val_loss: 5.1367\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7697 - val_loss: 4.8691\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.8656 - val_loss: 5.1625\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.0455 - val_loss: 5.6137\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8411 - val_loss: 4.8250\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7713 - val_loss: 5.7789\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.9516 - val_loss: 4.8073\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6083 - val_loss: 5.4155\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.6327 - val_loss: 5.0700\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.7528 - val_loss: 5.2334\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6136 - val_loss: 4.7182\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6726 - val_loss: 5.6549\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7703 - val_loss: 4.9748\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.9153 - val_loss: 5.2334\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 4.7596 - val_loss: 5.3139\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.6357 - val_loss: 4.9759\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.7119 - val_loss: 4.7748\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.8186 - val_loss: 4.9582\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.7924 - val_loss: 4.8516\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6783 - val_loss: 5.6896\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.6159 - val_loss: 5.3165\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8647 - val_loss: 5.2298\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7656 - val_loss: 4.7811\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.6951 - val_loss: 5.2402\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.5290 - val_loss: 4.7154\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 4.6388 - val_loss: 5.0982\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6879 - val_loss: 5.3216\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5671 - val_loss: 4.8817\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.7191 - val_loss: 4.9911\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.8966 - val_loss: 4.7534\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7733 - val_loss: 5.3253\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9343 - val_loss: 5.1802\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.0246 - val_loss: 5.5457\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.6442 - val_loss: 5.1532\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6008 - val_loss: 5.3040\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5888 - val_loss: 5.1396\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.6327 - val_loss: 5.4349\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.6168 - val_loss: 4.7815\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7376 - val_loss: 5.0581\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.6474 - val_loss: 5.4308\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7313 - val_loss: 5.4737\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7752 - val_loss: 5.3963\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 5.1848 - val_loss: 5.2025\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6102 - val_loss: 4.9566\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5322 - val_loss: 5.3716\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.6969 - val_loss: 5.1452\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6762 - val_loss: 5.0052\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5383 - val_loss: 5.1793\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7081 - val_loss: 5.3503\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7397 - val_loss: 4.9259\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5158 - val_loss: 5.1926\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5470 - val_loss: 5.4552\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.6383 - val_loss: 5.0038\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6667 - val_loss: 5.4969\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5759 - val_loss: 4.9522\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.5552 - val_loss: 4.9365\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.6156 - val_loss: 5.5923\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8529 - val_loss: 4.8968\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8785 - val_loss: 5.0227\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7028 - val_loss: 5.4663\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.7568 - val_loss: 5.4005\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 4.607 - 0s 92us/step - loss: 4.7411 - val_loss: 4.7023\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.8066 - val_loss: 5.2562\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.6431 - val_loss: 5.7041\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.7639 - val_loss: 5.3880\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6651 - val_loss: 5.0651\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.7259 - val_loss: 5.2844\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8706 - val_loss: 5.5137\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5633 - val_loss: 5.3099\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.6796 - val_loss: 4.9152\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6863 - val_loss: 4.8041\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.5444 - val_loss: 5.1638\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.8860 - val_loss: 5.4309\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.7616 - val_loss: 4.9674\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7568 - val_loss: 5.9136\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.9215 - val_loss: 5.0500\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.9445 - val_loss: 5.2428\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.7256 - val_loss: 4.9192\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5867 - val_loss: 5.3734\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.5276 - val_loss: 4.7388\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5973 - val_loss: 5.4249\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6891 - val_loss: 5.3221\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5481 - val_loss: 4.9481\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6062 - val_loss: 4.7549\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.6312 - val_loss: 5.0117\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.8645 - val_loss: 5.1446\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.5223 - val_loss: 5.3744\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5746 - val_loss: 5.1816\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.6896 - val_loss: 5.1313\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.6532 - val_loss: 4.9016\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.5352 - val_loss: 5.0595\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.5778 - val_loss: 5.1131\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.6212 - val_loss: 5.0236\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.6664 - val_loss: 5.1214\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.7528 - val_loss: 4.9957\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.4974 - val_loss: 5.5575\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.7306 - val_loss: 4.8158\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 4.5541 - val_loss: 5.5086\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.6859 - val_loss: 5.5410\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.6680 - val_loss: 4.9717\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5436 - val_loss: 4.8212\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.4366 - val_loss: 5.1616\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.7119 - val_loss: 4.9365\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.4592 - val_loss: 5.0721\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5346 - val_loss: 5.6314\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5421 - val_loss: 5.3290\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6654 - val_loss: 5.4206\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.4733 - val_loss: 5.0127\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5882 - val_loss: 5.3913\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.7603 - val_loss: 5.0574\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6136 - val_loss: 5.0472\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6037 - val_loss: 5.0469\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.6360 - val_loss: 5.4848\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.6092 - val_loss: 5.8384\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6947 - val_loss: 5.0973\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.8724 - val_loss: 5.5609\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5678 - val_loss: 4.8795\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5818 - val_loss: 5.9713\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.5697 - val_loss: 5.3667\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 5.0049 - val_loss: 6.5329\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6551 - val_loss: 5.1470\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5547 - val_loss: 5.3035\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.6557 - val_loss: 5.0307\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.1422 - val_loss: 5.7513\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.9546 - val_loss: 5.2980\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.5474 - val_loss: 5.3678\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6883 - val_loss: 4.9680\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.6051 - val_loss: 5.1351\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.5890 - val_loss: 5.0122\n",
      "4.802999783406215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-5.2033484e-01, -4.7393384e+00, -3.0512083e+00, -3.7033233e-01,\n",
       "         -8.2904589e-01],\n",
       "        [-7.5878553e-02, -2.1115689e-01, -6.3740337e-01, -1.8770087e+00,\n",
       "         -9.1968125e-01],\n",
       "        [-2.8525898e+00, -6.0775465e-01, -9.4560765e-02, -2.4566758e+00,\n",
       "         -4.7509304e-01],\n",
       "        [-2.6456499e-03,  2.1405822e-01,  1.5452112e-01,  4.9772036e-01,\n",
       "          3.3927661e-01],\n",
       "        [-1.8693858e-01, -4.1060388e-01, -2.0304325e+00,  8.0984962e-01,\n",
       "         -1.3403702e-01]], dtype=float32),\n",
       " array([-1.8509638 , -1.6893492 , -0.27678943, -0.6225084 ,  1.6041775 ],\n",
       "       dtype=float32),\n",
       " array([[ -0.96521014,   0.36952645,   0.06282875,   0.8993432 ,\n",
       "           1.0988032 ,   0.22635858,  -2.8072968 ,  -1.1251224 ,\n",
       "           1.178104  ,   0.38830224],\n",
       "        [ -0.16879466,  -1.123248  ,  -1.0735056 ,   0.55869234,\n",
       "           0.3551835 ,   1.9298272 , -12.2996    ,  -0.34739986,\n",
       "           0.3520365 ,   0.61857665],\n",
       "        [ -0.6430522 ,  -1.4212925 ,   0.72646147,   0.01808654,\n",
       "           0.05391363,  -1.0517788 ,   0.18467686,  -0.0379836 ,\n",
       "           0.03451926,   0.23118342],\n",
       "        [  0.35933986,  -0.2308603 ,  -2.0396779 ,  -0.35456932,\n",
       "           0.75450385,  -0.5687622 ,  -5.328648  ,  -0.8242321 ,\n",
       "           0.84254116,   0.2846415 ],\n",
       "        [ -0.3711941 ,   1.974068  ,  -8.908429  ,  -0.22485168,\n",
       "           0.6330475 ,  -0.05290391,  -0.5480799 ,  -0.64477503,\n",
       "           0.67317855,   0.22030728]], dtype=float32),\n",
       " array([ 3.3158338 ,  3.0306184 , -1.8684213 ,  2.523111  ,  2.0485108 ,\n",
       "        -3.7504306 , -0.9409245 , -1.7852645 ,  1.0138421 , -0.85049134],\n",
       "       dtype=float32),\n",
       " array([[  6.226457 ],\n",
       "        [ 13.299477 ],\n",
       "        [-13.919673 ],\n",
       "        [ 13.7872305],\n",
       "        [ 13.641403 ],\n",
       "        [-11.669902 ],\n",
       "        [-14.144683 ],\n",
       "        [-13.563956 ],\n",
       "        [ 13.865538 ],\n",
       "        [ 11.856268 ]], dtype=float32),\n",
       " array([13.021928], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_tanh(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_tanh.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 665us/step - loss: 495.0073 - val_loss: 266.0142\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 185.0015 - val_loss: 71.5803\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 48.6236 - val_loss: 25.2300\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 29.4323 - val_loss: 24.0978\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 26.2835 - val_loss: 23.9678\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 24.5251 - val_loss: 20.9562\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 22.7387 - val_loss: 20.9717\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 22.3815 - val_loss: 19.8405\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 20.5811 - val_loss: 19.2597\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 18.9117 - val_loss: 19.2149\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 17.9035 - val_loss: 18.3918\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 16.8484 - val_loss: 17.8447\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 16.2513 - val_loss: 16.2205\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.8519 - val_loss: 15.1929\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 14.2696 - val_loss: 15.8796\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 13.1200 - val_loss: 15.8357\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.0749 - val_loss: 15.4418\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.8388 - val_loss: 16.1140\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.4178 - val_loss: 15.2670\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 11.0544 - val_loss: 14.7864\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.4726 - val_loss: 14.2515\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.0909 - val_loss: 13.7214\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.9042 - val_loss: 13.1705\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.5034 - val_loss: 12.6320\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.2214 - val_loss: 12.1274\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.2323 - val_loss: 11.8109\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.9958 - val_loss: 12.0899\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.6098 - val_loss: 11.2928\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.6703 - val_loss: 11.5175\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.6789 - val_loss: 11.0806\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.6000 - val_loss: 11.1981\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.3206 - val_loss: 10.8274\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3206 - val_loss: 10.9182\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2059 - val_loss: 10.7931\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1094 - val_loss: 10.7638\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1502 - val_loss: 10.7849\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2215 - val_loss: 10.8323\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.8125 - val_loss: 11.1332\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 8.0270 - val_loss: 10.7682\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9933 - val_loss: 10.7314\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9673 - val_loss: 10.6511\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8395 - val_loss: 10.4447\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9149 - val_loss: 10.5401\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.4294 - val_loss: 11.1661\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2583 - val_loss: 10.7133\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 8.1223 - val_loss: 10.5501\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8600 - val_loss: 10.5210\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8606 - val_loss: 10.7529\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9074 - val_loss: 10.4130\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.8294 - val_loss: 10.3986\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9424 - val_loss: 10.7653\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7906 - val_loss: 10.2189\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.6821 - val_loss: 9.8198\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.8419 - val_loss: 10.4069\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7480 - val_loss: 10.1072\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6705 - val_loss: 10.1319\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6417 - val_loss: 9.9529\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6211 - val_loss: 9.9564\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6944 - val_loss: 10.2407\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.9539 - val_loss: 10.1686\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.5745 - val_loss: 9.8746\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3483 - val_loss: 10.0009\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4344 - val_loss: 9.7057\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2720 - val_loss: 9.8914\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3204 - val_loss: 9.6369\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3735 - val_loss: 9.8270\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.6916 - val_loss: 9.3426\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 7.2907 - val_loss: 9.4898\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3983 - val_loss: 9.7228\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3648 - val_loss: 10.0104\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.4831 - val_loss: 9.6093\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1823 - val_loss: 9.3595\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1814 - val_loss: 9.4599\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2131 - val_loss: 9.5775\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1529 - val_loss: 9.6917\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7773 - val_loss: 9.3532\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7538 - val_loss: 9.5436\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2570 - val_loss: 9.6141\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4869 - val_loss: 10.0138\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3120 - val_loss: 9.5289\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.2531 - val_loss: 9.3193\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2255 - val_loss: 9.4215\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1895 - val_loss: 9.4192\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2539 - val_loss: 9.9082\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3246 - val_loss: 9.2990\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1732 - val_loss: 9.5080\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1132 - val_loss: 9.5576\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.9957 - val_loss: 8.8074\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2089 - val_loss: 8.7623\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9948 - val_loss: 9.0794\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0223 - val_loss: 9.0019\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2079 - val_loss: 9.3865\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0262 - val_loss: 9.3400\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2557 - val_loss: 9.4532\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3558 - val_loss: 9.4984\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1998 - val_loss: 9.1736\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2448 - val_loss: 9.0656\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9702 - val_loss: 9.0835\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9270 - val_loss: 9.3372\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0188 - val_loss: 9.0890\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.9113 - val_loss: 8.9559\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1667 - val_loss: 9.0862\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.0173 - val_loss: 9.2156\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9336 - val_loss: 9.0131\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3780 - val_loss: 8.9877\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1190 - val_loss: 9.0425\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9220 - val_loss: 9.0270\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9741 - val_loss: 9.0949\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8820 - val_loss: 8.8973\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0306 - val_loss: 9.0027\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8023 - val_loss: 8.8092\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7867 - val_loss: 8.8365\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9275 - val_loss: 8.7867\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9185 - val_loss: 8.8274\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8238 - val_loss: 9.0872\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2175 - val_loss: 8.8694\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0618 - val_loss: 9.5367\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8955 - val_loss: 9.2307\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8791 - val_loss: 8.9128\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8530 - val_loss: 9.1324\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7227 - val_loss: 9.2479\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0465 - val_loss: 9.4985\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2591 - val_loss: 8.9096\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0756 - val_loss: 9.2479\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8276 - val_loss: 9.0385\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9224 - val_loss: 9.4569\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8834 - val_loss: 8.8430\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9187 - val_loss: 8.8384\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8464 - val_loss: 8.9468\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7577 - val_loss: 9.1170\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7784 - val_loss: 8.9006\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7696 - val_loss: 8.7853\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7850 - val_loss: 8.6029\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7330 - val_loss: 8.7463\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6944 - val_loss: 9.0599\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7586 - val_loss: 8.8938\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6897 - val_loss: 8.8640\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8916 - val_loss: 9.2776\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4893 - val_loss: 9.0752\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8990 - val_loss: 8.9649\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6892 - val_loss: 8.7857\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8851 - val_loss: 8.9094\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8802 - val_loss: 8.9500\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9118 - val_loss: 9.0026\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9087 - val_loss: 8.7921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6604 - val_loss: 8.4092\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6492 - val_loss: 8.6558\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5581 - val_loss: 8.9770\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8310 - val_loss: 8.9167\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8343 - val_loss: 8.7496\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6693 - val_loss: 8.8237\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6297 - val_loss: 8.6113\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8083 - val_loss: 8.5195\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6725 - val_loss: 8.9148\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7275 - val_loss: 8.7287\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6546 - val_loss: 8.9785\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0156 - val_loss: 8.6823\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7718 - val_loss: 8.7970\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5901 - val_loss: 8.6842\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6096 - val_loss: 8.6731\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.5805 - val_loss: 8.8118\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5073 - val_loss: 8.6666\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4811 - val_loss: 8.8234\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5933 - val_loss: 8.6885\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6528 - val_loss: 8.5856\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6403 - val_loss: 8.9029\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6263 - val_loss: 8.5227\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.6073 - val_loss: 8.5769\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7599 - val_loss: 8.5382\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5187 - val_loss: 8.5778\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5713 - val_loss: 8.6842\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5367 - val_loss: 8.8475\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4524 - val_loss: 8.3398\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5007 - val_loss: 8.6956\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3518 - val_loss: 8.7096\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5158 - val_loss: 8.3504\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4145 - val_loss: 8.5952\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3907 - val_loss: 8.5730\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6649 - val_loss: 8.6407\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6200 - val_loss: 8.5856\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4369 - val_loss: 8.4058\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3993 - val_loss: 8.4872\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3355 - val_loss: 8.4976\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4700 - val_loss: 8.7227\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7413 - val_loss: 8.7493\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9895 - val_loss: 8.4807\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6935 - val_loss: 8.5840\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4950 - val_loss: 8.5255\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5958 - val_loss: 8.8662\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3014 - val_loss: 8.4293\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4087 - val_loss: 8.7711\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4520 - val_loss: 8.1647\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2429 - val_loss: 8.7536\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4758 - val_loss: 8.5525\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7989 - val_loss: 9.2336\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9149 - val_loss: 9.2647\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7158 - val_loss: 8.7000\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7292 - val_loss: 9.2080\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5732 - val_loss: 8.8499\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3099 - val_loss: 8.7891\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3048 - val_loss: 8.4459\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2664 - val_loss: 8.6104\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3540 - val_loss: 8.5738\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3671 - val_loss: 8.6809\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2003 - val_loss: 8.6459\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1331 - val_loss: 8.5107\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3378 - val_loss: 8.6125\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4544 - val_loss: 8.9095\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3461 - val_loss: 8.5195\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2744 - val_loss: 8.6163\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.1187 - val_loss: 8.9821\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3613 - val_loss: 8.7430\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1849 - val_loss: 8.4856\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1493 - val_loss: 8.6597\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0845 - val_loss: 8.6184\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1027 - val_loss: 8.7967\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1297 - val_loss: 8.5906\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4720 - val_loss: 8.8637\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4089 - val_loss: 9.3215\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1011 - val_loss: 8.9485\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2817 - val_loss: 8.5382\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0659 - val_loss: 8.7074\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 108us/step - loss: 6.1105 - val_loss: 8.9275\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9962 - val_loss: 8.6005\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0462 - val_loss: 8.6882\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2879 - val_loss: 9.0595\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2365 - val_loss: 8.6028\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0957 - val_loss: 8.7466\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2360 - val_loss: 8.8932\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2906 - val_loss: 8.5710\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2635 - val_loss: 8.6716\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0135 - val_loss: 8.7673\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0837 - val_loss: 8.8573\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0065 - val_loss: 8.8941\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1281 - val_loss: 8.8748\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1440 - val_loss: 8.8281\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9782 - val_loss: 8.6503\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9719 - val_loss: 8.7129\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0381 - val_loss: 8.7432\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9825 - val_loss: 8.9646\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1301 - val_loss: 8.8173\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1664 - val_loss: 8.6293\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9028 - val_loss: 9.0014\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5140 - val_loss: 9.0821\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0030 - val_loss: 8.6539\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0353 - val_loss: 8.8688\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2241 - val_loss: 8.8353\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0412 - val_loss: 9.2169\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0077 - val_loss: 9.2614\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4141 - val_loss: 8.6938\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0054 - val_loss: 9.2333\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0991 - val_loss: 9.2177\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2202 - val_loss: 8.6335\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1705 - val_loss: 9.2316\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1434 - val_loss: 9.2704\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9512 - val_loss: 9.4183\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9521 - val_loss: 8.9489\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9566 - val_loss: 9.0208\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9172 - val_loss: 8.5479\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8893 - val_loss: 9.1187\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9885 - val_loss: 9.6123\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0332 - val_loss: 8.9517\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9568 - val_loss: 9.0911\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0780 - val_loss: 8.7362\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1600 - val_loss: 9.4056\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.0845 - val_loss: 9.4813\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0117 - val_loss: 9.1632\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9425 - val_loss: 9.2192\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9252 - val_loss: 9.0086\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8787 - val_loss: 9.0922\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9118 - val_loss: 9.4766\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9268 - val_loss: 9.2008\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9260 - val_loss: 8.8913\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9280 - val_loss: 9.0824\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9135 - val_loss: 9.3114\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0772 - val_loss: 9.0196\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1974 - val_loss: 9.8683\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1563 - val_loss: 9.3945\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0431 - val_loss: 9.1421\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1230 - val_loss: 9.3601\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.9422 - val_loss: 9.0750\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.3480 - val_loss: 9.7409\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6179 - val_loss: 9.2144\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.0448 - val_loss: 9.6639\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6491 - val_loss: 9.2214\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1719 - val_loss: 9.2376\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9811 - val_loss: 9.2671\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3172 - val_loss: 9.6115\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0869 - val_loss: 9.3431\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9715 - val_loss: 9.0103\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0001 - val_loss: 9.3995\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8744 - val_loss: 9.0922\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1351 - val_loss: 9.3973\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0719 - val_loss: 9.8763\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0011 - val_loss: 9.4013\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9952 - val_loss: 9.3539\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1523 - val_loss: 9.8548\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8727 - val_loss: 9.8495\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8561 - val_loss: 9.4611\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 6.4746 - val_loss: 10.0028\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1442 - val_loss: 9.7682\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9225 - val_loss: 9.3426\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9759 - val_loss: 9.4499\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8150 - val_loss: 9.3985\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8290 - val_loss: 9.9071\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1302 - val_loss: 9.1107\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.0564 - val_loss: 9.6198\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9122 - val_loss: 9.3127\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8425 - val_loss: 9.6777\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9421 - val_loss: 9.6535\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.8654 - val_loss: 9.6017\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8904 - val_loss: 9.4171\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8740 - val_loss: 9.7890\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0685 - val_loss: 9.8768\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8836 - val_loss: 9.5158\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8110 - val_loss: 9.8398\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8646 - val_loss: 9.9078\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9666 - val_loss: 9.5292\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8234 - val_loss: 10.1260\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8535 - val_loss: 9.8431\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9718 - val_loss: 9.9521\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3496 - val_loss: 9.5314\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9459 - val_loss: 9.9746\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9948 - val_loss: 9.9036\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8312 - val_loss: 9.9620\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8008 - val_loss: 9.7099\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9179 - val_loss: 9.6261\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8622 - val_loss: 9.6078\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7989 - val_loss: 10.2083\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8423 - val_loss: 10.0413\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.8496 - val_loss: 9.7106\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7402 - val_loss: 9.6786\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9506 - val_loss: 9.8485\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0120 - val_loss: 10.4988\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8805 - val_loss: 9.7481\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1225 - val_loss: 10.0155\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1785 - val_loss: 10.3648\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8070 - val_loss: 9.6059\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8965 - val_loss: 10.0518\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8983 - val_loss: 10.4894\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8408 - val_loss: 9.5901\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7676 - val_loss: 10.1113\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9131 - val_loss: 10.7286\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8187 - val_loss: 9.8726\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8284 - val_loss: 10.1920\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9085 - val_loss: 10.2383\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.8500 - val_loss: 10.1255\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8818 - val_loss: 10.3775\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9544 - val_loss: 10.0774\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8794 - val_loss: 9.9413\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9021 - val_loss: 9.8373\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1424 - val_loss: 10.7610\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8878 - val_loss: 9.6937\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8852 - val_loss: 10.2062\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9760 - val_loss: 10.5417\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9305 - val_loss: 9.9915\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7698 - val_loss: 10.0493\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7654 - val_loss: 10.3413\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7723 - val_loss: 9.7534\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8511 - val_loss: 10.3976\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7825 - val_loss: 10.1973\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7050 - val_loss: 9.8862\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8453 - val_loss: 10.0582\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6786 - val_loss: 10.1729\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7960 - val_loss: 10.4737\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6922 - val_loss: 10.0375\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7627 - val_loss: 10.2953\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7330 - val_loss: 9.7887\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6488 - val_loss: 10.4773\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7334 - val_loss: 10.3108\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9808 - val_loss: 10.5566\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1719 - val_loss: 10.0133\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7073 - val_loss: 10.2559\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7900 - val_loss: 10.1385\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7229 - val_loss: 10.4298\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7062 - val_loss: 9.8437\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.7859 - val_loss: 10.5661\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7096 - val_loss: 10.0423\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6930 - val_loss: 10.4118\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6957 - val_loss: 10.2022\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6650 - val_loss: 10.3308\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8868 - val_loss: 10.7602\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6195 - val_loss: 10.6056\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7733 - val_loss: 10.6159\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7826 - val_loss: 10.2356\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0684 - val_loss: 10.6789\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0811 - val_loss: 11.0940\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7469 - val_loss: 10.0857\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7664 - val_loss: 10.7091\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7176 - val_loss: 9.7497\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6871 - val_loss: 10.3840\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8001 - val_loss: 10.7803\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6059 - val_loss: 10.1580\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5463 - val_loss: 10.2692\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6853 - val_loss: 10.6907\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6060 - val_loss: 10.7583\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5263 - val_loss: 10.0734\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6887 - val_loss: 10.7970\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4689 - val_loss: 10.1792\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 11.30 - 0s 116us/step - loss: 5.5449 - val_loss: 11.2517\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7895 - val_loss: 10.4134\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.0218 - val_loss: 10.5161\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8303 - val_loss: 10.5536\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5502 - val_loss: 10.5644\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8770 - val_loss: 10.5661\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7653 - val_loss: 11.5282\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8233 - val_loss: 10.4230\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6293 - val_loss: 10.7446\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5497 - val_loss: 11.0740\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4203 - val_loss: 10.5792\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4816 - val_loss: 10.2544\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4297 - val_loss: 10.7414\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4660 - val_loss: 10.7964\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4878 - val_loss: 10.6333\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4833 - val_loss: 10.2980\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8280 - val_loss: 11.4376\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5929 - val_loss: 10.9838\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.6377 - val_loss: 11.7590\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 143us/step - loss: 5.6018 - val_loss: 10.2964\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6382 - val_loss: 10.6117\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6062 - val_loss: 11.2365\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5138 - val_loss: 10.6114\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4750 - val_loss: 10.9602\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4445 - val_loss: 10.5043\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4186 - val_loss: 10.5421\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4633 - val_loss: 11.1600\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4206 - val_loss: 10.4811\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4939 - val_loss: 10.3892\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5209 - val_loss: 11.8597\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5424 - val_loss: 10.5950\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6049 - val_loss: 10.6239\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4726 - val_loss: 10.8320\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4086 - val_loss: 10.8575\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4842 - val_loss: 10.6638\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9861 - val_loss: 11.6756\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4864 - val_loss: 10.6822\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.5316 - val_loss: 11.7187\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6516 - val_loss: 11.1074\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3450 - val_loss: 10.8598\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.4283 - val_loss: 12.4340\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4605 - val_loss: 9.9712\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6305 - val_loss: 10.7360\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4671 - val_loss: 10.2011\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4211 - val_loss: 10.3315\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4281 - val_loss: 10.6530\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4139 - val_loss: 10.2709\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6048 - val_loss: 10.1137\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9286 - val_loss: 11.0520\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5548 - val_loss: 10.5342\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3473 - val_loss: 10.8436\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3645 - val_loss: 10.6122\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3929 - val_loss: 10.7630\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.4517 - val_loss: 10.8418\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7924 - val_loss: 11.0129\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7458 - val_loss: 10.1239\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6145 - val_loss: 11.1713\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5209 - val_loss: 10.4476\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4593 - val_loss: 11.2907\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.3338 - val_loss: 10.0507\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4140 - val_loss: 11.2768\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6687 - val_loss: 10.3695\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7324 - val_loss: 11.2131\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8408 - val_loss: 10.4021\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3371 - val_loss: 11.3023\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5147 - val_loss: 10.4776\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8806 - val_loss: 12.0119\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6878 - val_loss: 10.2171\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3454 - val_loss: 10.3091\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3619 - val_loss: 10.8969\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4667 - val_loss: 10.3495\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4217 - val_loss: 11.0434\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3684 - val_loss: 10.2363\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6592 - val_loss: 12.2310\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8124 - val_loss: 9.9649\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3521 - val_loss: 11.1016\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3507 - val_loss: 10.4419\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6247 - val_loss: 10.0918\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4300 - val_loss: 10.9041\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4217 - val_loss: 9.9805\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4522 - val_loss: 10.8694\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3162 - val_loss: 10.4296\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5137 - val_loss: 11.1440\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3423 - val_loss: 10.2955\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3702 - val_loss: 10.7297\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2558 - val_loss: 10.6738\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2847 - val_loss: 10.6895\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2423 - val_loss: 10.3502\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3190 - val_loss: 10.6764\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3767 - val_loss: 10.5804\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3708 - val_loss: 10.3502\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4680 - val_loss: 11.0355\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4654 - val_loss: 10.5027\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3477 - val_loss: 10.3904\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5348 - val_loss: 11.6297\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5899 - val_loss: 10.5704\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3107 - val_loss: 10.3557\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2722 - val_loss: 10.0443\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2749 - val_loss: 10.6391\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3010 - val_loss: 11.2107\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5626 - val_loss: 9.9091\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4748 - val_loss: 10.9393\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3484 - val_loss: 10.6921\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4543 - val_loss: 10.5081\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2616 - val_loss: 10.3836\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2881 - val_loss: 10.3849\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2419 - val_loss: 10.6951\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2951 - val_loss: 10.3061\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2681 - val_loss: 11.1498\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3225 - val_loss: 9.9422\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2321 - val_loss: 10.2797\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2778 - val_loss: 10.0335\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3229 - val_loss: 10.4295\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4191 - val_loss: 10.3969\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5972 - val_loss: 10.5999\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4621 - val_loss: 10.2213\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6788 - val_loss: 11.6992\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3227 - val_loss: 9.9737\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6520 - val_loss: 10.6536\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3224 - val_loss: 10.6531\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3329 - val_loss: 10.2315\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2648 - val_loss: 10.5443\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3920 - val_loss: 11.0589\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5642 - val_loss: 10.1299\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7372 - val_loss: 10.9691\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6160 - val_loss: 10.1364\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3111 - val_loss: 10.8918\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4873 - val_loss: 10.3501\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4088 - val_loss: 9.8852\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3599 - val_loss: 11.0662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8615 - val_loss: 10.3946\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4280 - val_loss: 10.8177\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4079 - val_loss: 10.6071\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4643 - val_loss: 9.7051\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4194 - val_loss: 11.1149\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4997 - val_loss: 10.0815\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8987 - val_loss: 11.3310\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6626 - val_loss: 10.1642\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3949 - val_loss: 10.0364\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2558 - val_loss: 10.2771\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2818 - val_loss: 10.6874\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2298 - val_loss: 10.1968\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2460 - val_loss: 10.0098\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1970 - val_loss: 10.6375\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3723 - val_loss: 10.1002\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1484 - val_loss: 10.7779\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3994 - val_loss: 10.3234\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3580 - val_loss: 10.0624\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4868 - val_loss: 10.2581\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4655 - val_loss: 10.4728\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1931 - val_loss: 10.1791\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2584 - val_loss: 10.1963\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1731 - val_loss: 10.5305\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2611 - val_loss: 10.6711\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2515 - val_loss: 10.3043\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3320 - val_loss: 10.2570\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2902 - val_loss: 9.9399\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3206 - val_loss: 10.6563\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2189 - val_loss: 9.8283\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3604 - val_loss: 10.9134\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3519 - val_loss: 9.9034\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3769 - val_loss: 10.2384\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3141 - val_loss: 10.6916\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5726 - val_loss: 10.1874\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3702 - val_loss: 10.4028\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3003 - val_loss: 10.2576\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5472 - val_loss: 10.1494\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5885 - val_loss: 11.3576\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6266 - val_loss: 10.0698\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3010 - val_loss: 9.8167\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2764 - val_loss: 10.2065\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7053 - val_loss: 10.4689\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6259 - val_loss: 10.3298\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5746 - val_loss: 10.2630\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3795 - val_loss: 10.0978\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2377 - val_loss: 10.5314\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1934 - val_loss: 10.3108\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1571 - val_loss: 10.2725\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5254 - val_loss: 9.9100\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5670 - val_loss: 10.2174\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3223 - val_loss: 10.6700\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4694 - val_loss: 9.9247\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3320 - val_loss: 10.4041\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3605 - val_loss: 10.1539\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2440 - val_loss: 10.5193\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2560 - val_loss: 9.8845\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2789 - val_loss: 10.1040\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2770 - val_loss: 10.2070\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2018 - val_loss: 10.8019\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4456 - val_loss: 9.8037\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5415 - val_loss: 10.0557\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3765 - val_loss: 10.2756\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2502 - val_loss: 10.0125\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3308 - val_loss: 10.7035\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5324 - val_loss: 10.2499\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5043 - val_loss: 9.9339\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5273 - val_loss: 10.1952\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4671 - val_loss: 10.4824\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7850 - val_loss: 9.7417\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3921 - val_loss: 10.2974\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4641 - val_loss: 9.8201\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5572 - val_loss: 10.7693\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5137 - val_loss: 10.0632\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4183 - val_loss: 9.9679\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2274 - val_loss: 10.0033\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3417 - val_loss: 10.9619\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5114 - val_loss: 9.6838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4179 - val_loss: 9.9500\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3064 - val_loss: 10.6445\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1887 - val_loss: 9.8104\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2747 - val_loss: 9.9213\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2362 - val_loss: 9.9887\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2217 - val_loss: 10.5620\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5082 - val_loss: 9.9038\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3154 - val_loss: 9.8618\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3536 - val_loss: 10.7034\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3874 - val_loss: 9.7953\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3032 - val_loss: 10.5408\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5030 - val_loss: 9.9602\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4747 - val_loss: 9.5858\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9488 - val_loss: 11.7337\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8717 - val_loss: 9.6933\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5693 - val_loss: 10.0731\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3817 - val_loss: 10.9629\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4487 - val_loss: 10.0065\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2460 - val_loss: 9.7914\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2081 - val_loss: 9.9538\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3443 - val_loss: 10.4589\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5130 - val_loss: 10.3478\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2305 - val_loss: 9.8577\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2901 - val_loss: 10.4047\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2606 - val_loss: 10.0644\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1762 - val_loss: 10.1865\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2851 - val_loss: 10.3206\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1812 - val_loss: 10.5562\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2502 - val_loss: 9.7759\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3317 - val_loss: 9.9148\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2130 - val_loss: 10.0663\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1817 - val_loss: 9.9487\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3067 - val_loss: 10.4530\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2459 - val_loss: 10.1183\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2395 - val_loss: 9.8688\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1919 - val_loss: 10.1002\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2032 - val_loss: 9.8086\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3760 - val_loss: 11.2333\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3890 - val_loss: 9.8286\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3242 - val_loss: 10.9942\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3059 - val_loss: 9.9723\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1885 - val_loss: 10.6772\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3690 - val_loss: 9.9453\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2103 - val_loss: 10.6902\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5050 - val_loss: 10.1540\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3431 - val_loss: 10.2706\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3110 - val_loss: 9.6963\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4197 - val_loss: 10.2164\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6591 - val_loss: 11.5103\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4637 - val_loss: 10.4828\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6362 - val_loss: 11.2839\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8843 - val_loss: 9.8515\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4598 - val_loss: 10.9035\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7429 - val_loss: 10.5652\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4180 - val_loss: 10.0170\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2782 - val_loss: 10.3002\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4480 - val_loss: 10.5205\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.4086 - val_loss: 9.3144\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4313 - val_loss: 10.7962\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4199 - val_loss: 9.8102\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2158 - val_loss: 9.9088\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2567 - val_loss: 10.3284\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1439 - val_loss: 9.9678\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2281 - val_loss: 10.5596\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2439 - val_loss: 9.6433\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2131 - val_loss: 10.4633\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2979 - val_loss: 10.2329\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2506 - val_loss: 10.3055\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5194 - val_loss: 10.1514\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4683 - val_loss: 10.1934\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4285 - val_loss: 9.9473\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4646 - val_loss: 10.1847\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1993 - val_loss: 9.6664\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9428 - val_loss: 11.4437\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4828 - val_loss: 9.9541\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3397 - val_loss: 9.7769\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3868 - val_loss: 10.2754\n",
      "Epoch 684/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.4128 - val_loss: 9.9820\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2666 - val_loss: 10.0302\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4244 - val_loss: 10.4335\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6209 - val_loss: 10.1209\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7365 - val_loss: 9.8923\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4122 - val_loss: 9.4534\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3166 - val_loss: 10.0962\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3284 - val_loss: 10.2544\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2199 - val_loss: 9.8535\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2074 - val_loss: 9.5279\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2793 - val_loss: 10.2853\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1769 - val_loss: 9.7110\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1942 - val_loss: 10.5922\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3001 - val_loss: 10.0839\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2606 - val_loss: 9.6803\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2813 - val_loss: 10.3720\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2794 - val_loss: 9.9109\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2828 - val_loss: 10.7089\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3609 - val_loss: 9.2983\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2499 - val_loss: 9.8441\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3194 - val_loss: 9.8957\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3304 - val_loss: 10.7856\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4046 - val_loss: 9.4422\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3695 - val_loss: 10.4882\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4348 - val_loss: 10.0922\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2529 - val_loss: 10.1772\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2627 - val_loss: 9.7310\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2938 - val_loss: 10.4804\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2796 - val_loss: 9.8728\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2232 - val_loss: 9.7272\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2433 - val_loss: 9.6877\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3083 - val_loss: 9.8785\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3152 - val_loss: 10.0285\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2398 - val_loss: 9.9828\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8074 - val_loss: 12.5934\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0278 - val_loss: 9.5513\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3670 - val_loss: 10.3131\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2269 - val_loss: 9.8596\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4621 - val_loss: 9.9397\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3578 - val_loss: 10.2295\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5912 - val_loss: 10.4193\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4483 - val_loss: 10.0466\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.5226 - val_loss: 9.8070\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2737 - val_loss: 10.0252\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2948 - val_loss: 9.9643\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5438 - val_loss: 10.4256\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2790 - val_loss: 9.8855\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2136 - val_loss: 9.8007\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2053 - val_loss: 10.3252\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2636 - val_loss: 9.7875\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4313 - val_loss: 10.9494\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7349 - val_loss: 10.0420\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5288 - val_loss: 11.3532\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4737 - val_loss: 9.8517\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4212 - val_loss: 9.8604\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3470 - val_loss: 10.3999\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1878 - val_loss: 9.8653\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.3091 - val_loss: 9.8469\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2289 - val_loss: 10.4703\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5272 - val_loss: 9.7119\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8759 - val_loss: 11.3004\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3875 - val_loss: 9.7252\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2589 - val_loss: 9.8924\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3810 - val_loss: 9.7414\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2415 - val_loss: 10.1141\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4202 - val_loss: 9.9536\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2774 - val_loss: 9.7019\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2236 - val_loss: 10.0059\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2176 - val_loss: 9.3576\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2200 - val_loss: 10.5845\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3898 - val_loss: 9.7330\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1592 - val_loss: 10.5514\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3892 - val_loss: 9.6119\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2956 - val_loss: 10.3572\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3501 - val_loss: 9.9383\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2731 - val_loss: 10.3607\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4282 - val_loss: 9.4344\n",
      "Epoch 761/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 99us/step - loss: 5.4744 - val_loss: 10.3530\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1693 - val_loss: 9.8436\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5889 - val_loss: 9.5991\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2141 - val_loss: 10.3163\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6891 - val_loss: 10.2654\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7569 - val_loss: 10.9031\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7301 - val_loss: 9.5553\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4247 - val_loss: 10.4208\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1748 - val_loss: 9.4954\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2358 - val_loss: 10.0847\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3033 - val_loss: 9.6699\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4277 - val_loss: 10.6657\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1669 - val_loss: 9.5555\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4516 - val_loss: 10.9042\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5450 - val_loss: 9.8910\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4625 - val_loss: 9.9780\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2925 - val_loss: 9.6690\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2613 - val_loss: 9.9506\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2918 - val_loss: 9.9394\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2319 - val_loss: 9.7243\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2233 - val_loss: 10.2867\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4113 - val_loss: 10.1952\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4672 - val_loss: 9.4865\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6091 - val_loss: 10.2169\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5421 - val_loss: 10.5470\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3714 - val_loss: 9.4889\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2490 - val_loss: 9.7806\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2451 - val_loss: 9.4836\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3633 - val_loss: 10.1868\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4780 - val_loss: 10.4176\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5741 - val_loss: 9.8629\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2660 - val_loss: 10.6782\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4415 - val_loss: 9.6112\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4175 - val_loss: 10.1733\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3347 - val_loss: 9.7172\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3165 - val_loss: 10.2621\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4085 - val_loss: 10.3646\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6817 - val_loss: 10.0791\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6686 - val_loss: 9.6403\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6453 - val_loss: 9.9119\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3478 - val_loss: 10.3582\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5746 - val_loss: 9.5682\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3939 - val_loss: 10.1973\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2485 - val_loss: 10.0541\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3650 - val_loss: 9.9528\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2930 - val_loss: 9.4958\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2844 - val_loss: 9.8437\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2148 - val_loss: 9.5733\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2577 - val_loss: 9.8542\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2213 - val_loss: 9.9180\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5388 - val_loss: 9.5958\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5547 - val_loss: 11.4001\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4751 - val_loss: 10.1150\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6146 - val_loss: 10.5958\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5164 - val_loss: 9.4124\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3946 - val_loss: 9.4812\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2219 - val_loss: 9.5407\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2634 - val_loss: 9.9816\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2251 - val_loss: 10.5340\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.2992 - val_loss: 9.8037\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1744 - val_loss: 9.6380\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3407 - val_loss: 10.0545\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2039 - val_loss: 9.7304\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1914 - val_loss: 10.2132\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2272 - val_loss: 9.7960\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1828 - val_loss: 10.0116\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3472 - val_loss: 9.8041\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2519 - val_loss: 9.9486\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1972 - val_loss: 9.9462\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2723 - val_loss: 10.2097\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2721 - val_loss: 10.2049\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1890 - val_loss: 9.6234\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2376 - val_loss: 10.1515\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3120 - val_loss: 10.1089\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2897 - val_loss: 9.7323\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2979 - val_loss: 9.6272\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4751 - val_loss: 10.1517\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.4984 - val_loss: 10.0863\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3922 - val_loss: 9.7825\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3591 - val_loss: 10.1694\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2024 - val_loss: 9.7892\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4847 - val_loss: 10.5386\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5608 - val_loss: 10.2579\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.4214 - val_loss: 11.8158\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5099 - val_loss: 10.3452\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6745 - val_loss: 11.3536\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4489 - val_loss: 10.4388\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4097 - val_loss: 10.5093\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3989 - val_loss: 9.7596\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2994 - val_loss: 9.8353\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6798 - val_loss: 9.8870\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6638 - val_loss: 10.0361\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2681 - val_loss: 9.6237\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2675 - val_loss: 9.5974\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2397 - val_loss: 9.7118\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5902 - val_loss: 10.7694\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7124 - val_loss: 9.7229\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.1111 - val_loss: 11.2729\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.3384 - val_loss: 9.7526\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6453 - val_loss: 9.8755\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4868 - val_loss: 10.6535\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8840 - val_loss: 9.5160\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3832 - val_loss: 11.0072\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5051 - val_loss: 10.0394\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4296 - val_loss: 9.8613\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5342 - val_loss: 9.8887\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5338 - val_loss: 9.9532\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2643 - val_loss: 9.7553\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2304 - val_loss: 9.9737\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3579 - val_loss: 9.6329\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1685 - val_loss: 10.1344\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2900 - val_loss: 9.3152\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2898 - val_loss: 10.2342\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5666 - val_loss: 10.1075\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3693 - val_loss: 10.3495\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4460 - val_loss: 9.6473\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2425 - val_loss: 9.8751\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1795 - val_loss: 9.7027\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2815 - val_loss: 10.0039\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2964 - val_loss: 10.0842\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2723 - val_loss: 9.6416\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3136 - val_loss: 10.3873\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2951 - val_loss: 9.4837\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2885 - val_loss: 10.1716\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2600 - val_loss: 10.1287\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3846 - val_loss: 9.4202\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2882 - val_loss: 10.4205\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6323 - val_loss: 10.0141\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5528 - val_loss: 9.6523\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4427 - val_loss: 10.1638\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.6200 - val_loss: 9.8161\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1384 - val_loss: 10.1533\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6899 - val_loss: 9.8848\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5549 - val_loss: 9.7363\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1634 - val_loss: 9.5168\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2142 - val_loss: 9.6339\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2185 - val_loss: 9.7461\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3835 - val_loss: 9.7743\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4069 - val_loss: 9.7912\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1722 - val_loss: 10.0648\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2834 - val_loss: 9.6428\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4991 - val_loss: 9.4058\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5306 - val_loss: 10.7675\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1868 - val_loss: 9.4093\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2610 - val_loss: 9.9689\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2518 - val_loss: 9.5876\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3904 - val_loss: 10.0148\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3516 - val_loss: 9.8826\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5663 - val_loss: 9.6228\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5492 - val_loss: 9.8129\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3212 - val_loss: 9.8542\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3461 - val_loss: 9.3481\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4242 - val_loss: 10.1149\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4274 - val_loss: 9.8802\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.3661 - val_loss: 9.4606\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3007 - val_loss: 9.6632\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5624 - val_loss: 10.0983\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3713 - val_loss: 9.4273\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3104 - val_loss: 10.4870\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2725 - val_loss: 9.9009\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4308 - val_loss: 10.9765\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3679 - val_loss: 9.6650\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5960 - val_loss: 10.5312\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4223 - val_loss: 9.8222\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.772 - 0s 98us/step - loss: 5.2168 - val_loss: 10.0021\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.3446 - val_loss: 9.5781\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4130 - val_loss: 11.0802\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7499 - val_loss: 9.6927\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4656 - val_loss: 11.0741\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2065 - val_loss: 9.9428\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3915 - val_loss: 10.0285\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1866 - val_loss: 9.3659\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3164 - val_loss: 10.0859\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3748 - val_loss: 9.6965\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1638 - val_loss: 9.7933\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2736 - val_loss: 10.0183\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5031 - val_loss: 9.9234\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3751 - val_loss: 10.4382\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5191 - val_loss: 9.5560\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4575 - val_loss: 10.4948\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2634 - val_loss: 10.0612\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3035 - val_loss: 9.4183\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1982 - val_loss: 9.3682\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3803 - val_loss: 9.7714\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2272 - val_loss: 9.8868\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1645 - val_loss: 10.2038\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4505 - val_loss: 9.6671\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2203 - val_loss: 10.1932\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1763 - val_loss: 9.6386\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2662 - val_loss: 10.2914\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1584 - val_loss: 9.5933\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2362 - val_loss: 11.1152\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9737 - val_loss: 9.2831\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5526 - val_loss: 10.7459\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3587 - val_loss: 9.5471\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2118 - val_loss: 10.2515\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2234 - val_loss: 9.4430\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3253 - val_loss: 10.2083\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2202 - val_loss: 10.0790\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2081 - val_loss: 9.7703\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2690 - val_loss: 9.5135\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2763 - val_loss: 10.2294\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3962 - val_loss: 10.0483\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.2179 - val_loss: 9.9055\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2643 - val_loss: 9.5471\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5175 - val_loss: 9.5861\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4980 - val_loss: 10.1984\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3798 - val_loss: 9.3607\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3171 - val_loss: 10.2461\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3340 - val_loss: 9.9127\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3187 - val_loss: 10.4262\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2235 - val_loss: 9.3595\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2471 - val_loss: 10.3202\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2948 - val_loss: 9.8142\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2578 - val_loss: 9.8134\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2280 - val_loss: 9.9343\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2817 - val_loss: 9.7032\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2845 - val_loss: 10.3477\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3754 - val_loss: 9.6349\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2151 - val_loss: 9.8923\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1450 - val_loss: 9.7472\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2749 - val_loss: 10.3664\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2740 - val_loss: 9.5897\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2247 - val_loss: 10.0506\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3080 - val_loss: 9.9389\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6346 - val_loss: 9.5394\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3565 - val_loss: 10.6175\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4770 - val_loss: 9.8435\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5926 - val_loss: 9.5862\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4856 - val_loss: 10.3114\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2314 - val_loss: 9.8083\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.3393 - val_loss: 9.4435\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3377 - val_loss: 9.9367\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1206 - val_loss: 9.8196\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4062 - val_loss: 11.0545\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7167 - val_loss: 9.6371\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3767 - val_loss: 10.0894\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2828 - val_loss: 9.6372\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2155 - val_loss: 10.0565\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3733 - val_loss: 10.0631\n",
      "6.636007987846763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.83311653,  0.5884854 ,  0.0494797 , -0.43361402,  0.1768458 ],\n",
       "        [-0.58106405, -0.53671163, -0.19979109, -0.7988109 ,  0.54430443],\n",
       "        [ 2.9507828 , -0.56013364,  0.10999005, -0.23482151, -0.7635586 ],\n",
       "        [ 0.37081483,  0.9880998 ,  0.18785782,  0.19894074, -0.91482717],\n",
       "        [-0.14942732, -1.283089  , -0.21566197, -0.6973004 ,  0.10718463],\n",
       "        [-1.8501477 ,  0.6505568 , -0.4530498 , -0.5435549 ,  0.36639878],\n",
       "        [-2.378687  ,  1.8573694 ,  0.42793334,  2.1766615 ,  0.50221825]],\n",
       "       dtype=float32),\n",
       " array([ 0.7764911,  2.8137336,  1.082541 ,  1.1195278, -0.7528398],\n",
       "       dtype=float32),\n",
       " array([[-0.3290912 ,  0.39726815,  0.37822735,  1.0584078 , -0.01873143,\n",
       "          0.13435373,  0.7744767 ,  0.02604375, -0.38222107,  0.18733682],\n",
       "        [ 0.21414784,  0.5622379 ,  0.5817552 ,  0.5138616 ,  0.42881975,\n",
       "         -0.3434088 ,  0.543071  ,  0.06611046,  0.05564168,  0.28392738],\n",
       "        [ 0.86506206, -1.0544946 , -1.1547403 , -0.7116181 ,  1.1512884 ,\n",
       "          0.34993693, -0.9943223 , -1.2880198 ,  0.6944865 , -0.08460128],\n",
       "        [ 0.3143449 ,  0.41692954,  0.70088995,  0.43847394, -0.3648053 ,\n",
       "         -0.29050356,  0.47924316,  0.19560689, -0.23603472, -0.42739713],\n",
       "        [-1.2997506 ,  0.526986  ,  1.0418338 ,  0.22766319, -1.2586527 ,\n",
       "         -1.2075422 ,  0.41783303,  0.8141249 , -0.87830335,  0.6621127 ]],\n",
       "       dtype=float32),\n",
       " array([-2.307022 ,  2.067417 ,  2.0570445,  2.0770655, -2.18134  ,\n",
       "        -2.0300696,  2.0860229,  2.082144 , -2.1264281,  2.0994449],\n",
       "       dtype=float32),\n",
       " array([[-1.4503314],\n",
       "        [ 1.3018526],\n",
       "        [ 1.5629643],\n",
       "        [ 1.5269127],\n",
       "        [-1.4664892],\n",
       "        [-1.4799789],\n",
       "        [ 1.6039215],\n",
       "        [ 1.5001878],\n",
       "        [-1.6202455],\n",
       "        [ 0.7696442]], dtype=float32),\n",
       " array([1.9103869], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_linear(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_linear.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 721us/step - loss: 453.8751 - val_loss: 72.7908\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 90.9932 - val_loss: 35.9319\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 40.7091 - val_loss: 21.7721\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 24.4544 - val_loss: 18.0168\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 16.5534 - val_loss: 16.8857\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.7530 - val_loss: 13.0338\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 12.0841 - val_loss: 12.2922\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 11.3530 - val_loss: 11.4245\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.5178 - val_loss: 11.0498\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.1353 - val_loss: 10.9854\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.7013 - val_loss: 10.9141\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.4879 - val_loss: 10.7966\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.2660 - val_loss: 10.2247\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.1426 - val_loss: 9.8801\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.0681 - val_loss: 9.9120\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 8.8837 - val_loss: 10.0331\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.7424 - val_loss: 9.6514\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.6183 - val_loss: 9.6992\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 8.5282 - val_loss: 9.6374\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.4977 - val_loss: 9.4039\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.4081 - val_loss: 9.3561\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.3515 - val_loss: 9.0037\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.4750 - val_loss: 9.5225\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2357 - val_loss: 8.8600\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2582 - val_loss: 9.1436\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 8.286 - 0s 106us/step - loss: 8.2692 - val_loss: 8.5968\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.1502 - val_loss: 8.8510\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0551 - val_loss: 8.8807\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0767 - val_loss: 8.7035\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.0119 - val_loss: 8.4688\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9372 - val_loss: 8.4421\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8322 - val_loss: 8.5412\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2140 - val_loss: 8.4310\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 8.1478 - val_loss: 8.7512\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8665 - val_loss: 8.1321\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9777 - val_loss: 8.6482\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7472 - val_loss: 8.1606\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8318 - val_loss: 8.5313\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7515 - val_loss: 8.2612\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6984 - val_loss: 7.9144\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8371 - val_loss: 8.0936\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8389 - val_loss: 8.0405\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5474 - val_loss: 8.5075\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7163 - val_loss: 7.7948\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5393 - val_loss: 8.0612\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.5041 - val_loss: 7.8855\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5087 - val_loss: 8.0359\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3705 - val_loss: 7.4846\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5272 - val_loss: 7.8206\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6856 - val_loss: 7.7632\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5099 - val_loss: 7.7459\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3555 - val_loss: 7.4509\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3998 - val_loss: 7.7607\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3763 - val_loss: 7.3726\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3132 - val_loss: 7.6154\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5361 - val_loss: 7.4946\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7278 - val_loss: 7.9534\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5454 - val_loss: 7.6384\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2888 - val_loss: 7.5973\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2741 - val_loss: 7.2547\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2675 - val_loss: 7.3747\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 7.2948 - val_loss: 7.7215\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4513 - val_loss: 7.5317\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2955 - val_loss: 7.5313\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.4951 - val_loss: 7.2862\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3394 - val_loss: 7.7637\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3669 - val_loss: 7.2295\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 7.1524 - val_loss: 7.6566\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2978 - val_loss: 7.3991\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6032 - val_loss: 7.5470\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5666 - val_loss: 7.6833\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1617 - val_loss: 7.2032\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2681 - val_loss: 7.5401\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1942 - val_loss: 7.5902\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1226 - val_loss: 7.3849\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.2607 - val_loss: 7.2160\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0870 - val_loss: 7.6460\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.4403 - val_loss: 7.2110\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.3813 - val_loss: 7.2784\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1591 - val_loss: 7.5675\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0902 - val_loss: 7.3634\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2143 - val_loss: 7.3584\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1398 - val_loss: 7.5109\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1017 - val_loss: 7.1542\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1268 - val_loss: 7.5683\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.1211 - val_loss: 7.3795\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2454 - val_loss: 7.3608\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2060 - val_loss: 7.3563\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0569 - val_loss: 7.0398\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1735 - val_loss: 7.5025\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0132 - val_loss: 7.2539\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0722 - val_loss: 7.4240\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.2126 - val_loss: 7.1809\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0546 - val_loss: 7.3201\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4979 - val_loss: 7.3712\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1687 - val_loss: 6.8380\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3710 - val_loss: 7.8942\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8816 - val_loss: 7.5381\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2122 - val_loss: 7.7475\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0874 - val_loss: 6.9932\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1122 - val_loss: 7.2887\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1083 - val_loss: 7.1584\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1189 - val_loss: 7.3488\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1316 - val_loss: 7.1132\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0866 - val_loss: 7.3351\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.0724 - val_loss: 7.0976\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.2183 - val_loss: 7.1830\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.1694 - val_loss: 7.1762\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.1992 - val_loss: 7.3142\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0451 - val_loss: 7.3546\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0149 - val_loss: 7.0546\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0478 - val_loss: 7.4775\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0097 - val_loss: 7.1657\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2023 - val_loss: 7.5840\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2211 - val_loss: 7.0734\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9969 - val_loss: 7.3049\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0408 - val_loss: 7.3215\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0711 - val_loss: 7.1575\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0600 - val_loss: 7.2851\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0120 - val_loss: 7.2965\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9876 - val_loss: 7.5539\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0994 - val_loss: 7.1132\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1233 - val_loss: 7.2353\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2091 - val_loss: 7.2123\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1532 - val_loss: 7.0090\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1250 - val_loss: 7.4496\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.1763 - val_loss: 7.0102\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3488 - val_loss: 7.9794\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4632 - val_loss: 7.3384\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0420 - val_loss: 7.0328\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1623 - val_loss: 7.3080\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1886 - val_loss: 7.0090\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1070 - val_loss: 7.2762\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0698 - val_loss: 7.1937\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2359 - val_loss: 7.0931\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2251 - val_loss: 7.2550\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 7.1342 - val_loss: 7.2300\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9768 - val_loss: 6.8874\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9677 - val_loss: 7.0831\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1141 - val_loss: 7.3598\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9834 - val_loss: 7.1405\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 7.0994 - val_loss: 7.6131\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.0335 - val_loss: 6.9054\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1055 - val_loss: 7.6164\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.0625 - val_loss: 7.0567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1353 - val_loss: 7.1130\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2444 - val_loss: 6.9751\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0482 - val_loss: 7.1621\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.1473 - val_loss: 7.1389\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0209 - val_loss: 7.0552\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1112 - val_loss: 7.5672\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1735 - val_loss: 7.1936\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0770 - val_loss: 7.3521\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.9926 - val_loss: 7.2761\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9560 - val_loss: 7.2119\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9880 - val_loss: 7.0301\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0195 - val_loss: 7.4727\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0290 - val_loss: 6.9839\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2031 - val_loss: 7.0904\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0861 - val_loss: 7.3302\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.1574 - val_loss: 6.9041\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0264 - val_loss: 7.1921\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.9551 - val_loss: 6.9879\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5022 - val_loss: 7.0680\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.3941 - val_loss: 7.0737\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1444 - val_loss: 7.1697\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1715 - val_loss: 7.3992\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.9326 - val_loss: 7.0643\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0439 - val_loss: 7.3303\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1020 - val_loss: 7.1202\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9917 - val_loss: 7.4417\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0514 - val_loss: 7.1307\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.0907 - val_loss: 7.2284\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9711 - val_loss: 7.0114\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9444 - val_loss: 6.9768\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9133 - val_loss: 7.3290\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8769 - val_loss: 7.0290\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9923 - val_loss: 7.0590\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0587 - val_loss: 7.1442\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9912 - val_loss: 7.2770\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2012 - val_loss: 7.1163\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0104 - val_loss: 6.9917\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9233 - val_loss: 7.1992\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3513 - val_loss: 6.7502\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1192 - val_loss: 7.7396\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3563 - val_loss: 6.8779\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2113 - val_loss: 7.6627\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9894 - val_loss: 7.0497\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1106 - val_loss: 7.1420\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1212 - val_loss: 7.0259\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9353 - val_loss: 7.8424\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3519 - val_loss: 6.8511\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0864 - val_loss: 6.9744\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0121 - val_loss: 7.3560\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9047 - val_loss: 6.8999\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9758 - val_loss: 7.6916\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1577 - val_loss: 7.0168\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0112 - val_loss: 7.3721\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3107 - val_loss: 6.8996\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.3044 - val_loss: 7.0317\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9852 - val_loss: 6.9536\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9911 - val_loss: 7.3157\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0886 - val_loss: 7.3268\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9529 - val_loss: 7.2495\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9615 - val_loss: 7.0775\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.9803 - val_loss: 6.8334\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1298 - val_loss: 7.8368\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1109 - val_loss: 7.0224\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0328 - val_loss: 6.9614\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9431 - val_loss: 7.6204\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0292 - val_loss: 6.9594\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9359 - val_loss: 7.2186\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9168 - val_loss: 7.1292\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1691 - val_loss: 6.9285\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4394 - val_loss: 7.8014\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2339 - val_loss: 7.3781\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4057 - val_loss: 7.4329\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2515 - val_loss: 6.8673\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4884 - val_loss: 8.0164\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3214 - val_loss: 7.0442\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 9.092 - 0s 109us/step - loss: 6.8367 - val_loss: 7.1747\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9914 - val_loss: 7.0107\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.9079 - val_loss: 7.0829\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9131 - val_loss: 7.3395\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8901 - val_loss: 7.0548\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1451 - val_loss: 6.8282\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2066 - val_loss: 7.1848\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2958 - val_loss: 7.1253\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1573 - val_loss: 7.4292\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2521 - val_loss: 6.8934\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0305 - val_loss: 7.2898\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9704 - val_loss: 6.7915\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2786 - val_loss: 7.2010\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2676 - val_loss: 7.1096\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1474 - val_loss: 7.0716\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0067 - val_loss: 7.2789\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5027 - val_loss: 6.7741\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9450 - val_loss: 7.1658\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.9727 - val_loss: 7.1333\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0188 - val_loss: 7.4651\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0583 - val_loss: 6.8416\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9914 - val_loss: 7.2178\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1868 - val_loss: 6.8784\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9896 - val_loss: 7.1707\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1072 - val_loss: 6.9378\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.3725 - val_loss: 7.2437\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9341 - val_loss: 7.4339\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9232 - val_loss: 6.8240\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.8101 - val_loss: 7.6754\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6935 - val_loss: 6.7128\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4657 - val_loss: 7.3593\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9348 - val_loss: 7.1991\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 7.1710 - val_loss: 7.0071\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9839 - val_loss: 7.5196\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4304 - val_loss: 6.7128\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.2056 - val_loss: 7.0911\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0239 - val_loss: 6.9226\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0328 - val_loss: 6.9616\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9579 - val_loss: 7.2795\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8862 - val_loss: 7.3156\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8634 - val_loss: 6.8462\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0332 - val_loss: 7.4255\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8870 - val_loss: 6.7133\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0636 - val_loss: 7.3008\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9410 - val_loss: 7.2111\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9972 - val_loss: 6.9080\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0531 - val_loss: 7.0981\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0807 - val_loss: 6.9459\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9414 - val_loss: 7.3926\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9484 - val_loss: 7.0419\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0748 - val_loss: 7.0246\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.8759 - val_loss: 7.0590\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8987 - val_loss: 7.0304\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9567 - val_loss: 7.2180\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8666 - val_loss: 6.6160\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9266 - val_loss: 7.1724\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8790 - val_loss: 7.0980\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.0190 - val_loss: 6.9102\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9344 - val_loss: 7.3983\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9487 - val_loss: 6.7334\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9812 - val_loss: 7.0385\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9985 - val_loss: 7.5374\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9550 - val_loss: 7.2054\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9264 - val_loss: 7.1555\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.9151 - val_loss: 7.1947\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9605 - val_loss: 7.0575\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9445 - val_loss: 7.4285\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9092 - val_loss: 7.0568\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.3334 - val_loss: 7.4477\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9655 - val_loss: 7.3205\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0202 - val_loss: 7.0951\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9648 - val_loss: 7.2186\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9075 - val_loss: 6.9051\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0509 - val_loss: 7.1752\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9501 - val_loss: 7.1487\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1312 - val_loss: 6.9101\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9768 - val_loss: 7.0219\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8580 - val_loss: 7.0142\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9858 - val_loss: 7.4645\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 6.8718 - val_loss: 6.9542\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8679 - val_loss: 7.6396\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9332 - val_loss: 6.9059\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8998 - val_loss: 7.1906\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9911 - val_loss: 7.5044\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9293 - val_loss: 7.1876\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0126 - val_loss: 6.8304\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0546 - val_loss: 6.7563\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0865 - val_loss: 7.1196\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9454 - val_loss: 7.2742\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8744 - val_loss: 7.0161\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0727 - val_loss: 7.4158\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3767 - val_loss: 7.0304\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0064 - val_loss: 7.9901\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2235 - val_loss: 6.7887\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9409 - val_loss: 7.4726\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0192 - val_loss: 7.6650\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8870 - val_loss: 7.1421\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9320 - val_loss: 7.2216\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8136 - val_loss: 7.2442\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9357 - val_loss: 7.2919\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8431 - val_loss: 7.2706\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.0214 - val_loss: 6.9167\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8893 - val_loss: 7.4320\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0576 - val_loss: 7.0255\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9378 - val_loss: 7.0586\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9009 - val_loss: 7.2739\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8500 - val_loss: 7.2022\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7930 - val_loss: 7.2680\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9588 - val_loss: 7.4686\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8585 - val_loss: 7.0763\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1127 - val_loss: 6.8704\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9300 - val_loss: 7.3720\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9151 - val_loss: 6.9377\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9544 - val_loss: 7.0883\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9459 - val_loss: 7.3152\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8098 - val_loss: 7.0485\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9550 - val_loss: 7.1438\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0941 - val_loss: 6.8986\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9504 - val_loss: 6.9631\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8184 - val_loss: 7.4160\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3372 - val_loss: 6.8365\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2934 - val_loss: 8.2292\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6697 - val_loss: 6.8957\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2866 - val_loss: 7.2989\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1184 - val_loss: 7.4752\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9205 - val_loss: 7.0096\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8891 - val_loss: 7.7837\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8533 - val_loss: 7.1294\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.9702 - val_loss: 7.4120\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2329 - val_loss: 7.0082\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9400 - val_loss: 6.9457\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8877 - val_loss: 7.1630\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8841 - val_loss: 7.4951\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1170 - val_loss: 6.9163\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9251 - val_loss: 7.5519\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8296 - val_loss: 7.1619\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9932 - val_loss: 7.0184\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9661 - val_loss: 7.4161\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8732 - val_loss: 7.0629\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9161 - val_loss: 7.0223\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8750 - val_loss: 7.3817\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9108 - val_loss: 7.0688\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9249 - val_loss: 7.2150\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.874 - 0s 102us/step - loss: 6.8439 - val_loss: 7.3069\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8164 - val_loss: 6.7554\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9894 - val_loss: 7.3226\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1121 - val_loss: 7.3247\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8109 - val_loss: 7.1865\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9651 - val_loss: 7.6410\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9218 - val_loss: 6.9898\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9888 - val_loss: 7.5332\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8390 - val_loss: 7.1065\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7893 - val_loss: 7.1073\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8404 - val_loss: 7.3025\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8643 - val_loss: 7.1008\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1864 - val_loss: 8.0662\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 105us/step - loss: 7.3519 - val_loss: 6.7746\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.9542 - val_loss: 7.4308\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1010 - val_loss: 6.9101\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0139 - val_loss: 7.5872\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8486 - val_loss: 6.9796\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7816 - val_loss: 7.3560\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8970 - val_loss: 7.1035\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7757 - val_loss: 7.0304\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7382 - val_loss: 7.3546\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8124 - val_loss: 7.0837\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8422 - val_loss: 7.2065\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8912 - val_loss: 7.0417\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8459 - val_loss: 7.1364\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7931 - val_loss: 7.3588\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8358 - val_loss: 6.9466\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8392 - val_loss: 7.0211\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8480 - val_loss: 7.2659\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9418 - val_loss: 7.0253\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0802 - val_loss: 6.9622\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.8055 - val_loss: 7.4688\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 122us/step - loss: 6.8658 - val_loss: 7.0144\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.7752 - val_loss: 7.2016\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.8273 - val_loss: 6.9689\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8668 - val_loss: 7.1983\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7828 - val_loss: 6.8531\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.8478 - val_loss: 7.5851\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8662 - val_loss: 7.0576\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.9570 - val_loss: 6.7751\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 6.7749 - val_loss: 7.2201\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 126us/step - loss: 6.9200 - val_loss: 7.2555\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7371 - val_loss: 7.8818\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2450 - val_loss: 6.7354\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8370 - val_loss: 7.2479\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8234 - val_loss: 7.6153\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8381 - val_loss: 7.1694\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7743 - val_loss: 7.2329\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8244 - val_loss: 7.2036\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8021 - val_loss: 7.2087\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8080 - val_loss: 7.1532\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7527 - val_loss: 7.1174\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7994 - val_loss: 7.3654\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9017 - val_loss: 7.2886\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8141 - val_loss: 6.9371\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8529 - val_loss: 7.3563\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1062 - val_loss: 7.3274\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8525 - val_loss: 7.3164\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7773 - val_loss: 6.9359\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8387 - val_loss: 6.9988\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7783 - val_loss: 7.1366\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8124 - val_loss: 7.4008\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7869 - val_loss: 7.1782\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9402 - val_loss: 7.8834\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 6.9746 - val_loss: 6.9044\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.8662 - val_loss: 7.9736\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0016 - val_loss: 6.7821\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2252 - val_loss: 7.9045\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7374 - val_loss: 6.9199\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0526 - val_loss: 7.6815\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7915 - val_loss: 7.0228\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7073 - val_loss: 7.3788\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9554 - val_loss: 7.8038\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0113 - val_loss: 6.9162\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6819 - val_loss: 7.4913\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0536 - val_loss: 6.6619\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.0156 - val_loss: 7.7043\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8102 - val_loss: 6.9655\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9516 - val_loss: 7.2747\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8728 - val_loss: 7.2347\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7821 - val_loss: 7.5641\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7705 - val_loss: 6.9822\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8840 - val_loss: 7.2180\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8267 - val_loss: 7.0854\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8502 - val_loss: 7.0913\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0022 - val_loss: 7.6158\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2288 - val_loss: 6.7986\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2778 - val_loss: 7.7884\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9664 - val_loss: 7.0017\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 7.1005 - val_loss: 7.0985\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9925 - val_loss: 7.6181\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9071 - val_loss: 7.0449\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8149 - val_loss: 7.1477\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8673 - val_loss: 6.8398\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9443 - val_loss: 7.2764\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8416 - val_loss: 6.9069\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8944 - val_loss: 7.9575\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7600 - val_loss: 6.7005\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8981 - val_loss: 7.1847\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8575 - val_loss: 7.0856\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7717 - val_loss: 7.0540\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8415 - val_loss: 6.9421\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7584 - val_loss: 6.8961\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8896 - val_loss: 7.7257\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9833 - val_loss: 6.8324\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.9466 - val_loss: 7.3304\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.7386 - val_loss: 7.0393\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7767 - val_loss: 7.3289\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.0288 - val_loss: 7.1352\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9349 - val_loss: 6.9869\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.0771 - val_loss: 7.6273\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 8.336 - 0s 113us/step - loss: 7.1673 - val_loss: 7.3307\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.8092 - val_loss: 6.8889\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.9307 - val_loss: 7.1094\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.9674 - val_loss: 7.3301\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.3496 - val_loss: 7.4878\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3666 - val_loss: 7.0007\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8809 - val_loss: 7.4059\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8759 - val_loss: 7.1255\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7370 - val_loss: 7.3368\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7344 - val_loss: 6.9903\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.7601 - val_loss: 7.0805\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7147 - val_loss: 7.1529\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7961 - val_loss: 7.4192\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7672 - val_loss: 7.0659\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7739 - val_loss: 7.6507\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2369 - val_loss: 6.7165\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2032 - val_loss: 7.6604\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.0234 - val_loss: 7.4205\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.7383 - val_loss: 7.1221\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7642 - val_loss: 7.3474\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 6.9618 - val_loss: 7.2324\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 6.9547 - val_loss: 6.9247\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 7.1069 - val_loss: 7.6455\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8661 - val_loss: 7.0129\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9132 - val_loss: 7.2665\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0712 - val_loss: 6.9135\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1370 - val_loss: 7.2375\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7663 - val_loss: 7.1187\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8116 - val_loss: 7.1598\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8944 - val_loss: 7.3231\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1270 - val_loss: 6.8862\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9537 - val_loss: 7.5171\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8287 - val_loss: 6.8858\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0220 - val_loss: 7.3773\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8016 - val_loss: 7.1981\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9107 - val_loss: 6.5965\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.0072 - val_loss: 7.5686\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7572 - val_loss: 7.0115\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.8241 - val_loss: 7.3887\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7886 - val_loss: 7.3885\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7414 - val_loss: 7.4737\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7418 - val_loss: 6.8210\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7266 - val_loss: 7.2418\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9139 - val_loss: 7.4041\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9352 - val_loss: 6.9256\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4933 - val_loss: 8.5876\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2250 - val_loss: 6.8877\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2185 - val_loss: 7.6222\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9373 - val_loss: 6.9942\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.4003 - val_loss: 7.0739\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1058 - val_loss: 7.4956\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7487 - val_loss: 6.9744\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.8318 - val_loss: 7.3789\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.7217 - val_loss: 6.8625\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8850 - val_loss: 7.0386\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 104us/step - loss: 6.9323 - val_loss: 7.2891\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7802 - val_loss: 7.1768\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8345 - val_loss: 7.2966\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8959 - val_loss: 7.3738\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7624 - val_loss: 7.0701\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9629 - val_loss: 7.1778\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7604 - val_loss: 7.3251\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9395 - val_loss: 6.6934\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.3551 - val_loss: 8.4259\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0187 - val_loss: 6.8364\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8702 - val_loss: 7.4855\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9500 - val_loss: 6.7706\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9608 - val_loss: 7.5222\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8519 - val_loss: 7.2801\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0626 - val_loss: 6.7659\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.2802 - val_loss: 7.5219\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7985 - val_loss: 6.9445\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4320 - val_loss: 9.0385\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5596 - val_loss: 6.7101\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1748 - val_loss: 8.2745\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0440 - val_loss: 6.7502\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8096 - val_loss: 7.4740\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1351 - val_loss: 7.4163\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2068 - val_loss: 6.6531\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2632 - val_loss: 7.9031\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8807 - val_loss: 7.2609\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1410 - val_loss: 7.8640\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1353 - val_loss: 6.7073\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1642 - val_loss: 7.5252\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8784 - val_loss: 7.1065\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8071 - val_loss: 7.1745\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8419 - val_loss: 7.4979\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8956 - val_loss: 6.9893\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5083 - val_loss: 7.9584\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8758 - val_loss: 7.0091\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8670 - val_loss: 7.2736\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7754 - val_loss: 7.1181\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8762 - val_loss: 7.2733\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8638 - val_loss: 7.2412\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.2922 - val_loss: 6.8347\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3361 - val_loss: 8.1619\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9863 - val_loss: 7.2862\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7763 - val_loss: 7.1350\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8407 - val_loss: 7.0710\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8846 - val_loss: 7.4838\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9076 - val_loss: 6.9539\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1290 - val_loss: 7.6777\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9921 - val_loss: 7.3327\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.9379 - val_loss: 6.8068\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8808 - val_loss: 7.2698\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8197 - val_loss: 7.9699\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7911 - val_loss: 6.9122\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8187 - val_loss: 7.2363\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7524 - val_loss: 7.1533\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8086 - val_loss: 7.3880\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8883 - val_loss: 7.1019\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8257 - val_loss: 7.2871\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8178 - val_loss: 7.2830\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6976 - val_loss: 7.2515\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8189 - val_loss: 7.3252\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7977 - val_loss: 7.3144\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0552 - val_loss: 7.7054\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0607 - val_loss: 6.9551\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9615 - val_loss: 7.6128\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8289 - val_loss: 7.2650\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7898 - val_loss: 7.1177\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0204 - val_loss: 7.2471\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1252 - val_loss: 7.5261\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.0668 - val_loss: 7.4165\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7443 - val_loss: 7.1921\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8819 - val_loss: 7.8691\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8017 - val_loss: 7.0912\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0389 - val_loss: 7.7500\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8808 - val_loss: 6.7914\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6158 - val_loss: 8.5973\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2273 - val_loss: 7.1070\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8109 - val_loss: 7.9513\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 6.9727 - val_loss: 7.4698\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8653 - val_loss: 7.2513\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8814 - val_loss: 7.3432\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8673 - val_loss: 6.9517\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2966 - val_loss: 8.1773\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0362 - val_loss: 6.9191\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.1176 - val_loss: 8.1690\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1219 - val_loss: 6.7191\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8279 - val_loss: 7.6421\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8000 - val_loss: 7.3465\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7238 - val_loss: 7.6142\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7158 - val_loss: 6.8695\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.989 - 0s 113us/step - loss: 6.8438 - val_loss: 7.6734\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8209 - val_loss: 7.2967\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7947 - val_loss: 7.0193\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6907 - val_loss: 7.8179\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8517 - val_loss: 6.9694\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.8166 - val_loss: 7.3709\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.7700 - val_loss: 7.4292\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6908 - val_loss: 7.0039\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6901 - val_loss: 7.3117\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8673 - val_loss: 7.7102\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8169 - val_loss: 7.0315\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7459 - val_loss: 7.4636\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7259 - val_loss: 6.9568\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8783 - val_loss: 8.1124\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1092 - val_loss: 7.1363\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8103 - val_loss: 7.4463\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1946 - val_loss: 8.1213\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9925 - val_loss: 7.4264\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8181 - val_loss: 6.9175\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8004 - val_loss: 8.0629\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9267 - val_loss: 7.4533\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7933 - val_loss: 7.2287\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8586 - val_loss: 7.2706\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9013 - val_loss: 7.3793\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6889 - val_loss: 7.7490\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7780 - val_loss: 7.3307\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6936 - val_loss: 7.4135\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7579 - val_loss: 7.1193\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8964 - val_loss: 7.8551\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7303 - val_loss: 7.8358\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8459 - val_loss: 7.7564\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8368 - val_loss: 6.9544\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6470 - val_loss: 7.5795\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7915 - val_loss: 7.5000\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7089 - val_loss: 7.4479\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.6800 - val_loss: 7.3006\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6866 - val_loss: 7.6709\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8865 - val_loss: 8.0576\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.2080 - val_loss: 6.9569\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9155 - val_loss: 7.6776\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8417 - val_loss: 7.5279\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8643 - val_loss: 7.2960\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.9339 - val_loss: 7.9710\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0638 - val_loss: 6.9662\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6794 - val_loss: 7.7686\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7910 - val_loss: 7.0018\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7675 - val_loss: 7.7939\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8456 - val_loss: 6.9718\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1796 - val_loss: 8.4159\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.2151 - val_loss: 7.2136\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8560 - val_loss: 7.8412\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0187 - val_loss: 7.3392\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.0013 - val_loss: 7.1718\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3576 - val_loss: 8.7972\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3496 - val_loss: 7.0573\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8922 - val_loss: 7.5847\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6932 - val_loss: 7.3635\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9526 - val_loss: 7.2027\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9807 - val_loss: 8.1125\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9168 - val_loss: 7.0919\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9714 - val_loss: 7.9940\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7398 - val_loss: 7.1137\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8113 - val_loss: 8.2643\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8305 - val_loss: 7.2319\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7628 - val_loss: 7.4395\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 6.6923 - val_loss: 7.5647\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7844 - val_loss: 7.7770\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7920 - val_loss: 7.0852\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.7441 - val_loss: 7.7453\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7728 - val_loss: 7.0737\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9674 - val_loss: 7.6032\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7522 - val_loss: 7.3351\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9035 - val_loss: 7.2183\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8386 - val_loss: 7.6295\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0508 - val_loss: 7.0952\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.5753 - val_loss: 9.0401\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1085 - val_loss: 7.2193\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1686 - val_loss: 8.8490\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.1688 - val_loss: 7.1846\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7079 - val_loss: 7.8531\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7260 - val_loss: 7.1068\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9346 - val_loss: 8.2729\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.5158 - val_loss: 7.1542\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9975 - val_loss: 8.1009\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2363 - val_loss: 6.9320\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8485 - val_loss: 7.5167\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7864 - val_loss: 7.5997\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7616 - val_loss: 7.5949\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7031 - val_loss: 7.4133\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7836 - val_loss: 7.3936\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.6661 - val_loss: 7.5366\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9191 - val_loss: 7.1329\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0567 - val_loss: 7.3406\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7202 - val_loss: 7.1644\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9173 - val_loss: 7.9534\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1777 - val_loss: 7.1785\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7928 - val_loss: 7.6026\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9341 - val_loss: 7.9240\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8935 - val_loss: 7.3211\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7699 - val_loss: 7.3548\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7273 - val_loss: 7.2642\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6607 - val_loss: 7.2969\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9247 - val_loss: 7.5849\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7116 - val_loss: 7.6036\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7645 - val_loss: 7.1826\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7849 - val_loss: 7.6095\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7022 - val_loss: 7.3118\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7924 - val_loss: 7.1727\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7348 - val_loss: 7.3875\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6586 - val_loss: 7.7697\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7545 - val_loss: 7.3280\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.6889 - val_loss: 7.6454\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7465 - val_loss: 7.2022\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7634 - val_loss: 7.4700\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.2707 - val_loss: 7.8100\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.1059 - val_loss: 7.0324\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8257 - val_loss: 7.4927\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6908 - val_loss: 7.4460\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7347 - val_loss: 7.4059\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9788 - val_loss: 8.4538\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7997 - val_loss: 7.0634\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7601 - val_loss: 7.2463\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7792 - val_loss: 7.4777\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9058 - val_loss: 7.1600\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8933 - val_loss: 8.1163\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6262 - val_loss: 7.0489\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6822 - val_loss: 7.4549\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7518 - val_loss: 7.1396\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8249 - val_loss: 7.8289\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6375 - val_loss: 7.4397\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6782 - val_loss: 7.3565\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7703 - val_loss: 7.2387\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6955 - val_loss: 7.1163\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6028 - val_loss: 7.4841\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.6605 - val_loss: 7.2146\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9964 - val_loss: 7.1956\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8306 - val_loss: 7.6028\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6950 - val_loss: 7.4110\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6744 - val_loss: 7.3681\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1422 - val_loss: 6.9801\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4361 - val_loss: 8.6883\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3622 - val_loss: 7.1373\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 6.8376 - val_loss: 7.7594\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9004 - val_loss: 7.0841\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7317 - val_loss: 8.0797\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1654 - val_loss: 7.1168\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8275 - val_loss: 7.8306\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7723 - val_loss: 7.2327\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6548 - val_loss: 7.2276\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.8195 - val_loss: 7.4023\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7272 - val_loss: 7.5967\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6372 - val_loss: 7.5842\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7290 - val_loss: 7.4005\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6583 - val_loss: 7.5240\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 2.136 - 0s 113us/step - loss: 6.6724 - val_loss: 7.3221\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6954 - val_loss: 7.4881\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 6.6832 - val_loss: 7.4983\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7484 - val_loss: 7.6620\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1657 - val_loss: 7.1056\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8581 - val_loss: 7.6892\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8834 - val_loss: 7.2625\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6457 - val_loss: 7.6168\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6571 - val_loss: 7.4775\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8704 - val_loss: 7.2434\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3575 - val_loss: 9.0469\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5943 - val_loss: 7.2348\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5011 - val_loss: 8.0175\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6781 - val_loss: 7.1191\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.7674 - val_loss: 7.5447\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7619 - val_loss: 7.0710\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0840 - val_loss: 7.6966\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6815 - val_loss: 7.1720\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2095 - val_loss: 7.9294\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8159 - val_loss: 7.2507\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6178 - val_loss: 7.5133\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6162 - val_loss: 7.2901\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7290 - val_loss: 7.7811\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.8669 - val_loss: 7.2774\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6668 - val_loss: 7.1918\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9219 - val_loss: 7.7603\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6522 - val_loss: 7.4106\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6529 - val_loss: 7.3711\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9425 - val_loss: 7.0101\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.8313 - val_loss: 7.8584\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9222 - val_loss: 7.1657\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8630 - val_loss: 7.5216\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5893 - val_loss: 7.5817\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7996 - val_loss: 6.9421\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6827 - val_loss: 7.4792\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8526 - val_loss: 7.5514\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5715 - val_loss: 7.8345\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7153 - val_loss: 7.2015\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8447 - val_loss: 7.0914\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6309 - val_loss: 7.7420\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7106 - val_loss: 7.4489\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6750 - val_loss: 7.1864\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6007 - val_loss: 7.4088\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7567 - val_loss: 7.2247\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.7843 - val_loss: 7.2744\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6314 - val_loss: 7.4506\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7213 - val_loss: 7.1821\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3879 - val_loss: 7.0211\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7378 - val_loss: 7.2057\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6689 - val_loss: 7.4779\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7634 - val_loss: 7.5570\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6023 - val_loss: 7.4394\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7573 - val_loss: 7.2577\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.6487 - val_loss: 7.1235\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9423 - val_loss: 8.3994\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8577 - val_loss: 7.0582\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5940 - val_loss: 7.6168\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6593 - val_loss: 7.2867\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7285 - val_loss: 7.3505\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6747 - val_loss: 7.2582\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6605 - val_loss: 7.7873\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7324 - val_loss: 7.2602\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6312 - val_loss: 7.4698\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6284 - val_loss: 7.0920\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5759 - val_loss: 7.5502\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 6.6321 - val_loss: 7.0888\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9545 - val_loss: 8.0635\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8066 - val_loss: 7.3161\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7191 - val_loss: 7.5617\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6932 - val_loss: 6.9099\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9404 - val_loss: 8.2741\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7860 - val_loss: 7.1998\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7915 - val_loss: 7.1843\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7038 - val_loss: 7.6326\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.6272 - val_loss: 7.2956\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8898 - val_loss: 8.3702\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0033 - val_loss: 6.9181\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.8676 - val_loss: 7.5375\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.7940 - val_loss: 7.0042\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7309 - val_loss: 7.6217\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6371 - val_loss: 7.3358\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5849 - val_loss: 7.5357\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5786 - val_loss: 7.3662\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6146 - val_loss: 7.2092\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5655 - val_loss: 7.3111\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7244 - val_loss: 7.2398\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6431 - val_loss: 7.4942\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7142 - val_loss: 7.2689\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9487 - val_loss: 7.6779\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7730 - val_loss: 7.0487\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1689 - val_loss: 8.1488\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0154 - val_loss: 6.9942\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8221 - val_loss: 7.4169\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7698 - val_loss: 7.4959\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6079 - val_loss: 7.4910\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5895 - val_loss: 7.1125\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6104 - val_loss: 7.3710\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6983 - val_loss: 7.8122\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9225 - val_loss: 7.1750\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7656 - val_loss: 7.4242\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.6818 - val_loss: 7.4406\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6464 - val_loss: 7.5359\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5515 - val_loss: 7.3750\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.5561 - val_loss: 7.1096\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5853 - val_loss: 7.7727\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.8361 - val_loss: 6.9983\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8921 - val_loss: 7.9938\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6971 - val_loss: 7.0468\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6790 - val_loss: 8.8948\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.0354 - val_loss: 7.2051\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6909 - val_loss: 7.1764\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6327 - val_loss: 7.0631\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6786 - val_loss: 7.2651\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6935 - val_loss: 7.4815\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7088 - val_loss: 7.1645\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6683 - val_loss: 7.5025\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7633 - val_loss: 7.7713\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7097 - val_loss: 7.0057\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7088 - val_loss: 7.8266\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6018 - val_loss: 7.2718\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5966 - val_loss: 7.8158\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6613 - val_loss: 7.6917\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6444 - val_loss: 7.2082\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8719 - val_loss: 7.1060\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6769 - val_loss: 7.8373\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8033 - val_loss: 7.2034\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7462 - val_loss: 7.8294\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7166 - val_loss: 7.0279\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6147 - val_loss: 7.3599\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6514 - val_loss: 7.5723\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6209 - val_loss: 7.3785\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5459 - val_loss: 7.3251\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9132 - val_loss: 6.9266\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7673 - val_loss: 7.9216\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.8775 - val_loss: 7.5162\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6370 - val_loss: 7.7731\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6495 - val_loss: 7.1987\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6309 - val_loss: 7.4017\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6766 - val_loss: 7.0576\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7327 - val_loss: 7.2700\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6783 - val_loss: 7.3305\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0336 - val_loss: 8.0605\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 110us/step - loss: 6.8732 - val_loss: 7.1529\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7849 - val_loss: 7.0576\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5887 - val_loss: 7.6631\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6377 - val_loss: 7.2664\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.1480 - val_loss: 8.1610\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6477 - val_loss: 6.9351\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6204 - val_loss: 7.8382\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0370 - val_loss: 7.2649\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7834 - val_loss: 7.1367\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0470 - val_loss: 7.8222\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9678 - val_loss: 7.2329\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5040 - val_loss: 7.4198\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6051 - val_loss: 7.0738\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.8286 - val_loss: 7.8108\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5858 - val_loss: 6.8739\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7316 - val_loss: 8.2266\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7693 - val_loss: 7.1667\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7087 - val_loss: 7.6020\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4553 - val_loss: 7.0434\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9081 - val_loss: 7.6875\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7939 - val_loss: 7.0309\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8225 - val_loss: 7.0775\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6413 - val_loss: 7.4964\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6230 - val_loss: 7.4774\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6919 - val_loss: 8.0132\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8088 - val_loss: 6.9036\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8123 - val_loss: 7.2496\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5379 - val_loss: 7.5773\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6422 - val_loss: 7.6237\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6302 - val_loss: 7.2740\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5585 - val_loss: 7.5004\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7183 - val_loss: 7.1309\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8236 - val_loss: 7.6598\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6139 - val_loss: 7.2772\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5188 - val_loss: 7.1271\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6609 - val_loss: 7.7956\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6382 - val_loss: 7.4491\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6263 - val_loss: 7.1469\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7101 - val_loss: 7.0728\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6548 - val_loss: 7.2888\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6535 - val_loss: 7.1291\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5555 - val_loss: 7.1812\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4891 - val_loss: 8.1453\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7707 - val_loss: 7.1170\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5728 - val_loss: 7.3250\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5123 - val_loss: 7.2601\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4896 - val_loss: 7.4844\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6026 - val_loss: 7.3462\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9040 - val_loss: 8.0829\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3701 - val_loss: 6.9910\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5679 - val_loss: 8.5245\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8967 - val_loss: 7.2571\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.1334 - val_loss: 8.3212\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7048 - val_loss: 7.2417\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5882 - val_loss: 7.1529\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4856 - val_loss: 7.2254\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5285 - val_loss: 7.5920\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6131 - val_loss: 7.0810\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.6948 - val_loss: 7.2249\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.5313 - val_loss: 7.3798\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5678 - val_loss: 7.3279\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5946 - val_loss: 7.5101\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5321 - val_loss: 7.3505\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6771 - val_loss: 7.6690\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 6.5522 - val_loss: 7.0556\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7103 - val_loss: 7.3297\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7970 - val_loss: 7.0957\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6666 - val_loss: 7.2715\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7162 - val_loss: 7.1912\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5607 - val_loss: 7.3555\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6307 - val_loss: 7.7161\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7703 - val_loss: 7.1305\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6006 - val_loss: 7.2268\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6820 - val_loss: 7.6284\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6736 - val_loss: 7.2098\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5446 - val_loss: 7.4457\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5919 - val_loss: 7.3212\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 6.6297 - val_loss: 7.3738\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9177 - val_loss: 6.9971\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6375 - val_loss: 7.4315\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8660 - val_loss: 7.0146\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7706 - val_loss: 7.5698\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5888 - val_loss: 7.1267\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5662 - val_loss: 7.2283\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5711 - val_loss: 7.5257\n",
      "5.16731866739564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-2.3778477e-01,  4.7207379e-01,  1.0587238e+00, -4.7740924e-01,\n",
       "         -6.6336977e-01],\n",
       "        [-4.1890949e-01,  3.0460006e-01, -1.2836611e-01, -1.1081041e+00,\n",
       "          3.8351077e-01],\n",
       "        [-8.9037590e-02, -1.0113994e+00, -1.0715749e+00, -1.8192314e-01,\n",
       "          2.6511472e-01],\n",
       "        [-3.0521601e-01,  2.7581352e-01, -1.5902560e+00,  4.7203210e-01,\n",
       "         -1.5644250e-03],\n",
       "        [-1.0334246e+00,  2.3423942e-02,  2.4775465e-01, -2.3613258e-01,\n",
       "          2.0111036e-01],\n",
       "        [-7.7294558e-01,  7.8259498e-01,  3.4123483e-01, -9.2104053e-01,\n",
       "          1.3687657e+00],\n",
       "        [-1.6271433e+00, -3.6115530e-01,  1.1644647e+00, -1.6612518e-01,\n",
       "         -3.4967187e-01]], dtype=float32),\n",
       " array([0.3951535 , 0.95498943, 0.40515965, 1.2461897 , 1.5125704 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.04313226,  0.6350163 ,  0.566217  , -0.30702314,  0.0217797 ,\n",
       "          0.47691074,  0.15866761, -0.5526673 ,  0.01500894,  0.23430908],\n",
       "        [ 0.57161313,  0.02640379,  0.07566023, -0.3185977 , -0.5369109 ,\n",
       "          0.5081208 , -0.26684442, -0.4053704 ,  0.17060101,  0.9415672 ],\n",
       "        [ 0.36374408,  0.5567055 ,  1.0743563 , -0.38808283, -0.9532249 ,\n",
       "          0.5056134 ,  1.0457529 , -0.69051754, -0.31666234,  0.33712658],\n",
       "        [ 0.23686853,  1.2635839 ,  0.49797502, -0.5148407 , -0.86350054,\n",
       "          0.12061656, -0.04006773, -0.41587967,  0.02986485,  0.5676199 ],\n",
       "        [ 0.42976698,  1.0082508 ,  0.1619258 , -0.510124  , -0.30094174,\n",
       "          0.24073718,  0.47823673, -0.3257219 ,  0.3789027 ,  1.0745374 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.90244204,  1.0483664 ,  1.0497453 , -0.62744844, -0.57133275,\n",
       "         0.8824256 ,  1.0773735 , -0.60262907,  0.38087067,  1.0550146 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.53586847],\n",
       "        [ 1.1706265 ],\n",
       "        [ 0.94175434],\n",
       "        [ 0.11458423],\n",
       "        [ 0.27976158],\n",
       "        [ 0.48027578],\n",
       "        [ 0.8468778 ],\n",
       "        [ 0.17235832],\n",
       "        [-0.0181317 ],\n",
       "        [ 1.1083875 ]], dtype=float32),\n",
       " array([1.1423874], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_relu(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 844us/step - loss: 520.1219 - val_loss: 432.3143\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 324.9245 - val_loss: 255.9185\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 186.5324 - val_loss: 151.2386\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 113.6954 - val_loss: 98.8981\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 80.9394 - val_loss: 75.2386\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 67.0853 - val_loss: 65.5721\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 63.2516 - val_loss: 61.7920\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.6187 - val_loss: 60.6343\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3194 - val_loss: 60.3491\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3468 - val_loss: 60.2394\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.4284 - val_loss: 60.1127\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3842 - val_loss: 60.1670\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3590 - val_loss: 60.2096\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.3537 - val_loss: 60.3258\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.3290 - val_loss: 60.3205\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3491 - val_loss: 60.1994\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3048 - val_loss: 60.2560\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.3106 - val_loss: 60.3691\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2761 - val_loss: 60.3127\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2640 - val_loss: 60.2976\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2081 - val_loss: 60.0643\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 60.8689 - val_loss: 58.8793\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 54.0743 - val_loss: 50.3019\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 48.0296 - val_loss: 48.4544\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 46.8424 - val_loss: 46.5625\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 45.7777 - val_loss: 44.9756\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 44.8427 - val_loss: 43.8292\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 43.9520 - val_loss: 42.9546\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 43.0102 - val_loss: 42.2012\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 42.0031 - val_loss: 41.5785\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 41.3589 - val_loss: 41.0142\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 40.8884 - val_loss: 40.4160\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 40.3817 - val_loss: 39.9048\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 39.7853 - val_loss: 39.4046\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 39.2441 - val_loss: 38.9502\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 38.7159 - val_loss: 38.4335\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 38.1695 - val_loss: 38.1139\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 37.5734 - val_loss: 37.4596\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 37.0370 - val_loss: 37.2758\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 36.4891 - val_loss: 36.7287\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 36.0310 - val_loss: 36.3084\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 35.5887 - val_loss: 36.0750\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 35.1453 - val_loss: 35.6759\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 34.7138 - val_loss: 35.4176\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 34.2804 - val_loss: 35.1887\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 33.9164 - val_loss: 34.9967\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 33.4985 - val_loss: 34.8450\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 33.0954 - val_loss: 34.8065\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 32.6968 - val_loss: 34.7598\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 32.3358 - val_loss: 34.6891\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 31.9307 - val_loss: 34.6304\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 31.5761 - val_loss: 34.3212\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 31.2043 - val_loss: 33.8364\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 30.8207 - val_loss: 33.5320\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 30.4326 - val_loss: 33.0719\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 30.0849 - val_loss: 32.7287\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 29.7303 - val_loss: 32.3075\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 29.3910 - val_loss: 31.9325\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 29.0516 - val_loss: 31.6774\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 28.7065 - val_loss: 31.1907\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 28.4153 - val_loss: 30.9636\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 28.1574 - val_loss: 30.8279\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 27.8335 - val_loss: 30.3751\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 27.5172 - val_loss: 30.0826\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 27.2533 - val_loss: 29.8495\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 26.9616 - val_loss: 29.5329\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 26.6920 - val_loss: 29.2801\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 26.4095 - val_loss: 29.0198\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 26.1360 - val_loss: 28.7296\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 25.8938 - val_loss: 28.5167\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 25.6289 - val_loss: 28.3567\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 25.4279 - val_loss: 27.9689\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 25.1744 - val_loss: 27.7100\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 24.9756 - val_loss: 27.4175\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 24.6744 - val_loss: 27.2755\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 24.5203 - val_loss: 27.0549\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 24.2800 - val_loss: 26.7525\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 24.0036 - val_loss: 26.5911\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 23.7843 - val_loss: 26.0697\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 21.5224 - val_loss: 21.6864\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 18.2884 - val_loss: 21.1838\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 17.7902 - val_loss: 20.3928\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 17.1231 - val_loss: 19.7969\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 16.5623 - val_loss: 19.3993\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 16.1769 - val_loss: 19.0052\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.8841 - val_loss: 18.8381\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 15.6692 - val_loss: 18.6891\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.4042 - val_loss: 18.6595\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 15.2514 - val_loss: 18.5263\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 15.0464 - val_loss: 18.5005\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.8943 - val_loss: 18.3824\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.7881 - val_loss: 18.3257\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.6449 - val_loss: 18.1418\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.3981 - val_loss: 18.0601\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.2045 - val_loss: 17.6947\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.1239 - val_loss: 16.0285\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.7022 - val_loss: 15.8333\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.2695 - val_loss: 15.5264\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.9281 - val_loss: 15.2736\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 10.7197 - val_loss: 15.2587\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 10.5454 - val_loss: 14.8675\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 10.4662 - val_loss: 14.8200\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.3568 - val_loss: 14.9119\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.2692 - val_loss: 14.9241\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 10.1178 - val_loss: 14.8469\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.1971 - val_loss: 14.5740\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.0907 - val_loss: 14.8087\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 9.9459 - val_loss: 14.4446\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.8588 - val_loss: 14.6212\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.7973 - val_loss: 14.3586\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 9.7216 - val_loss: 14.0769\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 9.6693 - val_loss: 13.9268\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.5768 - val_loss: 13.9270\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 9.5162 - val_loss: 13.8405\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 9.4358 - val_loss: 13.6535\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.3625 - val_loss: 13.5100\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.2896 - val_loss: 13.2541\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.2116 - val_loss: 13.1810\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.0939 - val_loss: 13.0146\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 9.0204 - val_loss: 12.8324\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.9552 - val_loss: 12.7389\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.9042 - val_loss: 12.5760\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.7396 - val_loss: 12.7686\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.8415 - val_loss: 12.6763\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.6872 - val_loss: 12.4078\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.6585 - val_loss: 12.5775\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 8.5482 - val_loss: 12.4350\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 8.5958 - val_loss: 12.3829\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.5020 - val_loss: 12.3906\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.4191 - val_loss: 12.4077\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.3625 - val_loss: 12.3214\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 8.3200 - val_loss: 12.1916\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.3932 - val_loss: 12.1956\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.3844 - val_loss: 11.9966\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2791 - val_loss: 12.0871\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 8.2357 - val_loss: 11.9251\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1356 - val_loss: 12.0115\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.1113 - val_loss: 11.9036\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0728 - val_loss: 11.9803\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.0417 - val_loss: 11.7893\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0310 - val_loss: 11.7088\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.9553 - val_loss: 11.6589\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9260 - val_loss: 11.6829\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.9096 - val_loss: 11.5716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8638 - val_loss: 11.5839\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8337 - val_loss: 11.6146\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 7.7940 - val_loss: 11.5575\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.7676 - val_loss: 11.3887\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.7551 - val_loss: 11.3561\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7143 - val_loss: 11.2511\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6895 - val_loss: 11.3968\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6269 - val_loss: 11.3443\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6154 - val_loss: 11.1872\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.6194 - val_loss: 11.1779\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5768 - val_loss: 11.1156\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.5312 - val_loss: 11.1588\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4796 - val_loss: 11.2097\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4907 - val_loss: 11.1535\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.4395 - val_loss: 11.0154\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.4164 - val_loss: 11.0598\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.3975 - val_loss: 10.9923\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3948 - val_loss: 11.0222\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3261 - val_loss: 11.0477\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3232 - val_loss: 11.0167\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3045 - val_loss: 10.9990\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.2843 - val_loss: 10.9085\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2623 - val_loss: 10.7808\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3786 - val_loss: 10.8461\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2987 - val_loss: 10.9698\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2559 - val_loss: 10.9939\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2265 - val_loss: 10.8033\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2518 - val_loss: 10.9075\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.1394 - val_loss: 10.8143\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2230 - val_loss: 10.7319\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0833 - val_loss: 10.7114\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.0692 - val_loss: 10.8083\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0695 - val_loss: 10.7509\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0592 - val_loss: 10.8055\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0447 - val_loss: 10.8749\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0427 - val_loss: 10.6943\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9678 - val_loss: 10.7309\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9830 - val_loss: 10.7816\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9171 - val_loss: 10.7259\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9283 - val_loss: 10.6763\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9259 - val_loss: 10.6501\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8925 - val_loss: 10.5842\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.8857 - val_loss: 10.5858\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8940 - val_loss: 10.6053\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8328 - val_loss: 10.5534\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8727 - val_loss: 10.6934\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7754 - val_loss: 10.8350\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8271 - val_loss: 10.8124\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7916 - val_loss: 10.7089\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7635 - val_loss: 10.6343\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7464 - val_loss: 10.6851\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7704 - val_loss: 10.6353\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7038 - val_loss: 10.6445\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7651 - val_loss: 10.6710\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6999 - val_loss: 10.5679\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7090 - val_loss: 10.5718\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6931 - val_loss: 10.6585\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7014 - val_loss: 10.6788\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6658 - val_loss: 10.7040\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6780 - val_loss: 10.5127\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6613 - val_loss: 10.6069\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6535 - val_loss: 10.5290\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6134 - val_loss: 10.5858\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6376 - val_loss: 10.3670\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6264 - val_loss: 10.3881\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5785 - val_loss: 10.4748\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5898 - val_loss: 10.5334\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5665 - val_loss: 10.5460\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5833 - val_loss: 10.5562\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5228 - val_loss: 10.4055\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.5160 - val_loss: 10.3912\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5351 - val_loss: 10.3623\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5327 - val_loss: 10.4287\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4648 - val_loss: 10.3836\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4715 - val_loss: 10.3504\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4892 - val_loss: 10.2958\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4537 - val_loss: 10.3698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4785 - val_loss: 10.4123\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4664 - val_loss: 10.4083\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4423 - val_loss: 10.1116\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4303 - val_loss: 10.0477\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4262 - val_loss: 10.2298\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4640 - val_loss: 10.2381\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4699 - val_loss: 10.0734\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4952 - val_loss: 10.0354\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4890 - val_loss: 10.1273\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4225 - val_loss: 10.2587\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4942 - val_loss: 10.0765\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3679 - val_loss: 10.1086\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3783 - val_loss: 9.8791\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3601 - val_loss: 9.9788\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4054 - val_loss: 10.0691\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3401 - val_loss: 9.9207\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3265 - val_loss: 9.8840\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3406 - val_loss: 9.8871\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3250 - val_loss: 10.1014\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3368 - val_loss: 10.0848\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2941 - val_loss: 9.9002\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3163 - val_loss: 9.9537\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3231 - val_loss: 9.7764\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2846 - val_loss: 9.7302\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2505 - val_loss: 9.7894\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2612 - val_loss: 9.7386\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2499 - val_loss: 9.7758\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2860 - val_loss: 9.8177\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2579 - val_loss: 9.6942\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2590 - val_loss: 9.8622\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2384 - val_loss: 9.8713\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2250 - val_loss: 9.6519\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2322 - val_loss: 9.6671\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2214 - val_loss: 9.6082\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2219 - val_loss: 9.7868\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2197 - val_loss: 9.8081\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2320 - val_loss: 9.6626\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1942 - val_loss: 9.5373\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2086 - val_loss: 9.5028\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.2747 - val_loss: 9.4387\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1855 - val_loss: 9.5258\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1523 - val_loss: 9.4900\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.1802 - val_loss: 9.3697\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1737 - val_loss: 9.3454\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1720 - val_loss: 9.4576\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1708 - val_loss: 9.3115\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1244 - val_loss: 9.2536\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1405 - val_loss: 9.2594\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1268 - val_loss: 9.2035\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1030 - val_loss: 9.2764\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1125 - val_loss: 9.3295\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1105 - val_loss: 9.3033\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0895 - val_loss: 9.1375\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0605 - val_loss: 9.0889\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0742 - val_loss: 9.1422\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0529 - val_loss: 9.0900\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0686 - val_loss: 8.9620\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0457 - val_loss: 9.0200\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0585 - val_loss: 8.9904\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0432 - val_loss: 8.9610\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0234 - val_loss: 9.0482\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0498 - val_loss: 9.0189\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0250 - val_loss: 8.8235\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9955 - val_loss: 8.8011\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0674 - val_loss: 9.0262\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9941 - val_loss: 8.9815\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0119 - val_loss: 8.8027\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.9920 - val_loss: 8.8362\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0003 - val_loss: 8.8909\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9597 - val_loss: 8.6937\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9444 - val_loss: 8.6951\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9280 - val_loss: 8.6088\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9180 - val_loss: 8.6320\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9251 - val_loss: 8.6302\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9784 - val_loss: 8.3379\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9145 - val_loss: 8.6459\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8677 - val_loss: 8.5039\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 104us/step - loss: 5.8409 - val_loss: 8.3841\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8963 - val_loss: 8.5775\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8937 - val_loss: 8.7220\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8464 - val_loss: 8.4685\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8469 - val_loss: 8.5426\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8652 - val_loss: 8.5221\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8656 - val_loss: 8.5405\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9015 - val_loss: 8.6900\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8554 - val_loss: 8.4568\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7764 - val_loss: 8.4170\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7888 - val_loss: 8.7111\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7888 - val_loss: 8.5624\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7630 - val_loss: 8.6548\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7615 - val_loss: 8.6825\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7678 - val_loss: 8.5758\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7406 - val_loss: 8.5814\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7379 - val_loss: 8.5970\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7419 - val_loss: 8.6832\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7573 - val_loss: 8.6882\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7149 - val_loss: 8.5543\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7523 - val_loss: 8.5407\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7118 - val_loss: 8.6665\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7267 - val_loss: 8.6863\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7063 - val_loss: 8.6298\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7149 - val_loss: 8.4956\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7027 - val_loss: 8.5598\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7122 - val_loss: 8.6492\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6825 - val_loss: 8.7163\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6819 - val_loss: 8.5922\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6978 - val_loss: 8.6567\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6700 - val_loss: 8.7206\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6730 - val_loss: 8.6522\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6566 - val_loss: 8.7106\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6705 - val_loss: 8.4796\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6773 - val_loss: 8.5484\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6355 - val_loss: 8.4906\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6465 - val_loss: 8.6504\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6678 - val_loss: 8.6316\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6223 - val_loss: 8.7109\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6653 - val_loss: 8.7255\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6435 - val_loss: 8.7385\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6618 - val_loss: 8.7711\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6457 - val_loss: 8.5999\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6160 - val_loss: 8.7685\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6384 - val_loss: 8.7806\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6166 - val_loss: 8.6836\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6088 - val_loss: 8.6984\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6642 - val_loss: 8.8341\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6415 - val_loss: 8.6894\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6079 - val_loss: 8.7920\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6998 - val_loss: 8.7239\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7045 - val_loss: 8.4970\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6072 - val_loss: 8.7735\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6073 - val_loss: 8.8212\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.6090 - val_loss: 8.8633\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5945 - val_loss: 8.7923\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5612 - val_loss: 8.6118\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.6416 - val_loss: 8.4616\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6529 - val_loss: 8.5697\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6060 - val_loss: 8.7342\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6437 - val_loss: 8.4859\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5591 - val_loss: 8.4958\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5638 - val_loss: 8.7123\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5851 - val_loss: 8.6590\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7479 - val_loss: 8.4767\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5973 - val_loss: 8.6540\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.5864 - val_loss: 8.5567\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5573 - val_loss: 8.6784\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5456 - val_loss: 8.5786\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5244 - val_loss: 8.4502\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6183 - val_loss: 8.5842\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5227 - val_loss: 8.6655\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5783 - val_loss: 8.7743\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 5.5404 - val_loss: 8.7274\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5180 - val_loss: 8.4907\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5821 - val_loss: 8.5815\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5203 - val_loss: 8.7480\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.5693 - val_loss: 8.5623\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5148 - val_loss: 8.8023\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5396 - val_loss: 8.6647\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5427 - val_loss: 8.7417\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5698 - val_loss: 8.5880\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4911 - val_loss: 8.7816\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4800 - val_loss: 8.7389\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4907 - val_loss: 8.6996\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5192 - val_loss: 8.7475\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4780 - val_loss: 8.6413\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4826 - val_loss: 8.6690\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4733 - val_loss: 8.8193\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5356 - val_loss: 8.7091\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4766 - val_loss: 8.8556\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4724 - val_loss: 8.8020\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4970 - val_loss: 8.7955\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4827 - val_loss: 8.7217\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4721 - val_loss: 8.7641\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4720 - val_loss: 8.7175\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4438 - val_loss: 8.6926\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4506 - val_loss: 8.6459\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4905 - val_loss: 8.8630\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4767 - val_loss: 8.6088\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5178 - val_loss: 8.7042\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5006 - val_loss: 8.4282\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3546 - val_loss: 8.5809\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4094 - val_loss: 8.5965\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3265 - val_loss: 8.2994\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2562 - val_loss: 8.3752\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2435 - val_loss: 8.4182\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2388 - val_loss: 8.3475\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2211 - val_loss: 8.3209\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2759 - val_loss: 8.3582\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1661 - val_loss: 8.2029\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2258 - val_loss: 8.1757\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1951 - val_loss: 8.4106\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1605 - val_loss: 8.3631\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1980 - val_loss: 8.3160\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1841 - val_loss: 8.7563\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2202 - val_loss: 8.5232\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1192 - val_loss: 8.6075\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1899 - val_loss: 8.3295\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1324 - val_loss: 8.3987\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1268 - val_loss: 8.3944\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1009 - val_loss: 8.4407\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1179 - val_loss: 8.3610\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.0846 - val_loss: 8.4925\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1004 - val_loss: 8.4760\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0645 - val_loss: 8.5476\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0856 - val_loss: 8.3489\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.0757 - val_loss: 8.3153\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0938 - val_loss: 8.4158\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0613 - val_loss: 8.2824\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.0830 - val_loss: 8.3505\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0655 - val_loss: 8.4236\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1284 - val_loss: 8.4715\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0343 - val_loss: 8.5113\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0491 - val_loss: 8.5158\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0289 - val_loss: 8.5578\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0016 - val_loss: 8.5913\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0256 - val_loss: 8.6077\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0440 - val_loss: 8.3334\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0327 - val_loss: 8.4397\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.0677 - val_loss: 8.7006\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0626 - val_loss: 8.5668\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9836 - val_loss: 8.5796\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0170 - val_loss: 8.6872\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0377 - val_loss: 8.7211\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0556 - val_loss: 8.6031\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9921 - val_loss: 8.5591\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9879 - val_loss: 8.6055\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9960 - val_loss: 8.6053\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9729 - val_loss: 8.6324\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9740 - val_loss: 8.5823\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9793 - val_loss: 8.5112\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9555 - val_loss: 8.6577\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0301 - val_loss: 8.7243\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.0166 - val_loss: 8.5580\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1326 - val_loss: 8.7249\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9894 - val_loss: 8.4439\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9944 - val_loss: 8.6674\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0074 - val_loss: 8.5551\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9556 - val_loss: 8.6428\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9844 - val_loss: 8.6953\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0069 - val_loss: 8.5940\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9652 - val_loss: 8.8347\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9450 - val_loss: 8.7547\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9462 - val_loss: 8.7490\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0002 - val_loss: 8.7824\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9309 - val_loss: 8.7106\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9557 - val_loss: 8.7176\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9538 - val_loss: 8.7766\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9493 - val_loss: 8.7819\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0568 - val_loss: 8.8708\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9596 - val_loss: 9.1944\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9479 - val_loss: 8.7018\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9995 - val_loss: 8.7110\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9223 - val_loss: 8.8293\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9356 - val_loss: 8.8682\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9517 - val_loss: 8.8171\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0438 - val_loss: 8.8724\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8905 - val_loss: 8.7538\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9537 - val_loss: 8.7376\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9211 - val_loss: 8.8736\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9056 - val_loss: 8.9852\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9201 - val_loss: 8.8550\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9623 - val_loss: 8.6423\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8927 - val_loss: 8.7928\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.8934 - val_loss: 8.8741\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9156 - val_loss: 8.9351\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9063 - val_loss: 8.7851\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9213 - val_loss: 8.8626\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8976 - val_loss: 8.8906\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9130 - val_loss: 8.7367\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9215 - val_loss: 8.9198\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9792 - val_loss: 8.8717\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8921 - val_loss: 9.0133\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8949 - val_loss: 8.8338\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9431 - val_loss: 8.8187\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9323 - val_loss: 8.8960\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8825 - val_loss: 8.8093\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9009 - val_loss: 8.9507\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9039 - val_loss: 8.8435\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8936 - val_loss: 8.7914\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8692 - val_loss: 8.8877\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9108 - val_loss: 8.8852\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8448 - val_loss: 8.9336\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9308 - val_loss: 8.8609\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8864 - val_loss: 8.8265\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9512 - val_loss: 8.9098\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9369 - val_loss: 8.8386\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9089 - val_loss: 8.8313\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8913 - val_loss: 8.8711\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9113 - val_loss: 9.0333\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8683 - val_loss: 8.9546\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8981 - val_loss: 9.0713\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8942 - val_loss: 9.0460\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8830 - val_loss: 8.8695\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0274 - val_loss: 8.7871\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8846 - val_loss: 9.2064\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8753 - val_loss: 8.9768\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8844 - val_loss: 8.9209\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9018 - val_loss: 8.9235\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8636 - val_loss: 9.0971\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8737 - val_loss: 9.1460\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.9012 - val_loss: 8.9518\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8345 - val_loss: 8.9688\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9262 - val_loss: 8.9766\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9263 - val_loss: 8.8395\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9081 - val_loss: 8.9126\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8351 - val_loss: 9.0124\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9113 - val_loss: 8.8775\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0193 - val_loss: 9.0065\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8250 - val_loss: 8.9478\n",
      "Epoch 530/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 4.9299 - val_loss: 9.0515\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.906 - 0s 109us/step - loss: 4.8741 - val_loss: 9.1354\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8565 - val_loss: 9.0416\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8632 - val_loss: 9.0910\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8464 - val_loss: 9.1141\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8546 - val_loss: 8.8879\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9617 - val_loss: 8.9328\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0756 - val_loss: 8.9176\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9134 - val_loss: 9.1307\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9650 - val_loss: 8.8838\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8781 - val_loss: 9.0629\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8389 - val_loss: 8.8883\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8812 - val_loss: 8.9486\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7905 - val_loss: 9.0867\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8678 - val_loss: 9.1986\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9275 - val_loss: 8.9926\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9035 - val_loss: 9.2609\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8211 - val_loss: 8.9543\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8498 - val_loss: 8.9925\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8541 - val_loss: 9.1285\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8177 - val_loss: 9.0791\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8200 - val_loss: 9.0186\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8554 - val_loss: 8.9950\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.8438 - val_loss: 8.9632\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8399 - val_loss: 8.9276\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8177 - val_loss: 8.9953\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.8272 - val_loss: 9.1058\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8183 - val_loss: 8.9358\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8033 - val_loss: 8.9496\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8441 - val_loss: 9.0368\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8107 - val_loss: 9.0582\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8741 - val_loss: 9.0854\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8434 - val_loss: 9.1560\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.8478 - val_loss: 8.9612\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8331 - val_loss: 9.0130\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8445 - val_loss: 8.9822\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8329 - val_loss: 9.0661\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8066 - val_loss: 9.1819\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8134 - val_loss: 9.0097\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8727 - val_loss: 8.9116\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8210 - val_loss: 9.0703\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7875 - val_loss: 9.0271\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8305 - val_loss: 9.0867\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8153 - val_loss: 8.9241\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7758 - val_loss: 8.9683\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7648 - val_loss: 8.9250\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8541 - val_loss: 8.9387\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8073 - val_loss: 9.0091\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7883 - val_loss: 9.0589\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8115 - val_loss: 8.9600\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7805 - val_loss: 8.9833\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.8505 - val_loss: 8.9813\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7725 - val_loss: 8.8309\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8250 - val_loss: 9.0215\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8516 - val_loss: 9.1386\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7893 - val_loss: 9.0885\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7681 - val_loss: 8.9563\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7766 - val_loss: 8.8892\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7921 - val_loss: 8.9938\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7852 - val_loss: 8.9773\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7935 - val_loss: 8.9629\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.7506 - val_loss: 8.9435\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8148 - val_loss: 8.9615\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8481 - val_loss: 8.9343\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8855 - val_loss: 9.0186\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8367 - val_loss: 9.0415\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8224 - val_loss: 8.9105\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8055 - val_loss: 8.9812\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7399 - val_loss: 9.0617\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7809 - val_loss: 9.0231\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7390 - val_loss: 8.8959\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7606 - val_loss: 8.8076\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8088 - val_loss: 8.7933\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7582 - val_loss: 8.9300\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7563 - val_loss: 9.0140\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8049 - val_loss: 9.0323\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8202 - val_loss: 9.1789\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.7277 - val_loss: 9.1161\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.8351 - val_loss: 9.0257\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8242 - val_loss: 8.8991\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7135 - val_loss: 8.8470\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.7623 - val_loss: 8.8641\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7732 - val_loss: 9.0412\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7485 - val_loss: 9.0404\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7711 - val_loss: 8.9683\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7671 - val_loss: 9.0626\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8451 - val_loss: 8.9246\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7546 - val_loss: 8.9231\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7454 - val_loss: 9.0274\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7117 - val_loss: 8.8061\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7699 - val_loss: 8.7632\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8016 - val_loss: 8.9356\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7366 - val_loss: 8.9651\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7468 - val_loss: 8.9679\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7369 - val_loss: 8.9226\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7638 - val_loss: 8.8619\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7716 - val_loss: 8.8123\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7440 - val_loss: 8.7565\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8339 - val_loss: 8.8797\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7295 - val_loss: 8.9296\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7321 - val_loss: 9.0332\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7237 - val_loss: 8.8657\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7195 - val_loss: 8.9532\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7589 - val_loss: 9.1257\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7102 - val_loss: 8.9310\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7995 - val_loss: 8.9839\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7638 - val_loss: 9.1076\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.7449 - val_loss: 8.9066\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7361 - val_loss: 8.9035\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7301 - val_loss: 8.9386\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7210 - val_loss: 8.8590\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7607 - val_loss: 9.0166\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7015 - val_loss: 8.9744\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7236 - val_loss: 8.8916\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7077 - val_loss: 8.9287\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7175 - val_loss: 8.8837\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7019 - val_loss: 8.8999\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7187 - val_loss: 8.9892\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6976 - val_loss: 9.1111\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7358 - val_loss: 8.9498\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7250 - val_loss: 8.9608\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6934 - val_loss: 8.9758\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7106 - val_loss: 8.8466\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7234 - val_loss: 8.7466\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7070 - val_loss: 9.0392\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7844 - val_loss: 8.9607\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7911 - val_loss: 8.8294\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7646 - val_loss: 9.0421\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7549 - val_loss: 9.0767\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7737 - val_loss: 8.8934\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6907 - val_loss: 8.8529\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7156 - val_loss: 8.9046\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6943 - val_loss: 8.8425\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7541 - val_loss: 8.8381\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.8026 - val_loss: 8.6610\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7007 - val_loss: 8.9123\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6884 - val_loss: 8.9580\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7238 - val_loss: 8.8837\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7079 - val_loss: 8.8855\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6942 - val_loss: 8.9917\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.6977 - val_loss: 8.9290\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7428 - val_loss: 8.8263\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7234 - val_loss: 8.8239\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6696 - val_loss: 8.7097\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7431 - val_loss: 8.8374\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7542 - val_loss: 9.0018\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7063 - val_loss: 8.9468\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7349 - val_loss: 8.9176\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7105 - val_loss: 8.9138\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6910 - val_loss: 8.7558\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8413 - val_loss: 8.8128\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6925 - val_loss: 9.0216\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6703 - val_loss: 8.9191\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6667 - val_loss: 8.7904\n",
      "Epoch 684/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 4.6964 - val_loss: 8.6717\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6714 - val_loss: 8.6835\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6861 - val_loss: 8.8496\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6762 - val_loss: 8.8473\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6578 - val_loss: 8.7970\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7032 - val_loss: 8.9972\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6880 - val_loss: 8.8520\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7157 - val_loss: 8.9812\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6875 - val_loss: 8.8100\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7096 - val_loss: 8.7675\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6407 - val_loss: 8.6299\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6710 - val_loss: 8.7678\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6820 - val_loss: 8.9327\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6377 - val_loss: 8.7319\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6776 - val_loss: 8.8773\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.7177 - val_loss: 8.7689\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6910 - val_loss: 8.7811\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6765 - val_loss: 8.8574\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7140 - val_loss: 8.8239\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6402 - val_loss: 8.8209\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6608 - val_loss: 8.7597\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7028 - val_loss: 8.7278\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7531 - val_loss: 8.7449\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6645 - val_loss: 8.8155\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6716 - val_loss: 8.7541\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6321 - val_loss: 8.6916\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.6303 - val_loss: 8.7029\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6419 - val_loss: 8.8314\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6201 - val_loss: 8.7376\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6015 - val_loss: 8.8221\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6012 - val_loss: 8.7972\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6444 - val_loss: 8.7611\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6533 - val_loss: 8.6805\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6027 - val_loss: 8.6660\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6816 - val_loss: 8.5885\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6213 - val_loss: 8.6531\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6150 - val_loss: 8.6132\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6090 - val_loss: 8.5543\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6303 - val_loss: 8.7947\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6214 - val_loss: 8.8085\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6089 - val_loss: 8.6066\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6041 - val_loss: 8.6937\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6685 - val_loss: 8.5495\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6436 - val_loss: 8.5499\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5905 - val_loss: 8.7933\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5998 - val_loss: 8.7538\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.6209 - val_loss: 8.7228\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5701 - val_loss: 8.6788\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6051 - val_loss: 8.6318\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5836 - val_loss: 8.5643\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6233 - val_loss: 8.5960\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6353 - val_loss: 8.6909\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6235 - val_loss: 8.8267\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5654 - val_loss: 8.6266\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.6827 - val_loss: 8.5666\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5965 - val_loss: 8.8605\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6259 - val_loss: 8.5381\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.6438 - val_loss: 8.5441\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6373 - val_loss: 8.6291\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6124 - val_loss: 8.6223\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6107 - val_loss: 8.7961\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6523 - val_loss: 8.5340\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6341 - val_loss: 8.5426\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6098 - val_loss: 8.5197\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5863 - val_loss: 8.6320\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5936 - val_loss: 8.5931\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5853 - val_loss: 8.6841\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5774 - val_loss: 8.5871\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5939 - val_loss: 8.6685\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5610 - val_loss: 8.6467\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6003 - val_loss: 8.4276\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5844 - val_loss: 8.6014\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5576 - val_loss: 8.5983\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5604 - val_loss: 8.6841\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5767 - val_loss: 8.5687\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.5550 - val_loss: 8.4982\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5993 - val_loss: 8.5879\n",
      "Epoch 761/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.5557 - val_loss: 8.4836\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5575 - val_loss: 8.6203\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6160 - val_loss: 8.4837\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.5764 - val_loss: 8.6864\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6151 - val_loss: 8.6219\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5914 - val_loss: 8.5214\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5697 - val_loss: 8.5842\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5870 - val_loss: 8.5439\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5525 - val_loss: 8.4658\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5339 - val_loss: 8.4583\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5843 - val_loss: 8.6428\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5751 - val_loss: 8.6417\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5537 - val_loss: 8.7941\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6914 - val_loss: 8.4067\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6082 - val_loss: 8.4969\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5637 - val_loss: 8.5149\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5449 - val_loss: 8.5916\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5639 - val_loss: 8.3800\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5297 - val_loss: 8.4954\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5876 - val_loss: 8.4908\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5459 - val_loss: 8.4953\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6039 - val_loss: 8.5500\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.5721 - val_loss: 8.5768\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5962 - val_loss: 8.3068\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5339 - val_loss: 8.4713\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5472 - val_loss: 8.7095\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5864 - val_loss: 8.4934\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5540 - val_loss: 8.5938\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6034 - val_loss: 8.6067\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5045 - val_loss: 8.4631\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6504 - val_loss: 8.4560\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5898 - val_loss: 8.5487\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6514 - val_loss: 8.3915\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5579 - val_loss: 8.5110\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5988 - val_loss: 8.3684\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5667 - val_loss: 8.3591\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.5286 - val_loss: 8.4755\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5587 - val_loss: 8.5027\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5131 - val_loss: 8.4780\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.4941 - val_loss: 8.2945\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.5217 - val_loss: 8.4552\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.5154 - val_loss: 8.4480\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.5297 - val_loss: 8.4830\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.5747 - val_loss: 8.4578\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4966 - val_loss: 8.4441\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5505 - val_loss: 8.2707\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5029 - val_loss: 8.4367\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5134 - val_loss: 8.3543\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5069 - val_loss: 8.4371\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5094 - val_loss: 8.5346\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5393 - val_loss: 8.4519\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6135 - val_loss: 8.5478\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5119 - val_loss: 8.2778\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5129 - val_loss: 8.3563\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5288 - val_loss: 8.5107\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.5437 - val_loss: 8.4292\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5273 - val_loss: 8.4325\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.5047 - val_loss: 8.4269\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5128 - val_loss: 8.5776\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4958 - val_loss: 8.3618\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4707 - val_loss: 8.2370\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4880 - val_loss: 8.2961\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4658 - val_loss: 8.3702\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5125 - val_loss: 8.3852\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5674 - val_loss: 8.3589\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4716 - val_loss: 8.2789\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4998 - val_loss: 8.3551\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5384 - val_loss: 8.2251\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4601 - val_loss: 8.3783\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5198 - val_loss: 8.3808\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4920 - val_loss: 8.4733\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.4906 - val_loss: 8.3554\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5437 - val_loss: 8.3786\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4944 - val_loss: 8.2667\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4784 - val_loss: 8.4330\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5815 - val_loss: 8.3629\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4648 - val_loss: 8.2803\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4979 - val_loss: 8.4759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4896 - val_loss: 8.4519\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4849 - val_loss: 8.3483\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6737 - val_loss: 8.3333\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4410 - val_loss: 8.6013\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5603 - val_loss: 8.2277\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4956 - val_loss: 8.2684\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4669 - val_loss: 8.4945\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4574 - val_loss: 8.2603\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4788 - val_loss: 8.2601\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4771 - val_loss: 8.3839\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4996 - val_loss: 8.4308\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4479 - val_loss: 8.2884\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4857 - val_loss: 8.3141\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4492 - val_loss: 8.3752\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4752 - val_loss: 8.4209\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4853 - val_loss: 8.4050\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4799 - val_loss: 8.2474\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4542 - val_loss: 8.3805\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4953 - val_loss: 8.3134\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4663 - val_loss: 8.2870\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4680 - val_loss: 8.1926\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4364 - val_loss: 8.4065\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4506 - val_loss: 8.2611\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.4599 - val_loss: 8.1686\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4432 - val_loss: 8.1922\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4579 - val_loss: 8.3394\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.4330 - val_loss: 8.2856\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5013 - val_loss: 8.3754\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4569 - val_loss: 8.2828\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4853 - val_loss: 8.2494\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4156 - val_loss: 8.1932\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4532 - val_loss: 8.2302\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4412 - val_loss: 8.3918\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.4362 - val_loss: 8.1994\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4694 - val_loss: 8.3417\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4340 - val_loss: 8.2229\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4158 - val_loss: 8.1797\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4475 - val_loss: 8.2374\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4608 - val_loss: 8.3038\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4512 - val_loss: 8.3635\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4361 - val_loss: 8.1478\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4905 - val_loss: 8.1665\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.5150 - val_loss: 8.4291\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4337 - val_loss: 8.3167\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4676 - val_loss: 8.3072\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4953 - val_loss: 8.0979\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4526 - val_loss: 8.4076\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4270 - val_loss: 8.2530\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.4103 - val_loss: 8.3343\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4819 - val_loss: 8.2603\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.5765 - val_loss: 8.1830\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5540 - val_loss: 8.4382\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4547 - val_loss: 8.2090\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4659 - val_loss: 8.2142\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4660 - val_loss: 8.1718\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4391 - val_loss: 8.3926\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3995 - val_loss: 8.2957\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3956 - val_loss: 8.1678\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3949 - val_loss: 8.1918\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4151 - val_loss: 8.2431\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.3845 - val_loss: 8.2807\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5976 - val_loss: 8.1589\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4340 - val_loss: 8.1431\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.4763 - val_loss: 8.3055\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4595 - val_loss: 8.1715\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4359 - val_loss: 8.2105\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4539 - val_loss: 8.1522\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3907 - val_loss: 8.4422\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.4279 - val_loss: 8.1581\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4565 - val_loss: 8.1331\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3938 - val_loss: 8.2994\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3871 - val_loss: 8.2901\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3734 - val_loss: 8.2668\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.4220 - val_loss: 8.1358\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4636 - val_loss: 8.1860\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4065 - val_loss: 8.4018\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4090 - val_loss: 8.3531\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 107us/step - loss: 4.4155 - val_loss: 8.0185\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.4085 - val_loss: 8.0683\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.4224 - val_loss: 8.3174\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3956 - val_loss: 8.2563\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3920 - val_loss: 8.3430\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4497 - val_loss: 8.3274\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3788 - val_loss: 8.1203\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3960 - val_loss: 8.0720\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3497 - val_loss: 8.2063\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3579 - val_loss: 8.2009\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3763 - val_loss: 8.2760\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3762 - val_loss: 8.1883\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4837 - val_loss: 8.2689\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4293 - val_loss: 8.3638\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4466 - val_loss: 8.3338\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4247 - val_loss: 8.3699\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3600 - val_loss: 8.1981\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3954 - val_loss: 8.2244\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3802 - val_loss: 8.0949\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4037 - val_loss: 8.1599\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4543 - val_loss: 8.2413\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3595 - val_loss: 8.1882\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4230 - val_loss: 8.4099\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3942 - val_loss: 8.1797\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.4917 - val_loss: 8.3092\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.3558 - val_loss: 8.0129\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4106 - val_loss: 8.1286\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3651 - val_loss: 8.1524\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.3865 - val_loss: 8.2778\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3562 - val_loss: 8.2550\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 4.4049 - val_loss: 8.2159\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3932 - val_loss: 8.3023\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3777 - val_loss: 8.2439\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3437 - val_loss: 8.3101\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3820 - val_loss: 8.2409\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.3693 - val_loss: 8.2777\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3628 - val_loss: 8.1689\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.4079 - val_loss: 8.3085\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4641 - val_loss: 8.3652\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4228 - val_loss: 8.2066\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4090 - val_loss: 8.4138\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3551 - val_loss: 8.4453\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.4356 - val_loss: 8.1957\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.3849 - val_loss: 8.2247\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3762 - val_loss: 8.3018\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.4159 - val_loss: 8.4829\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3488 - val_loss: 8.2043\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3275 - val_loss: 8.2729\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.3232 - val_loss: 8.2441\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3414 - val_loss: 8.0753\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3477 - val_loss: 8.2295\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3780 - val_loss: 8.3284\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3920 - val_loss: 8.3190\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.3753 - val_loss: 8.0972\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3445 - val_loss: 8.1959\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.3654 - val_loss: 8.2772\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3976 - val_loss: 8.3476\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3118 - val_loss: 8.1692\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3800 - val_loss: 8.0687\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3338 - val_loss: 8.4810\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3485 - val_loss: 8.4972\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.3670 - val_loss: 8.1944\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.4236 - val_loss: 8.1710\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3709 - val_loss: 8.4444\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3544 - val_loss: 8.2660\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3386 - val_loss: 8.3125\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.3666 - val_loss: 8.2395\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3239 - val_loss: 8.1704\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3747 - val_loss: 8.3346\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.3446 - val_loss: 8.1955\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3481 - val_loss: 8.2375\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.4362 - val_loss: 8.3988\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3319 - val_loss: 8.1825\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.3766 - val_loss: 8.1056\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.3222 - val_loss: 8.2355\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.3616 - val_loss: 8.3787\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.3481 - val_loss: 8.4985\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 4.3179 - val_loss: 8.2837\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3689 - val_loss: 8.2310\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3630 - val_loss: 8.2288\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3175 - val_loss: 8.2062\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.2992 - val_loss: 8.1630\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3161 - val_loss: 8.3271\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.3284 - val_loss: 8.2711\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.3574 - val_loss: 8.2416\n",
      "7.7368779101614225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 2.8883133 ,  1.3257989 ,  0.20135549, -0.8154305 ,  0.08173855],\n",
       "        [-0.27676305,  0.24998869,  0.17527364,  2.0909438 , -2.501121  ],\n",
       "        [ 1.6751955 , -1.6579424 ,  0.2784073 , -0.15088892,  1.6567736 ],\n",
       "        [ 2.4209313 , -2.0516522 , -0.7122689 , -2.3013616 ,  2.4565532 ],\n",
       "        [ 1.8783796 ,  0.27674732,  0.14979509,  0.6812794 ,  0.2453247 ],\n",
       "        [-2.8243732 , -0.38156027,  0.20827448,  3.455559  ,  0.4085609 ],\n",
       "        [-4.240262  , -0.32138622,  0.09404498,  0.04023812, -2.3090014 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.70993614,  1.4502965 , -0.86578864, -1.3067633 ,  0.30401212],\n",
       "       dtype=float32),\n",
       " array([[ 1.4946966 , -1.1394205 , -2.207962  ,  0.5083123 , -1.1854556 ,\n",
       "         -5.2317576 ,  0.38028318,  0.40507454, -1.1825122 , -0.9733874 ],\n",
       "        [ 0.96021867,  1.2770596 , -0.10651914,  1.2587723 , -3.1290863 ,\n",
       "          1.309111  ,  0.16353655,  1.926213  , -3.1191945 , -2.7329893 ],\n",
       "        [ 0.33909494,  0.8127635 , -0.5665956 ,  0.7776362 , -0.22383475,\n",
       "          1.046984  ,  0.34674436,  0.45081007, -0.73743695, -1.1228454 ],\n",
       "        [ 1.7488253 ,  5.989112  ,  1.1092566 ,  1.6972045 , -2.2380216 ,\n",
       "         -1.0178014 ,  0.7942455 ,  2.2159534 , -2.2314057 , -1.950434  ],\n",
       "        [-1.206741  ,  2.5285249 , -3.6903799 ,  1.5449945 , -8.929487  ,\n",
       "          1.8780525 , -1.8185637 ,  2.7911885 , -9.023195  , -6.8871555 ]],\n",
       "       dtype=float32),\n",
       " array([-1.3816491 ,  2.0873647 , -2.4534993 , -2.6786313 ,  1.420881  ,\n",
       "         0.56339985,  0.4455115 , -5.6986814 ,  1.4265292 ,  0.68754685],\n",
       "       dtype=float32),\n",
       " array([[ 2.8139853],\n",
       "        [ 7.100325 ],\n",
       "        [10.951615 ],\n",
       "        [ 3.3199403],\n",
       "        [ 3.3247442],\n",
       "        [ 7.416572 ],\n",
       "        [ 4.358856 ],\n",
       "        [ 3.6542494],\n",
       "        [ 3.3640804],\n",
       "        [ 2.247524 ]], dtype=float32),\n",
       " array([2.027437], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_sigmoid(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_sigmoid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 823us/step - loss: 456.5694 - val_loss: 335.2381\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 229.4176 - val_loss: 163.5653\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 113.1432 - val_loss: 84.5608\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 69.9621 - val_loss: 62.3851\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 62.2071 - val_loss: 59.3950\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 62.1340 - val_loss: 59.3599\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 62.2558 - val_loss: 59.3651\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.7320 - val_loss: 59.5514\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 61.3994 - val_loss: 59.9606\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4197 - val_loss: 60.4418\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4384 - val_loss: 60.5451\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4995 - val_loss: 60.5814\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4350 - val_loss: 60.2618\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4155 - val_loss: 60.1356\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4090 - val_loss: 60.1285\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4201 - val_loss: 60.0501\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 61.4529 - val_loss: 60.1809\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 61.4077 - val_loss: 60.1771\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4066 - val_loss: 60.2203\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4144 - val_loss: 60.2497\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4340 - val_loss: 60.1305\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 61.4101 - val_loss: 60.1648\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 61.4074 - val_loss: 60.1596\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4201 - val_loss: 60.1093\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4169 - val_loss: 60.1136\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4563 - val_loss: 60.0872\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4412 - val_loss: 60.1747\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4148 - val_loss: 60.2056\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.3964 - val_loss: 60.3023\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4238 - val_loss: 60.2888\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4660 - val_loss: 60.1838\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4236 - val_loss: 60.3958\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4800 - val_loss: 60.5281\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4709 - val_loss: 60.2324\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4467 - val_loss: 60.2970\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4327 - val_loss: 60.1541\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4145 - val_loss: 60.0260\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4374 - val_loss: 59.9772\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 61.4289 - val_loss: 60.1123\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4408 - val_loss: 60.2106\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4623 - val_loss: 60.1407\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.5178 - val_loss: 60.5148\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4412 - val_loss: 60.2551\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4060 - val_loss: 60.2012\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4821 - val_loss: 60.0337\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 61.4708 - val_loss: 60.3168\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4269 - val_loss: 60.3197\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 61.4122 - val_loss: 60.2819\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4304 - val_loss: 60.3048\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.5872 - val_loss: 60.0276\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4334 - val_loss: 60.2405\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4113 - val_loss: 60.2484\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4091 - val_loss: 60.2340\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4715 - val_loss: 60.1115\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4544 - val_loss: 60.3502\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 61.4202 - val_loss: 60.2554\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.4266 - val_loss: 60.1194\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.4284 - val_loss: 60.2132\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4180 - val_loss: 60.1826\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4279 - val_loss: 60.2454\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 61.4476 - val_loss: 60.0901\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.4060 - val_loss: 60.1616\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4316 - val_loss: 60.1242\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.4219 - val_loss: 60.2973\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4296 - val_loss: 60.2496\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4095 - val_loss: 60.2663\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4267 - val_loss: 60.2641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4402 - val_loss: 60.3508\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4278 - val_loss: 60.2645\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.4250 - val_loss: 60.2336\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4869 - val_loss: 60.1021\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4247 - val_loss: 60.2316\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4306 - val_loss: 60.2703\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.4154 - val_loss: 60.1958\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4448 - val_loss: 60.0464\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4445 - val_loss: 59.9374\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4220 - val_loss: 60.0067\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4011 - val_loss: 60.1507\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.4357 - val_loss: 60.3632\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4493 - val_loss: 60.2896\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4263 - val_loss: 60.2250\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4266 - val_loss: 60.3557\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.4145 - val_loss: 60.3397\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 61.4690 - val_loss: 60.0940\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4350 - val_loss: 60.0607\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 61.4218 - val_loss: 60.0686\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4104 - val_loss: 60.1622\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4344 - val_loss: 60.1756\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 61.6617 - val_loss: 60.5586\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4357 - val_loss: 60.3056\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3921 - val_loss: 60.1558\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4117 - val_loss: 60.0844\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4444 - val_loss: 60.1682\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4345 - val_loss: 60.1985\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4128 - val_loss: 60.1883\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4227 - val_loss: 60.1628\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 61.4290 - val_loss: 60.1725\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4388 - val_loss: 60.3161\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4658 - val_loss: 60.1501\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4161 - val_loss: 60.2523\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4341 - val_loss: 60.3336\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 61.4528 - val_loss: 60.3970\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4607 - val_loss: 60.0503\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 61.4385 - val_loss: 60.0409\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 61.4915 - val_loss: 60.1838\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4008 - val_loss: 60.0764\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 61.4158 - val_loss: 60.0652\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.4066 - val_loss: 60.0519\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4269 - val_loss: 60.0077\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.5418 - val_loss: 59.9441\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4286 - val_loss: 59.9875\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4403 - val_loss: 60.0681\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 61.4780 - val_loss: 59.9630\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 61.4307 - val_loss: 60.1025\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.4111 - val_loss: 60.1075\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 61.4179 - val_loss: 60.0804\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4314 - val_loss: 60.1429\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4956 - val_loss: 60.4190\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4322 - val_loss: 60.3016\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4362 - val_loss: 60.1767\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 61.4206 - val_loss: 59.9968\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4196 - val_loss: 59.9973\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4104 - val_loss: 60.0864\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4145 - val_loss: 60.1505\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4475 - val_loss: 60.3492\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4298 - val_loss: 60.3169\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4306 - val_loss: 60.0305\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4164 - val_loss: 60.0337\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 61.4179 - val_loss: 60.0785\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.5108 - val_loss: 60.4224\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4608 - val_loss: 60.3226\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 61.4295 - val_loss: 60.2353\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4784 - val_loss: 60.3353\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.4338 - val_loss: 60.0726\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 61.3935 - val_loss: 60.0681\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3833 - val_loss: 60.2666\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4363 - val_loss: 60.5000\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3705 - val_loss: 60.4011\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 61.3749 - val_loss: 60.2709\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.4136 - val_loss: 60.3521\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 61.3625 - val_loss: 60.4402\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4757 - val_loss: 60.2099\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 61.3476 - val_loss: 60.3780\n",
      "Epoch 144/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 61.3210 - val_loss: 60.4722\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3418 - val_loss: 60.6209\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.2871 - val_loss: 60.5251\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2966 - val_loss: 60.6530\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.2793 - val_loss: 61.0031\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2542 - val_loss: 61.2771\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 61.2761 - val_loss: 61.6947\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.2323 - val_loss: 61.9389\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 61.2360 - val_loss: 61.8408\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2696 - val_loss: 61.6441\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 61.2826 - val_loss: 61.4481\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 61.2124 - val_loss: 61.5934\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.2101 - val_loss: 61.5113\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2326 - val_loss: 61.3672\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 61.2195 - val_loss: 61.0919\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.2285 - val_loss: 61.0598\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2341 - val_loss: 61.2804\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.2278 - val_loss: 61.2966\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.2053 - val_loss: 61.2080\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 61.1864 - val_loss: 61.1185\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 61.2894 - val_loss: 60.9762\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3289 - val_loss: 61.3150\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.1864 - val_loss: 61.1482\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.1301 - val_loss: 60.9208\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.1565 - val_loss: 60.8304\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.2043 - val_loss: 60.7769\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 61.1076 - val_loss: 60.9579\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 61.0858 - val_loss: 61.1837\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.1276 - val_loss: 61.3372\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.1429 - val_loss: 61.0426\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.0857 - val_loss: 60.9520\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0710 - val_loss: 61.0148\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0349 - val_loss: 60.9839\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 56.7002 - val_loss: 47.6521\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 39.7715 - val_loss: 40.0291\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 33.7753 - val_loss: 32.9165\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 29.8516 - val_loss: 28.1867\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 27.6122 - val_loss: 26.0587\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 25.5508 - val_loss: 25.2250\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 23.5601 - val_loss: 24.6211\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 22.8551 - val_loss: 23.7277\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 21.2000 - val_loss: 24.5140\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 20.5201 - val_loss: 22.1526\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 19.9317 - val_loss: 21.5771\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 19.3945 - val_loss: 21.0851\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 18.6502 - val_loss: 20.4175\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 18.0798 - val_loss: 19.9577\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 17.1621 - val_loss: 20.7400\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 16.7057 - val_loss: 20.4430\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 15.8084 - val_loss: 19.4501\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 14.8808 - val_loss: 18.6424\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 14.1945 - val_loss: 17.8606\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 13.4345 - val_loss: 17.3323\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.8780 - val_loss: 16.2342\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.3855 - val_loss: 14.6963\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 12.1516 - val_loss: 14.5141\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 11.5233 - val_loss: 14.0353\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 11.3199 - val_loss: 13.5846\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.0683 - val_loss: 13.4031\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 10.5842 - val_loss: 13.9489\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.6766 - val_loss: 14.0759\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 10.5582 - val_loss: 13.7105\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.0136 - val_loss: 13.2311\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.9187 - val_loss: 13.1007\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.5824 - val_loss: 13.1948\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.4478 - val_loss: 12.3080\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 9.2934 - val_loss: 12.2620\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.0209 - val_loss: 11.9521\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 8.8784 - val_loss: 11.8319\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 8.6722 - val_loss: 11.7400\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2169 - val_loss: 11.1034\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.0120 - val_loss: 12.0740\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.1055 - val_loss: 11.6218\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.0224 - val_loss: 11.4573\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 7.8242 - val_loss: 10.9043\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7915 - val_loss: 11.2307\n",
      "Epoch 220/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 7.6992 - val_loss: 11.0118\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6463 - val_loss: 10.8867\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4533 - val_loss: 10.8380\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3089 - val_loss: 10.9447\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2416 - val_loss: 10.7446\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1394 - val_loss: 10.3760\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0912 - val_loss: 10.2036\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0699 - val_loss: 10.3676\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1018 - val_loss: 10.5921\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.0781 - val_loss: 10.5144\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9968 - val_loss: 10.3804\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2477 - val_loss: 10.1161\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0160 - val_loss: 10.5668\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8644 - val_loss: 10.4250\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8272 - val_loss: 10.4170\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8109 - val_loss: 10.5621\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7963 - val_loss: 10.4433\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8725 - val_loss: 9.9929\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7771 - val_loss: 10.4576\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7756 - val_loss: 10.4639\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7163 - val_loss: 10.4725\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7831 - val_loss: 9.9890\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7075 - val_loss: 10.0559\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7009 - val_loss: 10.4370\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5994 - val_loss: 10.0352\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7242 - val_loss: 10.4930\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5943 - val_loss: 10.3056\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7379 - val_loss: 10.0652\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0750 - val_loss: 10.3988\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7310 - val_loss: 10.5561\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5668 - val_loss: 10.0151\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6172 - val_loss: 10.2819\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6205 - val_loss: 9.8086\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8463 - val_loss: 9.8143\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5636 - val_loss: 10.0356\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5075 - val_loss: 9.9010\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5481 - val_loss: 9.9017\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7606 - val_loss: 10.1898\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5993 - val_loss: 9.9844\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4846 - val_loss: 9.7925\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4239 - val_loss: 9.9442\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5336 - val_loss: 9.8617\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5143 - val_loss: 9.7685\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4316 - val_loss: 9.9508\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3654 - val_loss: 9.8643\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.4806 - val_loss: 9.6996\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4701 - val_loss: 9.5504\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5795 - val_loss: 9.7058\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4636 - val_loss: 9.6753\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3776 - val_loss: 9.9280\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3587 - val_loss: 9.4679\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4131 - val_loss: 9.7146\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4147 - val_loss: 9.7190\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3494 - val_loss: 9.3517\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4223 - val_loss: 9.3403\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3135 - val_loss: 9.6676\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3301 - val_loss: 9.7600\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4866 - val_loss: 9.4725\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4299 - val_loss: 9.6509\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5043 - val_loss: 9.4498\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.3543 - val_loss: 9.4099\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3002 - val_loss: 9.5483\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4068 - val_loss: 9.7015\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2980 - val_loss: 9.6293\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3399 - val_loss: 9.6233\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.2797 - val_loss: 9.4162\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2920 - val_loss: 9.4620\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.2998 - val_loss: 9.6058\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2802 - val_loss: 9.3887\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2921 - val_loss: 9.4088\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2253 - val_loss: 9.4175\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2399 - val_loss: 9.4469\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2866 - val_loss: 9.4338\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.2247 - val_loss: 9.6475\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3648 - val_loss: 9.4937\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2616 - val_loss: 9.5613\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2660 - val_loss: 9.0469\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 101us/step - loss: 6.2494 - val_loss: 9.4956\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4105 - val_loss: 9.2658\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6354 - val_loss: 9.3283\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2759 - val_loss: 9.7003\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2205 - val_loss: 9.3283\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2934 - val_loss: 9.2165\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2575 - val_loss: 9.4105\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.4131 - val_loss: 9.6226\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2347 - val_loss: 9.1260\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1797 - val_loss: 9.3334\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2220 - val_loss: 9.1085\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4482 - val_loss: 9.4441\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4592 - val_loss: 9.1636\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1568 - val_loss: 9.1216\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1985 - val_loss: 9.4586\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3099 - val_loss: 9.1756\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2909 - val_loss: 9.4829\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2697 - val_loss: 9.4533\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2297 - val_loss: 9.5346\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1784 - val_loss: 9.2882\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1590 - val_loss: 9.2948\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1095 - val_loss: 9.3108\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2157 - val_loss: 9.4860\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2278 - val_loss: 9.2707\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 6.3039 - val_loss: 9.2840\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2897 - val_loss: 9.4854\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1433 - val_loss: 9.3116\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1464 - val_loss: 9.0988\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1668 - val_loss: 9.1864\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0723 - val_loss: 9.6769\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2189 - val_loss: 8.9523\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2958 - val_loss: 9.7559\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1729 - val_loss: 9.0441\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0773 - val_loss: 9.2696\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0953 - val_loss: 9.0995\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2575 - val_loss: 9.2273\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3732 - val_loss: 9.3842\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3892 - val_loss: 9.4558\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3018 - val_loss: 9.0716\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2827 - val_loss: 9.3662\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2718 - val_loss: 9.1273\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1048 - val_loss: 9.2808\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0965 - val_loss: 9.2414\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0950 - val_loss: 9.3821\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1079 - val_loss: 9.0033\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0991 - val_loss: 9.0395\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.0890 - val_loss: 8.9814\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1635 - val_loss: 9.0984\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3172 - val_loss: 8.8953\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2615 - val_loss: 9.3464\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1069 - val_loss: 9.2734\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0446 - val_loss: 8.9075\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0635 - val_loss: 9.3898\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0627 - val_loss: 9.0075\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0371 - val_loss: 9.2403\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2110 - val_loss: 9.3990\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.1023 - val_loss: 9.2171\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9931 - val_loss: 8.7101\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0723 - val_loss: 8.8198\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9897 - val_loss: 9.2047\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0377 - val_loss: 9.3431\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9909 - val_loss: 8.9384\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0595 - val_loss: 8.6874\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0155 - val_loss: 8.9817\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0062 - val_loss: 9.1136\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0212 - val_loss: 9.1035\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0353 - val_loss: 9.0496\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9800 - val_loss: 9.1074\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0269 - val_loss: 8.6755\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0503 - val_loss: 8.8103\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2297 - val_loss: 9.6844\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1530 - val_loss: 9.0421\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2700 - val_loss: 9.2030\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0355 - val_loss: 9.0120\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1559 - val_loss: 8.9302\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1799 - val_loss: 9.0048\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0209 - val_loss: 8.8255\n",
      "Epoch 374/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 112us/step - loss: 5.9925 - val_loss: 8.8593\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9845 - val_loss: 8.8069\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0262 - val_loss: 9.0066\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0769 - val_loss: 8.8943\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0069 - val_loss: 8.9335\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9861 - val_loss: 9.0739\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0599 - val_loss: 9.0435\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0381 - val_loss: 8.7153\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9311 - val_loss: 8.7675\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9483 - val_loss: 9.2322\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9302 - val_loss: 9.0393\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9553 - val_loss: 9.1064\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9428 - val_loss: 8.8953\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8854 - val_loss: 9.1220\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1008 - val_loss: 9.2515\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9135 - val_loss: 8.8095\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9068 - val_loss: 9.1948\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0064 - val_loss: 8.8438\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8796 - val_loss: 9.0635\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.9279 - val_loss: 8.8926\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0794 - val_loss: 8.9220\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9650 - val_loss: 9.1399\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0574 - val_loss: 9.1833\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9017 - val_loss: 9.3521\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8966 - val_loss: 8.8160\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9536 - val_loss: 9.0406\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9602 - val_loss: 9.0833\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8159 - val_loss: 9.0314\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9970 - val_loss: 9.0326\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9513 - val_loss: 9.0669\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8499 - val_loss: 8.7881\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8930 - val_loss: 8.9881\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9450 - val_loss: 8.9847\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0604 - val_loss: 8.8780\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2869 - val_loss: 9.2654\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0357 - val_loss: 9.0293\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0187 - val_loss: 8.8216\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1754 - val_loss: 9.1476\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9469 - val_loss: 9.0540\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7846 - val_loss: 9.0688\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9356 - val_loss: 8.7715\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8888 - val_loss: 8.6846\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8376 - val_loss: 9.0113\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8489 - val_loss: 8.9492\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8767 - val_loss: 8.9423\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8303 - val_loss: 8.7197\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7558 - val_loss: 8.8884\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9174 - val_loss: 8.7488\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9451 - val_loss: 8.9126\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7570 - val_loss: 8.9684\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7431 - val_loss: 9.0742\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8515 - val_loss: 8.7978\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8348 - val_loss: 9.3139\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9446 - val_loss: 8.8432\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8169 - val_loss: 8.8110\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7751 - val_loss: 8.9892\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8498 - val_loss: 8.6607\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0308 - val_loss: 8.9990\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8964 - val_loss: 9.0681\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9268 - val_loss: 8.8318\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.6994 - val_loss: 9.0790\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7730 - val_loss: 8.8939\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6796 - val_loss: 9.0797\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7408 - val_loss: 8.9562\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7625 - val_loss: 8.8365\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7704 - val_loss: 8.7806\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8528 - val_loss: 8.6039\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7874 - val_loss: 8.9844\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7698 - val_loss: 8.9567\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8536 - val_loss: 8.8144\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7529 - val_loss: 8.8595\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7551 - val_loss: 9.2073\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8939 - val_loss: 8.9847\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7952 - val_loss: 8.9677\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7841 - val_loss: 8.6877\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7319 - val_loss: 9.1132\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7698 - val_loss: 8.5336\n",
      "Epoch 451/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.7690 - val_loss: 8.9205\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8027 - val_loss: 8.7467\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9353 - val_loss: 8.4329\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9383 - val_loss: 8.7898\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0833 - val_loss: 8.4837\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7961 - val_loss: 8.7889\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7370 - val_loss: 8.7234\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6804 - val_loss: 8.6929\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7416 - val_loss: 8.7844\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6956 - val_loss: 8.6823\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7328 - val_loss: 8.6031\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6325 - val_loss: 8.8890\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7101 - val_loss: 8.7468\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6759 - val_loss: 8.6267\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7207 - val_loss: 9.0319\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8132 - val_loss: 8.6219\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6379 - val_loss: 8.5442\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7064 - val_loss: 8.3350\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8964 - val_loss: 8.8503\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6279 - val_loss: 8.9603\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6758 - val_loss: 8.5110\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7902 - val_loss: 8.5247\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6433 - val_loss: 8.3974\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6231 - val_loss: 8.5934\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9082 - val_loss: 8.4245\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6710 - val_loss: 8.3812\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5441 - val_loss: 8.4510\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5840 - val_loss: 8.5003\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5440 - val_loss: 8.3529\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5760 - val_loss: 8.2545\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6069 - val_loss: 8.2699\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5163 - val_loss: 8.3400\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5716 - val_loss: 8.2335\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5581 - val_loss: 8.1613\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5812 - val_loss: 8.3902\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5441 - val_loss: 8.2996\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6654 - val_loss: 8.3138\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6277 - val_loss: 8.0969\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5886 - val_loss: 8.0109\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.6617 - val_loss: 7.9810\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.4744 - val_loss: 8.3275\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5343 - val_loss: 8.2602\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6009 - val_loss: 8.1028\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7533 - val_loss: 8.0564\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5148 - val_loss: 7.8895\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 122us/step - loss: 5.4400 - val_loss: 7.9723\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4307 - val_loss: 8.2641\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5369 - val_loss: 7.8964\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5981 - val_loss: 7.9820\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6108 - val_loss: 7.9610\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4945 - val_loss: 7.8766\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4881 - val_loss: 7.9013\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5103 - val_loss: 8.0373\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4374 - val_loss: 8.2950\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 5.4285 - val_loss: 8.0581\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.3503 - val_loss: 7.9122\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4703 - val_loss: 8.1599\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4327 - val_loss: 8.0730\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4144 - val_loss: 8.1553\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4581 - val_loss: 8.0036\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4911 - val_loss: 7.9426\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4531 - val_loss: 8.2282\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3700 - val_loss: 8.0349\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4169 - val_loss: 7.8555\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3637 - val_loss: 8.0443\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4676 - val_loss: 7.7713\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.4204 - val_loss: 8.1339\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.5120 - val_loss: 7.7226\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.6091 - val_loss: 8.3562\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.4343 - val_loss: 8.1815\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5346 - val_loss: 8.4959\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.4746 - val_loss: 7.9972\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4119 - val_loss: 8.3647\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3806 - val_loss: 7.8882\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4487 - val_loss: 8.4947\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3620 - val_loss: 7.6022\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.6684 - val_loss: 7.7807\n",
      "Epoch 528/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.5802 - val_loss: 7.9779\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6321 - val_loss: 7.8741\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5844 - val_loss: 8.1269\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4903 - val_loss: 8.1649\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3792 - val_loss: 7.7794\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3694 - val_loss: 7.7317\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3717 - val_loss: 7.7794\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3686 - val_loss: 7.7704\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5308 - val_loss: 7.8325\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4189 - val_loss: 7.8979\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3287 - val_loss: 8.0781\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4859 - val_loss: 7.9431\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4513 - val_loss: 8.2339\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4431 - val_loss: 8.0496\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3450 - val_loss: 7.6888\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3142 - val_loss: 8.2262\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4070 - val_loss: 7.7403\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6386 - val_loss: 8.1996\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4788 - val_loss: 8.1397\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3389 - val_loss: 8.0614\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3585 - val_loss: 7.8618\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2749 - val_loss: 8.1397\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3149 - val_loss: 7.8924\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2397 - val_loss: 8.0079\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2593 - val_loss: 8.0283\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3791 - val_loss: 7.6318\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4212 - val_loss: 8.1164\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2838 - val_loss: 7.9604\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3222 - val_loss: 7.8944\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2824 - val_loss: 7.8299\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3074 - val_loss: 8.1530\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2960 - val_loss: 7.8184\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3383 - val_loss: 8.0381\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2803 - val_loss: 7.7948\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2543 - val_loss: 7.9567\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3904 - val_loss: 7.8565\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5410 - val_loss: 8.2652\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2701 - val_loss: 7.9913\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.3404 - val_loss: 8.2034\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1758 - val_loss: 7.6826\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3286 - val_loss: 8.1728\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2756 - val_loss: 7.8841\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3396 - val_loss: 8.8011\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7961 - val_loss: 7.7298\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2815 - val_loss: 8.3693\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3820 - val_loss: 7.9740\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2955 - val_loss: 8.3305\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4020 - val_loss: 7.8811\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3608 - val_loss: 7.8796\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2482 - val_loss: 7.7773\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3181 - val_loss: 8.1881\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3662 - val_loss: 8.1398\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3452 - val_loss: 7.8355\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.2094 - val_loss: 8.0094\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4545 - val_loss: 7.6739\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4484 - val_loss: 8.4759\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6651 - val_loss: 7.5523\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.8660 - val_loss: 8.0338\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3985 - val_loss: 7.9866\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3018 - val_loss: 7.8575\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2687 - val_loss: 7.7313\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1808 - val_loss: 7.7500\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.1564 - val_loss: 7.9678\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1813 - val_loss: 7.9374\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2312 - val_loss: 7.7957\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1512 - val_loss: 7.8573\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2005 - val_loss: 7.6416\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2843 - val_loss: 7.8648\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3015 - val_loss: 7.8323\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1847 - val_loss: 7.5477\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3843 - val_loss: 8.0170\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6149 - val_loss: 7.4669\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4387 - val_loss: 8.0959\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3077 - val_loss: 7.5914\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2008 - val_loss: 7.8710\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3077 - val_loss: 7.8540\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.2816 - val_loss: 7.8108\n",
      "Epoch 605/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 113us/step - loss: 5.2706 - val_loss: 7.8890\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3224 - val_loss: 7.6312\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1863 - val_loss: 7.3619\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1880 - val_loss: 7.4430\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1163 - val_loss: 7.6075\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1791 - val_loss: 7.7634\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1820 - val_loss: 7.6909\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3152 - val_loss: 8.0784\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2906 - val_loss: 7.3407\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3166 - val_loss: 7.4758\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.1501 - val_loss: 7.7314\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.1348 - val_loss: 7.5820\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4470 - val_loss: 8.1487\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2341 - val_loss: 7.5290\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2059 - val_loss: 7.4745\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2193 - val_loss: 7.4292\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0627 - val_loss: 7.5637\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2344 - val_loss: 7.5268\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3670 - val_loss: 7.4289\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4839 - val_loss: 7.7182\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1878 - val_loss: 7.2991\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1263 - val_loss: 7.8250\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2615 - val_loss: 7.4424\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0644 - val_loss: 7.6797\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1803 - val_loss: 7.5169\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0687 - val_loss: 7.7413\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0945 - val_loss: 7.4482\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1404 - val_loss: 7.5096\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2970 - val_loss: 7.5003\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2715 - val_loss: 7.5648\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1254 - val_loss: 7.4618\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0568 - val_loss: 7.6674\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0897 - val_loss: 7.5432\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0370 - val_loss: 7.3625\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0208 - val_loss: 7.6617\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0849 - val_loss: 7.2938\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5101 - val_loss: 7.6556\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7794 - val_loss: 7.3852\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3024 - val_loss: 7.6703\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.1934 - val_loss: 7.4183\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.0802 - val_loss: 7.6594\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0426 - val_loss: 7.4562\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1288 - val_loss: 7.4222\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2374 - val_loss: 7.5624\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0594 - val_loss: 7.5150\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0643 - val_loss: 7.8155\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0919 - val_loss: 7.1441\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1176 - val_loss: 7.4807\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3822 - val_loss: 7.4038\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.1373 - val_loss: 7.4375\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1978 - val_loss: 7.5937\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9956 - val_loss: 7.6240\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0401 - val_loss: 7.3119\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1009 - val_loss: 7.6704\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0880 - val_loss: 7.3086\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0866 - val_loss: 7.5611\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0847 - val_loss: 7.5325\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4048 - val_loss: 7.3731\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1150 - val_loss: 7.5679\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0598 - val_loss: 7.3111\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0274 - val_loss: 7.6223\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0441 - val_loss: 7.4985\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0950 - val_loss: 7.6963\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2240 - val_loss: 7.3553\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2396 - val_loss: 7.8058\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2272 - val_loss: 7.2531\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2057 - val_loss: 7.7244\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.0639 - val_loss: 7.3884\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0652 - val_loss: 7.3468\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0922 - val_loss: 7.7012\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2226 - val_loss: 7.2721\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2344 - val_loss: 7.7641\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1594 - val_loss: 7.2742\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2520 - val_loss: 7.2417\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1808 - val_loss: 7.6886\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4724 - val_loss: 7.8104\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4131 - val_loss: 7.3689\n",
      "Epoch 682/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.0789 - val_loss: 7.4999\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9847 - val_loss: 7.5160\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1725 - val_loss: 7.2485\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0766 - val_loss: 7.7609\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1780 - val_loss: 7.2701\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0927 - val_loss: 7.8155\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0374 - val_loss: 7.4331\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9510 - val_loss: 7.9234\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0457 - val_loss: 7.5309\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0328 - val_loss: 7.5202\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9351 - val_loss: 7.4101\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0732 - val_loss: 7.5714\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1029 - val_loss: 7.2982\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.0969 - val_loss: 7.3315\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0147 - val_loss: 7.2823\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.9827 - val_loss: 7.3050\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0971 - val_loss: 7.3825\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.1071 - val_loss: 7.6046\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0895 - val_loss: 7.3773\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1138 - val_loss: 7.7939\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3785 - val_loss: 7.3115\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2314 - val_loss: 7.7822\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0878 - val_loss: 7.2823\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9160 - val_loss: 7.7928\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9846 - val_loss: 7.2571\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0435 - val_loss: 7.6521\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.0307 - val_loss: 7.3495\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9949 - val_loss: 7.6712\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.0021 - val_loss: 7.2846\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.0002 - val_loss: 7.4093\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1130 - val_loss: 7.2683\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0456 - val_loss: 7.4217\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0253 - val_loss: 7.2912\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0866 - val_loss: 7.2062\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0840 - val_loss: 7.3323\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1019 - val_loss: 7.2170\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1405 - val_loss: 7.3779\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.0620 - val_loss: 7.4224\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0699 - val_loss: 7.4432\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0642 - val_loss: 7.4209\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1019 - val_loss: 7.6112\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0581 - val_loss: 7.2668\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1135 - val_loss: 7.4483\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.0847 - val_loss: 7.3713\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0065 - val_loss: 7.2428\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2199 - val_loss: 7.6497\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1252 - val_loss: 7.3795\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 5.0804 - val_loss: 7.3893\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0170 - val_loss: 7.4574\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9849 - val_loss: 7.4170\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9921 - val_loss: 7.3017\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.0218 - val_loss: 7.4009\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1068 - val_loss: 7.4015\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0230 - val_loss: 7.5001\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0767 - val_loss: 7.1328\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1605 - val_loss: 7.7127\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0770 - val_loss: 7.4090\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0639 - val_loss: 7.5428\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9747 - val_loss: 7.2556\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0968 - val_loss: 7.1264\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0639 - val_loss: 7.2588\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8777 - val_loss: 7.3053\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9707 - val_loss: 7.7057\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9615 - val_loss: 7.2674\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0204 - val_loss: 7.3075\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.9641 - val_loss: 7.1210\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9933 - val_loss: 7.6499\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0505 - val_loss: 7.5543\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9912 - val_loss: 7.5040\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.0425 - val_loss: 7.3307\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0006 - val_loss: 7.1227\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0565 - val_loss: 7.7733\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2200 - val_loss: 7.0205\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0154 - val_loss: 7.3484\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1296 - val_loss: 7.6772\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2201 - val_loss: 7.4451\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0996 - val_loss: 7.1418\n",
      "Epoch 759/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 111us/step - loss: 4.9965 - val_loss: 7.3919\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9516 - val_loss: 7.3826\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9486 - val_loss: 7.4471\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1464 - val_loss: 7.5564\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9412 - val_loss: 7.4083\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8548 - val_loss: 7.2772\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8971 - val_loss: 7.4660\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9312 - val_loss: 7.2811\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.9811 - val_loss: 7.9332\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1018 - val_loss: 7.2793\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9106 - val_loss: 7.8185\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0780 - val_loss: 7.2582\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2048 - val_loss: 7.8117\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1407 - val_loss: 7.6857\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0176 - val_loss: 7.2421\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8957 - val_loss: 7.2324\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8721 - val_loss: 7.2200\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9101 - val_loss: 7.2685\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8892 - val_loss: 7.3944\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9500 - val_loss: 7.2266\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1446 - val_loss: 7.4597\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0920 - val_loss: 7.4199\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9558 - val_loss: 7.2845\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9746 - val_loss: 7.4430\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9546 - val_loss: 7.4652\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1387 - val_loss: 7.6378\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9704 - val_loss: 7.3951\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9615 - val_loss: 7.5250\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9474 - val_loss: 7.3632\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8768 - val_loss: 7.4787\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.9067 - val_loss: 7.2257\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.9765 - val_loss: 7.4761\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9678 - val_loss: 7.3050\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9381 - val_loss: 7.5031\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0049 - val_loss: 7.1768\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0677 - val_loss: 7.6741\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1172 - val_loss: 7.3461\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0551 - val_loss: 7.3739\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9886 - val_loss: 7.1207\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6349 - val_loss: 7.3834\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1330 - val_loss: 7.3992\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9913 - val_loss: 7.3783\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1485 - val_loss: 7.7986\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2748 - val_loss: 7.4470\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9611 - val_loss: 7.5736\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3495 - val_loss: 7.7825\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5293 - val_loss: 7.2544\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3486 - val_loss: 7.7389\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1338 - val_loss: 7.5414\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0503 - val_loss: 7.6512\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.8965 - val_loss: 7.3569\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9022 - val_loss: 7.5867\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9293 - val_loss: 7.2618\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1999 - val_loss: 7.4553\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2132 - val_loss: 7.4817\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1061 - val_loss: 7.3258\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1074 - val_loss: 7.7477\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8801 - val_loss: 7.4195\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8910 - val_loss: 7.2570\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9874 - val_loss: 7.4129\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8794 - val_loss: 7.3466\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8866 - val_loss: 7.4390\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8708 - val_loss: 7.3145\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.9546 - val_loss: 7.4858\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.244 - 0s 105us/step - loss: 5.0358 - val_loss: 7.5311\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0827 - val_loss: 7.5691\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0085 - val_loss: 7.3972\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9049 - val_loss: 7.5298\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9248 - val_loss: 7.2656\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0073 - val_loss: 7.2771\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0074 - val_loss: 7.3983\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0725 - val_loss: 7.3466\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1434 - val_loss: 7.4758\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9140 - val_loss: 7.3110\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8604 - val_loss: 7.3896\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9453 - val_loss: 7.2076\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9590 - val_loss: 7.4608\n",
      "Epoch 836/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 4.8719 - val_loss: 7.3616\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8983 - val_loss: 7.2921\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8818 - val_loss: 7.4228\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9797 - val_loss: 7.4101\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9193 - val_loss: 7.1855\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9393 - val_loss: 7.2711\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9987 - val_loss: 7.5018\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0231 - val_loss: 7.0512\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.9911 - val_loss: 7.2146\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1437 - val_loss: 7.6077\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.1330 - val_loss: 7.3019\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0866 - val_loss: 7.2373\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8909 - val_loss: 7.3180\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9024 - val_loss: 7.0724\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8802 - val_loss: 7.5685\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9622 - val_loss: 7.1043\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8784 - val_loss: 7.4781\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0910 - val_loss: 6.9992\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0833 - val_loss: 7.3193\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4776 - val_loss: 7.2897\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1589 - val_loss: 7.4089\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0197 - val_loss: 7.1744\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9946 - val_loss: 7.4540\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1548 - val_loss: 7.2216\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9112 - val_loss: 7.3403\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9346 - val_loss: 7.5908\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8640 - val_loss: 7.1974\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9459 - val_loss: 7.2635\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9634 - val_loss: 7.3951\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0695 - val_loss: 7.4656\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1563 - val_loss: 7.6485\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1849 - val_loss: 7.2216\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9797 - val_loss: 7.6113\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2860 - val_loss: 7.0492\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1797 - val_loss: 7.3017\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.9054 - val_loss: 7.4811\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.9899 - val_loss: 7.3544\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0632 - val_loss: 7.1197\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9321 - val_loss: 7.4235\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0442 - val_loss: 7.4970\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8343 - val_loss: 7.5879\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9271 - val_loss: 7.1217\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9544 - val_loss: 7.2805\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8810 - val_loss: 7.3502\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8353 - val_loss: 7.2593\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8694 - val_loss: 7.2218\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8142 - val_loss: 7.2994\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9123 - val_loss: 7.3084\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0148 - val_loss: 7.1508\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9277 - val_loss: 7.3016\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8722 - val_loss: 7.4342\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8302 - val_loss: 7.2371\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1873 - val_loss: 7.5027\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9491 - val_loss: 7.3779\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.9114 - val_loss: 7.2317\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8686 - val_loss: 7.3978\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8489 - val_loss: 7.3705\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9589 - val_loss: 7.3872\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8676 - val_loss: 7.4082\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8752 - val_loss: 7.1567\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8282 - val_loss: 7.5206\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8044 - val_loss: 7.3346\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9374 - val_loss: 7.3563\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9197 - val_loss: 7.3706\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1627 - val_loss: 7.5170\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0568 - val_loss: 7.2201\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9111 - val_loss: 7.2876\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9053 - val_loss: 7.2878\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8872 - val_loss: 7.7075\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8332 - val_loss: 7.3276\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8592 - val_loss: 7.3816\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8874 - val_loss: 7.3408\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.9268 - val_loss: 7.1176\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.9785 - val_loss: 7.0603\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0928 - val_loss: 7.2932\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9191 - val_loss: 7.3600\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9656 - val_loss: 7.2628\n",
      "Epoch 913/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 5.0609 - val_loss: 7.5599\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9312 - val_loss: 7.1571\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8827 - val_loss: 7.3475\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2610 - val_loss: 7.0761\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3177 - val_loss: 7.6044\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1909 - val_loss: 7.2828\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0608 - val_loss: 7.1536\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9438 - val_loss: 7.4411\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8768 - val_loss: 7.3776\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.1119 - val_loss: 7.2806\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8468 - val_loss: 7.4666\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9631 - val_loss: 7.2055\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8321 - val_loss: 7.6075\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9236 - val_loss: 7.3149\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.0434 - val_loss: 7.0999\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8982 - val_loss: 7.2776\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8740 - val_loss: 7.4533\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9220 - val_loss: 7.5356\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8854 - val_loss: 7.2514\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8729 - val_loss: 7.1713\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0133 - val_loss: 7.2183\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9269 - val_loss: 7.4668\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8485 - val_loss: 7.3513\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9372 - val_loss: 7.5140\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8361 - val_loss: 7.2380\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8227 - val_loss: 7.5769\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9464 - val_loss: 7.4669\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9153 - val_loss: 7.2905\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8970 - val_loss: 7.4850\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9037 - val_loss: 7.4410\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9718 - val_loss: 7.2647\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9419 - val_loss: 7.2070\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8308 - val_loss: 7.4014\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8677 - val_loss: 7.3903\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8494 - val_loss: 7.1183\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7750 - val_loss: 7.3898\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9111 - val_loss: 7.4705\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8080 - val_loss: 7.0840\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8587 - val_loss: 7.5653\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9669 - val_loss: 7.2146\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0114 - val_loss: 7.4419\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.8941 - val_loss: 7.1923\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9193 - val_loss: 7.5888\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9007 - val_loss: 7.2758\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8271 - val_loss: 7.4490\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8302 - val_loss: 7.1840\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8050 - val_loss: 7.5117\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1677 - val_loss: 7.2584\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9659 - val_loss: 7.4147\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9270 - val_loss: 7.3422\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.8262 - val_loss: 7.1231\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.0403 - val_loss: 7.4112\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.9117 - val_loss: 7.1717\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1683 - val_loss: 7.8141\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6810 - val_loss: 7.0400\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3840 - val_loss: 7.8112\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1774 - val_loss: 7.1971\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1932 - val_loss: 7.3832\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9816 - val_loss: 7.2952\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8879 - val_loss: 7.3933\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0001 - val_loss: 7.4258\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.9059 - val_loss: 7.2684\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8603 - val_loss: 7.4421\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.8687 - val_loss: 7.2941\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.9307 - val_loss: 7.7756\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9324 - val_loss: 7.1703\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9854 - val_loss: 7.6425\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 4.8939 - val_loss: 7.2103\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8049 - val_loss: 7.4390\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8037 - val_loss: 7.2652\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9106 - val_loss: 7.6067\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9701 - val_loss: 7.0837\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9195 - val_loss: 7.6726\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9458 - val_loss: 7.1789\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9663 - val_loss: 7.2947\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.8951 - val_loss: 7.2046\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9344 - val_loss: 7.2795\n",
      "Epoch 990/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 4.9141 - val_loss: 7.3785\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7891 - val_loss: 7.1749\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0025 - val_loss: 7.6310\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1673 - val_loss: 7.1009\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.0361 - val_loss: 7.1174\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9924 - val_loss: 7.2697\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.9306 - val_loss: 7.2812\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9885 - val_loss: 7.5827\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7889 - val_loss: 7.7222\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.8637 - val_loss: 7.3104\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8524 - val_loss: 7.4604\n",
      "5.416455074892205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.2223332 , -2.14109   ,  0.7573525 , -0.214475  ,  0.15359765],\n",
       "        [-1.8977685 ,  0.3822674 , -0.5006837 ,  1.0953236 , -1.647411  ],\n",
       "        [ 1.2171786 , -1.2588183 ,  0.9678434 , -1.172159  , -1.1623416 ],\n",
       "        [ 1.6015115 , -1.097012  ,  1.8338016 , -1.802965  , -1.5164527 ],\n",
       "        [ 0.8062251 , -0.647942  ,  0.3865916 ,  0.07467788, -0.39499325],\n",
       "        [ 1.050703  , -0.90699875, -2.0405416 ,  1.6709263 , -1.5172808 ],\n",
       "        [-2.3087528 , -0.6896982 , -2.0316281 , -0.02842641, -1.1831399 ]],\n",
       "       dtype=float32),\n",
       " array([-0.8264746 ,  0.20169748,  1.3666537 , -0.24203554, -0.00417768],\n",
       "       dtype=float32),\n",
       " array([[  2.5156307 ,   1.5960205 ,   0.16944164,   0.5976743 ,\n",
       "         -14.093962  ,   0.30960616,  -2.5563164 ,  -0.6737516 ,\n",
       "           1.1948102 ,  -1.023744  ],\n",
       "        [  1.9818954 ,  -5.103624  , -12.387857  ,   0.6536983 ,\n",
       "          -1.2061354 ,  -0.25587824,  -1.7684783 ,  -1.2329873 ,\n",
       "           1.3774157 ,  -1.336538  ],\n",
       "        [  1.0062516 ,  -1.8477838 ,   0.12146873,   4.7014284 ,\n",
       "          -0.13528804,  -0.2679188 ,  -1.007136  ,  -1.1481748 ,\n",
       "           1.3283496 ,  -1.227512  ],\n",
       "        [  0.02863326,  -0.9643069 ,  -3.259506  ,  -0.4677735 ,\n",
       "           0.54632795,   0.26522627,  -0.04720902,  -0.7046993 ,\n",
       "           0.31769463,  -0.86474353],\n",
       "        [  0.7409717 ,  -5.1501775 , -10.041855  ,  -0.3416759 ,\n",
       "          -9.113735  ,   0.36692694,  -1.3409129 ,  -1.2899078 ,\n",
       "           0.8528154 ,  -0.49398792]], dtype=float32),\n",
       " array([ 2.0772603 ,  1.3160832 , -1.6337707 ,  0.16386211, -0.34931776,\n",
       "         0.12600312, -2.0744476 , -2.663412  ,  2.409139  , -2.738241  ],\n",
       "       dtype=float32),\n",
       " array([[ 2.6105618],\n",
       "        [-3.3983252],\n",
       "        [-3.876302 ],\n",
       "        [-7.3412404],\n",
       "        [-3.3961382],\n",
       "        [ 5.436575 ],\n",
       "        [-3.4193308],\n",
       "        [-3.3801012],\n",
       "        [ 3.0178208],\n",
       "        [-3.3696783]], dtype=float32),\n",
       " array([2.5368679], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_tanh(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_tanh.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2269 - val_loss: 0.1898\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.1174 - val_loss: 0.0219\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0463 - val_loss: 0.0346\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0299 - val_loss: 0.0080\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0176 - val_loss: 0.0098\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0211 - val_loss: 0.0201\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0224 - val_loss: 0.0190\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0190 - val_loss: 0.0148\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0166 - val_loss: 0.0106\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0142 - val_loss: 0.0078\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0125 - val_loss: 0.0089\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0116 - val_loss: 0.0057\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0107 - val_loss: 0.0056\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0095 - val_loss: 0.0061\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0099 - val_loss: 0.0040\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0098 - val_loss: 0.0037\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0092 - val_loss: 0.0044\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0096 - val_loss: 0.0051\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0124 - val_loss: 0.0082\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0104 - val_loss: 0.0048\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0089 - val_loss: 0.0048\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0074 - val_loss: 0.0037\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0083 - val_loss: 0.0041\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0083 - val_loss: 0.0042\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0044\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0038\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0042\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0073 - val_loss: 0.0041\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0048\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0079 - val_loss: 0.0044\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0082 - val_loss: 0.0048\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0053\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0064\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0042\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0083 - val_loss: 0.0088\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0067\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0067\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0042 - val_loss: 0.0076\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0068\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0047 - val_loss: 0.0069\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0104\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0111\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 119us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0071\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0075\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0064\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0072\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0061\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0077\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0081\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0051 - val_loss: 0.0088\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0038 - val_loss: 0.0082\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0070\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0083\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0060\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.006 - 0s 133us/step - loss: 0.0033 - val_loss: 0.0058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 195us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0076\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0059\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0081\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0078\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0060\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0071\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0091\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0079\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0064\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0069\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0071\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0077\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0035 - val_loss: 0.0064\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0100\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0070\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0068\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0061\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0033 - val_loss: 0.0073\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0068\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0062\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0071\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0074\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0062\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0066\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 106us/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0026 - val_loss: 0.0076\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0070\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0026 - val_loss: 0.0075\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0068\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0065\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0065\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 109us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0075\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0074\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0071\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0069\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0086\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 111us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0076\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0070\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 118us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0073\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0075\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0064\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0085\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0072\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 120us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 0.0075\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0055\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0065\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "0.00892431940883398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.31197202,  0.9247534 , -0.016066  , -0.7188173 , -0.69399923],\n",
       "        [ 0.74928015, -0.16331932,  0.6013086 , -0.01717093,  0.28937015],\n",
       "        [ 0.9315232 ,  0.04901846, -0.4507132 ,  0.36546084, -0.253138  ],\n",
       "        [ 0.28925988,  0.8750711 , -0.86104447, -0.01099506, -0.22964889],\n",
       "        [ 0.11316929, -0.39437932, -0.12877266,  0.08266321, -0.07851332],\n",
       "        [-0.75901866,  0.13666558,  0.7415113 , -0.6458094 ,  0.03180619],\n",
       "        [ 0.2778316 , -0.1454671 , -0.04315255,  0.3823157 ,  0.34173375],\n",
       "        [ 0.36899137,  0.5073173 , -0.531642  ,  0.08378247, -0.5735824 ],\n",
       "        [-1.36387   , -1.0155133 , -0.36032096,  0.35436863, -0.15180081],\n",
       "        [ 0.6279279 ,  0.67132026, -0.1251588 ,  0.40625146, -0.09595388],\n",
       "        [-0.20773685, -0.7296029 , -0.10307337,  0.9084429 ,  0.19524957],\n",
       "        [ 0.7886077 ,  1.8091712 , -0.6115882 ,  0.43725145,  0.43623254],\n",
       "        [ 0.48146418,  0.23617591,  1.1177322 ,  0.89241886,  1.2246758 ],\n",
       "        [-1.4576946 ,  0.7656241 ,  0.4678227 ,  0.37104592, -1.2866803 ],\n",
       "        [ 0.56495017, -0.62716407,  0.31522387,  0.22380821, -0.19924323],\n",
       "        [-0.30498707,  0.52185374, -0.28570998, -0.40169883, -0.20903392],\n",
       "        [ 0.2909193 ,  0.6346003 , -0.2763828 , -0.43870455,  0.4076781 ],\n",
       "        [-0.4712067 , -1.1768056 , -0.74100506,  0.20412907,  0.480319  ],\n",
       "        [-1.0654466 , -1.3026199 ,  0.18205883,  0.07836591,  0.4658945 ],\n",
       "        [-0.9000258 ,  0.1381082 , -0.88396955,  0.91667897, -0.4541511 ],\n",
       "        [ 0.9452425 ,  0.2117098 ,  0.30445942,  0.08858923,  1.4718779 ],\n",
       "        [-0.4157875 ,  0.92477083,  0.17887747,  0.2778411 ,  0.99349207]],\n",
       "       dtype=float32),\n",
       " array([ 0.4629101 , -0.05370368, -0.39331564, -0.08196219,  0.3376206 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.5323847 , -0.03651345, -0.4612262 , -0.2173561 ,  0.07506724,\n",
       "         -0.37989005, -0.2706728 , -0.238251  ,  0.00871236,  0.3442043 ],\n",
       "        [-0.5284738 ,  0.21066162,  0.3786854 ,  0.0985519 , -0.2750701 ,\n",
       "          0.5989089 , -0.52265745,  0.38845533,  0.03385294, -0.49802303],\n",
       "        [-0.02635901,  0.1095177 ,  0.09351953,  0.17274193, -0.43545365,\n",
       "          0.52990955, -0.61736584,  0.13424197,  0.36315572, -0.5007046 ],\n",
       "        [-0.07899766, -0.09365411,  0.02506256, -0.06320058, -0.35352147,\n",
       "          0.6042623 ,  0.18959136, -0.36324343,  0.35060486, -0.40447244],\n",
       "        [ 0.22758888,  0.313614  , -0.10037117,  0.1643116 ,  0.00603194,\n",
       "         -0.24333616,  0.19107202,  0.34045944,  0.10502047,  0.17155437]],\n",
       "       dtype=float32),\n",
       " array([-0.03434902, -0.14401169,  0.09991266,  0.13850443,  0.12128209,\n",
       "         0.0116376 , -0.03438748,  0.01275499, -0.07730428,  0.01413315],\n",
       "       dtype=float32),\n",
       " array([[-0.2540306 ],\n",
       "        [-0.06870486],\n",
       "        [ 0.08017794],\n",
       "        [-0.01473667],\n",
       "        [ 0.00293363],\n",
       "        [ 0.49838918],\n",
       "        [-0.04981971],\n",
       "        [-0.00786834],\n",
       "        [ 0.03662884],\n",
       "        [-0.18975757]], dtype=float32),\n",
       " array([0.09355319], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_linear(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_linear.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0837 - val_loss: 0.0290\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0390 - val_loss: 0.0262\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0391 - val_loss: 0.0258\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0295 - val_loss: 0.0174\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0279 - val_loss: 0.0149\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0234 - val_loss: 0.0133\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0197 - val_loss: 0.0084\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0169 - val_loss: 0.0058\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0136 - val_loss: 0.0058\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0120 - val_loss: 0.0031\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0106 - val_loss: 0.0040\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0100 - val_loss: 0.0038\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0096 - val_loss: 0.0052\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0098 - val_loss: 0.0051\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0099 - val_loss: 0.0052\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0085 - val_loss: 0.0051\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0083 - val_loss: 0.0052\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0083 - val_loss: 0.0055\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0048\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0081 - val_loss: 0.0052\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0080 - val_loss: 0.0051\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0063\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0081 - val_loss: 0.0049\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 179us/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 152us/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 172us/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 165us/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 179us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 188us/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 174us/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.006 - 0s 133us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0059 - val_loss: 0.0066\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 110us/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0060 - val_loss: 0.0066\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0064\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 150us/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0078\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0050 - val_loss: 0.0071\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 139us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0059\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 95us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0062\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0059\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 137us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 147us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 398us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0063\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 106us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 98us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 143us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "0.008124749176204205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.42083484, -0.24641335, -0.23223355,  0.41347745, -0.18533747],\n",
       "        [-0.1936484 , -0.5641768 , -0.3084368 ,  0.01084065, -0.17443319],\n",
       "        [-0.40134916, -0.7474982 , -0.38377753,  0.20883588, -0.7786139 ],\n",
       "        [ 0.0775115 , -0.5081579 , -0.4810326 ,  0.17256127, -0.74621445],\n",
       "        [-0.2177377 , -0.31496894, -0.08759028, -0.07791077,  0.04922814],\n",
       "        [-0.05694113, -0.15053698, -0.36387563,  0.67322767, -0.7665299 ],\n",
       "        [-0.5960933 , -0.6284287 , -0.38341343, -0.5639229 , -0.45138615],\n",
       "        [-0.69280183, -0.26468223, -0.615741  ,  0.5011787 , -0.71763784],\n",
       "        [-0.3584345 , -0.3974791 ,  0.21922228, -0.12247133, -0.6264677 ],\n",
       "        [-0.24556394, -0.2052883 , -0.5543784 ,  0.78527534, -0.7002575 ],\n",
       "        [-0.44584474, -0.52670515,  0.07792003, -0.4098202 , -0.30880177],\n",
       "        [-0.30181888, -0.03213681, -0.12528053,  0.2042669 , -0.03051895],\n",
       "        [ 0.07384815, -0.4101507 ,  0.02302563, -0.27624205,  0.08569348],\n",
       "        [-0.7483207 , -0.24559197, -0.3726166 ,  2.881146  ,  0.09240242],\n",
       "        [-0.42608872, -0.04602101,  0.18626124,  0.22604504,  0.17728132],\n",
       "        [-0.45614615, -0.06146505, -0.35253596,  0.02429648, -0.09752531],\n",
       "        [-0.509761  , -0.6438879 , -0.5405274 , -0.06452359, -0.35995272],\n",
       "        [ 0.00379664, -0.0822947 , -0.3706842 ,  1.0411763 , -0.53862387],\n",
       "        [-0.00796859, -0.7334921 , -0.07638343, -1.2141588 ,  0.21710557],\n",
       "        [-0.3324321 , -0.04087526, -0.15201144,  0.8336232 , -0.38238385],\n",
       "        [-0.6537293 ,  0.03287173, -0.5251095 , -2.5183218 , -0.7320068 ],\n",
       "        [-0.11768223,  0.09624416,  0.22437172, -0.05708631, -0.09212668]],\n",
       "       dtype=float32),\n",
       " array([-0.3175235 , -0.32117224, -0.22751352,  0.34689546, -0.32289702],\n",
       "       dtype=float32),\n",
       " array([[ 0.10700025,  0.8054026 , -0.49352294,  0.2680046 ,  0.49580705,\n",
       "         -0.2145811 , -0.06470209,  0.41305608, -0.56875706,  0.03393367],\n",
       "        [ 0.25914365,  0.807956  , -0.06421957,  0.10529383,  0.16305399,\n",
       "         -0.30257827,  0.33630678, -0.25947994, -0.25591633,  0.8001903 ],\n",
       "        [-0.13517568, -0.25040016,  0.14561951, -0.35532838, -0.43164054,\n",
       "          0.16135588, -0.06123967, -0.37289348,  0.51023036, -0.05289787],\n",
       "        [-0.8016624 , -0.4742738 , -0.40788683, -0.3610684 ,  0.743118  ,\n",
       "         -0.6388124 , -0.87769663, -0.9441552 , -0.5485736 , -0.7696992 ],\n",
       "        [-0.61643386, -0.5742337 ,  0.23202701, -0.14535767, -0.27055255,\n",
       "          0.19917238,  0.576786  ,  0.09662558, -0.4212755 , -0.19803607]],\n",
       "       dtype=float32),\n",
       " array([-0.31765276,  0.8019522 , -0.32717982, -0.3365332 , -0.16749018,\n",
       "        -0.1805538 , -0.00595042, -0.31764004, -0.18598256, -0.00145548],\n",
       "       dtype=float32),\n",
       " array([[-0.32450658],\n",
       "        [ 0.6772468 ],\n",
       "        [-0.24955378],\n",
       "        [ 0.03683484],\n",
       "        [ 0.5386516 ],\n",
       "        [ 0.39405373],\n",
       "        [ 0.86862653],\n",
       "        [-0.31409138],\n",
       "        [-0.49624443],\n",
       "        [ 0.4724008 ]], dtype=float32),\n",
       " array([-0.4559219], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_relu(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2073 - val_loss: 0.1519\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0764 - val_loss: 0.0732\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0665 - val_loss: 0.0239\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0425 - val_loss: 0.0365\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0300 - val_loss: 0.0192\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0339 - val_loss: 0.0147\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0239 - val_loss: 0.0193\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0256 - val_loss: 0.0125\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0218 - val_loss: 0.0111\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0211 - val_loss: 0.0099\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0187 - val_loss: 0.0086\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0178 - val_loss: 0.0082\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0173 - val_loss: 0.0076\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0169 - val_loss: 0.0074\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0163 - val_loss: 0.0078\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0165 - val_loss: 0.0072\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0157 - val_loss: 0.0072\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0154 - val_loss: 0.0075\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0150 - val_loss: 0.0071\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0147 - val_loss: 0.0071\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0142 - val_loss: 0.0070\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0140 - val_loss: 0.0070\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0136 - val_loss: 0.0069\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0134 - val_loss: 0.0069\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0132 - val_loss: 0.0072\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0129 - val_loss: 0.0070\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0123 - val_loss: 0.0069\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0124 - val_loss: 0.0069\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0125 - val_loss: 0.0070\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0118 - val_loss: 0.0070\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0116 - val_loss: 0.0070\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0113 - val_loss: 0.0068\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0114 - val_loss: 0.0068\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0116 - val_loss: 0.0067\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0112 - val_loss: 0.0069\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0110 - val_loss: 0.0066\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0107 - val_loss: 0.0069\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0104 - val_loss: 0.0065\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0103 - val_loss: 0.0065\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0101 - val_loss: 0.0063\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0100 - val_loss: 0.0063\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0102 - val_loss: 0.0064\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0097 - val_loss: 0.0065\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0103 - val_loss: 0.0065\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0098 - val_loss: 0.0061\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0097 - val_loss: 0.0061\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0089 - val_loss: 0.0058\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0083 - val_loss: 0.0055\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0079 - val_loss: 0.0054\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0056\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0055\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0076 - val_loss: 0.0053\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0079 - val_loss: 0.0058\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0052\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0064\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0079 - val_loss: 0.0054\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0077 - val_loss: 0.0055\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0083 - val_loss: 0.0052\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0078 - val_loss: 0.0052\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0061\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0050\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0057\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0066\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0051\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0048\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 807us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 117us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0066\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0069\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0062\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 108us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.006 - 0s 112us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 105us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0042 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0040 - val_loss: 0.0059\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0093\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0075\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 126us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0066\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 126us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 143us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0080\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0083\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.008 - 0s 112us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "0.008505837991833687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.76253664,  0.04063142,  0.3297249 , -0.74377745, -0.11426492],\n",
       "        [ 0.11159025, -0.61782753, -0.04098615, -0.74454576, -0.00388688],\n",
       "        [-0.7907695 , -0.6031821 , -0.11468627, -0.29220608, -0.6800088 ],\n",
       "        [-0.29088697, -0.4500564 ,  0.10777918, -0.24671173, -0.6342279 ],\n",
       "        [-0.22812006, -0.38321656, -0.13518324,  0.07464624, -0.8135084 ],\n",
       "        [ 0.10817076, -0.38393953,  0.62572914, -0.26337466,  0.07196265],\n",
       "        [ 0.06504642, -0.7971959 , -0.35640752, -0.5411264 , -0.40084612],\n",
       "        [-0.4986551 , -0.10826931,  0.25653   , -0.49404967, -0.77899784],\n",
       "        [ 0.2770133 , -0.45049146, -0.0224238 , -0.28064212, -0.02143971],\n",
       "        [-0.33947763, -0.01427973,  0.57788914, -0.30550605,  0.07334879],\n",
       "        [-0.04743984, -0.31444746, -0.6017709 , -0.04234437, -0.2759054 ],\n",
       "        [-0.37369227, -0.03158141,  0.0770127 , -0.12832436, -0.8196336 ],\n",
       "        [-0.29284748, -0.30290475, -0.2442945 , -0.74942315,  0.05783346],\n",
       "        [-0.40560824, -0.4752971 ,  2.3632593 , -0.5312214 , -0.11436688],\n",
       "        [-0.11136073, -0.6674834 ,  0.14521603,  0.06258398, -0.09373724],\n",
       "        [-0.11673088, -0.56575716, -0.07769093, -0.14909934, -0.46032956],\n",
       "        [-0.6320415 , -0.5863638 , -0.07597372,  0.17463301, -0.07443372],\n",
       "        [-0.33102176, -0.7039075 ,  0.59704167,  0.26429468, -0.6595657 ],\n",
       "        [-0.6741667 , -0.2685475 , -0.94433767,  0.02214764, -0.59847295],\n",
       "        [-0.6905035 , -0.7750954 ,  0.609618  , -0.23673336, -0.22487813],\n",
       "        [-0.02079633, -0.47318906, -2.6088846 , -0.3016484 , -0.23330241],\n",
       "        [-0.66752803,  0.13016133,  0.36573678, -0.72534126, -0.2880677 ]],\n",
       "       dtype=float32),\n",
       " array([-0.34442803, -0.36025667, -0.04163111, -0.2676043 , -0.38769364],\n",
       "       dtype=float32),\n",
       " array([[-0.13223241, -0.12535203, -0.29556546,  0.74865335, -0.6107091 ,\n",
       "          0.15923011, -0.7949279 ,  0.5943785 , -0.9864978 , -0.28296524],\n",
       "        [-0.11986028, -0.55221844,  0.24765652,  0.10759528,  0.03846556,\n",
       "         -0.24513806, -0.30299133,  0.3070985 , -0.3164994 ,  0.36654806],\n",
       "        [ 0.77448374,  0.7796627 , -0.7819196 , -0.8036232 , -0.59465176,\n",
       "         -0.79587805,  0.88416445, -0.7602723 , -2.983198  , -0.77027845],\n",
       "        [ 0.93173826,  0.6020057 ,  0.23847455, -0.9413353 , -0.24304338,\n",
       "         -0.56782097, -0.06931777,  0.28833634, -0.6658268 , -0.48464411],\n",
       "        [ 0.00806155, -0.14179136, -0.55973494, -0.19970502,  0.5129183 ,\n",
       "         -0.3886708 ,  0.05570854,  0.14152156, -0.3022818 , -0.13853128]],\n",
       "       dtype=float32),\n",
       " array([-0.4738588 , -0.5556969 ,  0.07668637,  0.1438358 , -0.7607045 ,\n",
       "         0.09004434, -0.69046205, -0.58099765,  0.47412795, -0.84764826],\n",
       "       dtype=float32),\n",
       " array([[ 0.52963233],\n",
       "        [ 0.41350856],\n",
       "        [-0.71389353],\n",
       "        [-0.6913117 ],\n",
       "        [-0.03276413],\n",
       "        [-0.6402662 ],\n",
       "        [ 0.6775358 ],\n",
       "        [-0.18332443],\n",
       "        [ 0.7657786 ],\n",
       "        [-0.15864055]], dtype=float32),\n",
       " array([0.19421881], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_sigmoid(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_sigmoid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0275\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0402 - val_loss: 0.0286\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0386 - val_loss: 0.0249\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0381 - val_loss: 0.0331\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0441 - val_loss: 0.0248\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0430 - val_loss: 0.0293\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0393 - val_loss: 0.0290\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0252\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0389 - val_loss: 0.0259\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0381 - val_loss: 0.0322\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0380 - val_loss: 0.0251\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0374 - val_loss: 0.0276\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0376 - val_loss: 0.0266\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0256\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0284\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0266\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0378 - val_loss: 0.0299\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0254\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0382 - val_loss: 0.0261\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0368 - val_loss: 0.0287\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0374 - val_loss: 0.0269\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0283\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0257\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0377 - val_loss: 0.0271\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0378 - val_loss: 0.0253\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0288\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0384 - val_loss: 0.0285\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0381 - val_loss: 0.0250\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0302\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0274\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0367 - val_loss: 0.0251\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0265\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0284\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0257\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0275\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0285\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0260\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.051 - 0s 118us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0373 - val_loss: 0.0259\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0284\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0298\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0280\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0288\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0284\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0275\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0276\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0264\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0291\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0287\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0259\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0287\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0260\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0258\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0379 - val_loss: 0.0283\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0372 - val_loss: 0.0259\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0372 - val_loss: 0.0256\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0267\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0297\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0258\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0255\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0270\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0288\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0370 - val_loss: 0.0255\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0274\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0273\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0259\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0283\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0258\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0374 - val_loss: 0.0256\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0374 - val_loss: 0.0272\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0287\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0293\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0267\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0372 - val_loss: 0.0268\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0260\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0262\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0289\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0255\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0286\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0366 - val_loss: 0.0262\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0252\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0263\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0284\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0258\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0286\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0267\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0254\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0263\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0367 - val_loss: 0.0275\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0299\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0373 - val_loss: 0.0272\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0283\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0259\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0373 - val_loss: 0.0265\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0290\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0262\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0375 - val_loss: 0.0283\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0372 - val_loss: 0.0278\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0287\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0288\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0273\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0294\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0371 - val_loss: 0.0275\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0266\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0263\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0275\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0269\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0268\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0258\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0367 - val_loss: 0.0264\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0366 - val_loss: 0.0287\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0294\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0273\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0286\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0282\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0370 - val_loss: 0.0258\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0269\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0287\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0367 - val_loss: 0.0277\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0284\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0289\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0264\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0373 - val_loss: 0.0279\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0274\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.023 - 0s 133us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0268\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0281\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0286\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0287\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0281\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0286\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0286\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0273\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0371 - val_loss: 0.0266\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 136us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0272\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0286\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0288\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0283\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0270\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0284\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0260\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0276\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0262\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0264\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0367 - val_loss: 0.0275\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0284\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0370 - val_loss: 0.0283\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0274\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0268\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0268\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "0.05466552823781967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-3.9049187e-01, -4.4809741e-01, -9.3458936e-02, -2.4739073e-01,\n",
       "         -8.2527161e-01],\n",
       "        [-2.0019412e-01, -2.6541314e-01, -2.9649273e-01, -6.7867243e-01,\n",
       "         -2.3971067e-01],\n",
       "        [ 2.6074218e-02, -1.2650952e-01,  2.0092204e-02, -5.6245637e-01,\n",
       "          3.6026403e-02],\n",
       "        [ 1.0131873e-01, -6.7715216e-01, -4.4517982e-01, -4.2253393e-01,\n",
       "         -7.2806931e-01],\n",
       "        [-3.1990841e-01, -7.1430020e-02, -4.9022174e-01, -4.1890171e-01,\n",
       "          2.0071103e-01],\n",
       "        [-5.5699891e-01, -2.5938502e-01, -4.0150887e-01, -4.5616952e-01,\n",
       "         -3.3004570e-01],\n",
       "        [-4.9469188e-01, -3.0628583e-01,  1.0743861e-04, -7.7638954e-01,\n",
       "         -2.1919270e-01],\n",
       "        [-4.4477087e-01, -4.1511416e-01, -3.0151343e-01,  8.0828100e-02,\n",
       "         -2.5638199e-01],\n",
       "        [ 4.6642404e-02, -1.3427813e-01,  3.4125559e-02, -2.5925195e-01,\n",
       "         -1.6974881e-01],\n",
       "        [-5.5418384e-01, -2.6836818e-01, -1.2468454e-02, -3.5941333e-01,\n",
       "         -7.8956342e-01],\n",
       "        [-3.6980337e-01, -7.1528471e-01, -7.9758275e-01, -4.1754541e-01,\n",
       "         -1.4162093e-01],\n",
       "        [-2.2825103e-02, -3.7785950e-01, -7.9715937e-01, -1.3964212e-01,\n",
       "         -1.7960651e-01],\n",
       "        [-4.1577590e-01, -3.3474332e-01, -5.7305996e-03,  1.2523416e-01,\n",
       "         -4.9421835e-01],\n",
       "        [-1.6448072e-01, -5.7356864e-01, -4.1111961e-01,  1.1103643e-01,\n",
       "          1.1043019e-01],\n",
       "        [-2.9235074e-01, -1.9780253e-01, -1.5044487e-01,  3.5522461e-02,\n",
       "         -4.9071353e-02],\n",
       "        [-4.5883480e-01, -5.3652555e-01, -4.7129956e-01, -6.3006872e-01,\n",
       "          3.3023149e-02],\n",
       "        [-5.3923422e-01, -3.4020108e-01, -1.6283584e-01, -5.2056856e-02,\n",
       "         -7.4206054e-01],\n",
       "        [-5.3044945e-01, -8.5491359e-01, -2.9443604e-01, -3.0634502e-01,\n",
       "         -2.6832211e-01],\n",
       "        [ 5.5095609e-02, -2.9324195e-01, -7.5969988e-01, -5.7355303e-01,\n",
       "         -5.6162429e-01],\n",
       "        [-6.5704161e-01, -1.7001407e-01, -5.1831990e-01, -7.3901296e-01,\n",
       "         -7.1966827e-01],\n",
       "        [-2.2263205e-01, -4.2386889e-01, -6.2723446e-01,  8.3207861e-02,\n",
       "         -3.1155649e-01],\n",
       "        [-7.5328273e-01, -8.5603780e-01, -5.7386541e-01, -3.7151146e-01,\n",
       "         -6.9559038e-01]], dtype=float32),\n",
       " array([-0.29984143, -0.38991743, -0.3280569 , -0.32444555, -0.36660534],\n",
       "       dtype=float32),\n",
       " array([[-0.02871496,  0.37792906, -0.79256487, -0.20885928,  0.73766166,\n",
       "         -0.1361335 ,  0.31785378,  0.2707496 , -0.73170215,  0.17505552],\n",
       "        [-0.8263479 ,  0.23351607, -0.18661557, -0.3972691 ,  0.23183377,\n",
       "          0.31454912, -0.0895158 ,  0.16891955, -0.5605106 ,  0.20439206],\n",
       "        [-0.53792566,  0.60687685, -0.44060016, -0.81646776,  0.34890342,\n",
       "          0.29428586, -0.24182591,  0.15666977, -0.4022029 , -0.13301145],\n",
       "        [ 0.09399489,  0.93488145, -0.11935639, -0.21025343,  0.25956306,\n",
       "         -0.66176903, -0.265306  ,  0.06167328, -0.41604632, -0.16031086],\n",
       "        [-0.03709853, -0.07724065, -0.14226888,  0.57202446, -0.7635125 ,\n",
       "         -0.12659119, -0.15130694, -0.0756916 ,  0.1108346 , -0.67354786]],\n",
       "       dtype=float32),\n",
       " array([-5.7586804e-03, -5.0736034e-08, -1.5031313e-35,  4.7509018e-21,\n",
       "        -1.7577331e-35,  1.1796740e-34, -6.7022974e-35,  1.1196197e-33,\n",
       "         5.3409109e-22, -4.1391779e-33], dtype=float32),\n",
       " array([[-1.9908471e-02],\n",
       "        [ 8.5481524e-09],\n",
       "        [ 7.6474919e-36],\n",
       "        [-1.5772480e-20],\n",
       "        [-7.3785803e-37],\n",
       "        [ 1.6748565e-34],\n",
       "        [ 9.4682461e-34],\n",
       "        [ 1.6761433e-33],\n",
       "        [-6.6559888e-21],\n",
       "        [-1.0930741e-32]], dtype=float32),\n",
       " array([0.21116003], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_tanh(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_tanh.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 36.1406 - val_loss: 32.8099\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 34.2633 - val_loss: 30.0687\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6028 - val_loss: 26.1430\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8170 - val_loss: 20.5416\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 22.8358 - val_loss: 14.0075\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 16.9104 - val_loss: 8.3600\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 10.7439 - val_loss: 5.1207\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3578 - val_loss: 4.0410\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0530 - val_loss: 3.7001\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1545 - val_loss: 2.7904\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6770 - val_loss: 1.5527\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6068 - val_loss: 0.6447\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4249 - val_loss: 0.2408\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6033 - val_loss: 0.1497\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1523 - val_loss: 0.1782\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4114 - val_loss: 0.2590\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2728 - val_loss: 0.3770\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4451 - val_loss: 0.5196\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6718 - val_loss: 0.6608\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8105 - val_loss: 0.7594\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8140 - val_loss: 0.7759\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.6960 - val_loss: 0.6975\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.5145 - val_loss: 0.5513\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3526 - val_loss: 0.3955\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2784 - val_loss: 0.2845\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3000 - val_loss: 0.2282\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3565 - val_loss: 0.1890\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3674 - val_loss: 0.1302\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2985 - val_loss: 0.0587\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.1831 - val_loss: 0.0141\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0846 - val_loss: 0.0293\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0486 - val_loss: 0.1019\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0774 - val_loss: 0.1962\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1379 - val_loss: 0.2665\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1875 - val_loss: 0.2824\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1982 - val_loss: 0.2412\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1670 - val_loss: 0.1645\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1121 - val_loss: 0.0857\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0605 - val_loss: 0.0330\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0332 - val_loss: 0.0170\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0353 - val_loss: 0.0276\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0543 - val_loss: 0.0442\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0708 - val_loss: 0.0504\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0711 - val_loss: 0.0438\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0558 - val_loss: 0.0329\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0355 - val_loss: 0.0281\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0220 - val_loss: 0.0334\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0207 - val_loss: 0.0450\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0284 - val_loss: 0.0553\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0376 - val_loss: 0.0579\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0414 - val_loss: 0.0511\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0372 - val_loss: 0.0381\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0273 - val_loss: 0.0239\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0163 - val_loss: 0.0128\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0094 - val_loss: 0.0027\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0132 - val_loss: 0.0017\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0155 - val_loss: 7.7138e-04\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 280us/step - loss: 0.0151 - val_loss: 7.1541e-04\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0126 - val_loss: 0.0024\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0077 - val_loss: 0.0095\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0075 - val_loss: 0.0126\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0085 - val_loss: 0.0139\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0095 - val_loss: 0.0132\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0087 - val_loss: 0.0078\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9630e-04 - val_loss: 0.0012\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8061e-04 - val_loss: 0.0012\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6625e-04 - val_loss: 0.0011\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5221e-04 - val_loss: 0.0011\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3757e-04 - val_loss: 0.0011\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2209e-04 - val_loss: 0.0011\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0623e-04 - val_loss: 0.0011\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9082e-04 - val_loss: 0.0011\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7638e-04 - val_loss: 0.0011\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6300e-04 - val_loss: 0.0011\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5027e-04 - val_loss: 0.0011\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3767e-04 - val_loss: 0.0011\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2488e-04 - val_loss: 0.0010\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1192e-04 - val_loss: 0.0010\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9906e-04 - val_loss: 9.8335e-04\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8660e-04 - val_loss: 9.5500e-04\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7466e-04 - val_loss: 9.3100e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6313e-04 - val_loss: 9.1271e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5182e-04 - val_loss: 9.0061e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4058e-04 - val_loss: 8.9418e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2935e-04 - val_loss: 8.9211e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1819e-04 - val_loss: 8.9271e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0726e-04 - val_loss: 8.9393e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9664e-04 - val_loss: 8.9392e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8635e-04 - val_loss: 8.9126e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7630e-04 - val_loss: 8.8511e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6644e-04 - val_loss: 8.7539e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5669e-04 - val_loss: 8.6261e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4703e-04 - val_loss: 8.4776e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3750e-04 - val_loss: 8.3192e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2815e-04 - val_loss: 8.1626e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1900e-04 - val_loss: 8.0165e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1004e-04 - val_loss: 7.8872e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0126e-04 - val_loss: 7.7775e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9262e-04 - val_loss: 7.6860e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8409e-04 - val_loss: 7.6095e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7569e-04 - val_loss: 7.5427e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6742e-04 - val_loss: 7.4802e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5932e-04 - val_loss: 7.4162e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5137e-04 - val_loss: 7.3467e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4357e-04 - val_loss: 7.2697e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3592e-04 - val_loss: 7.1845e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2839e-04 - val_loss: 7.0927e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2096e-04 - val_loss: 6.9969e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1365e-04 - val_loss: 6.9003e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0646e-04 - val_loss: 6.8062e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9939e-04 - val_loss: 6.7173e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9246e-04 - val_loss: 6.6355e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.8564e-04 - val_loss: 6.5615e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7895e-04 - val_loss: 6.4948e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7236e-04 - val_loss: 6.4343e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6586e-04 - val_loss: 6.3784e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5947e-04 - val_loss: 6.3247e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5320e-04 - val_loss: 6.2712e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4702e-04 - val_loss: 6.2163e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4097e-04 - val_loss: 6.1583e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3500e-04 - val_loss: 6.0970e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2914e-04 - val_loss: 6.0320e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2336e-04 - val_loss: 5.9641e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1767e-04 - val_loss: 5.8946e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1207e-04 - val_loss: 5.8245e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0658e-04 - val_loss: 5.7552e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0117e-04 - val_loss: 5.6879e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9585e-04 - val_loss: 5.6235e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9062e-04 - val_loss: 5.5626e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8547e-04 - val_loss: 5.5053e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8039e-04 - val_loss: 5.4512e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7541e-04 - val_loss: 5.3996e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7050e-04 - val_loss: 5.3497e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6568e-04 - val_loss: 5.3006e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6092e-04 - val_loss: 5.2516e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5625e-04 - val_loss: 5.2021e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5165e-04 - val_loss: 5.1516e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4711e-04 - val_loss: 5.1003e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4265e-04 - val_loss: 5.0487e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3827e-04 - val_loss: 4.9969e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3395e-04 - val_loss: 4.9459e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2970e-04 - val_loss: 4.8960e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2552e-04 - val_loss: 4.8477e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2140e-04 - val_loss: 4.8012e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1735e-04 - val_loss: 4.7567e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1336e-04 - val_loss: 4.7136e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0943e-04 - val_loss: 4.6719e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0556e-04 - val_loss: 4.6311e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0176e-04 - val_loss: 4.5904e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9801e-04 - val_loss: 4.5496e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9433e-04 - val_loss: 4.5084e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9069e-04 - val_loss: 4.4663e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8711e-04 - val_loss: 4.4242e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8359e-04 - val_loss: 4.3818e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8012e-04 - val_loss: 4.3395e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7670e-04 - val_loss: 4.2977e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7334e-04 - val_loss: 4.2567e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7003e-04 - val_loss: 4.2170e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6677e-04 - val_loss: 4.1784e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6356e-04 - val_loss: 4.1412e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6040e-04 - val_loss: 4.1050e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5729e-04 - val_loss: 4.0697e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5422e-04 - val_loss: 4.0351e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5120e-04 - val_loss: 4.0008e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4822e-04 - val_loss: 3.9666e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.4529e-04 - val_loss: 3.9324e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4241e-04 - val_loss: 3.8982e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3957e-04 - val_loss: 3.8641e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3677e-04 - val_loss: 3.8301e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.3401e-04 - val_loss: 3.7965e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3129e-04 - val_loss: 3.7635e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2861e-04 - val_loss: 3.7311e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2598e-04 - val_loss: 3.6992e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2338e-04 - val_loss: 3.6679e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2082e-04 - val_loss: 3.6375e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1830e-04 - val_loss: 3.6073e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1581e-04 - val_loss: 3.5779e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1336e-04 - val_loss: 3.5486e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1095e-04 - val_loss: 3.5195e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0857e-04 - val_loss: 3.4907e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0623e-04 - val_loss: 3.4617e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0393e-04 - val_loss: 3.4332e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0165e-04 - val_loss: 3.4048e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9941e-04 - val_loss: 3.3766e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9721e-04 - val_loss: 3.3488e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9503e-04 - val_loss: 3.3214e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9288e-04 - val_loss: 3.2944e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9077e-04 - val_loss: 3.2681e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8869e-04 - val_loss: 3.2421e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8663e-04 - val_loss: 3.2166e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8461e-04 - val_loss: 3.1913e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8262e-04 - val_loss: 3.1664e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.8065e-04 - val_loss: 3.1419e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7871e-04 - val_loss: 3.1174e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7681e-04 - val_loss: 3.0932e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7492e-04 - val_loss: 3.0693e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.7307e-04 - val_loss: 3.0455e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7124e-04 - val_loss: 3.0220e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.6943e-04 - val_loss: 2.9987e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6765e-04 - val_loss: 2.9757e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6590e-04 - val_loss: 2.9529e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6417e-04 - val_loss: 2.9305e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6247e-04 - val_loss: 2.9084e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6079e-04 - val_loss: 2.8865e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5913e-04 - val_loss: 2.8651e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5750e-04 - val_loss: 2.8436e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5589e-04 - val_loss: 2.8225e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5430e-04 - val_loss: 2.8016e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5274e-04 - val_loss: 2.7810e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5119e-04 - val_loss: 2.7605e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4967e-04 - val_loss: 2.7403e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4817e-04 - val_loss: 2.7202e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4669e-04 - val_loss: 2.7004e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4523e-04 - val_loss: 2.6807e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4379e-04 - val_loss: 2.6614e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4236e-04 - val_loss: 2.6422e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4096e-04 - val_loss: 2.6232e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3958e-04 - val_loss: 2.6045e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3822e-04 - val_loss: 2.5859e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3687e-04 - val_loss: 2.5676e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3555e-04 - val_loss: 2.5495e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3424e-04 - val_loss: 2.5315e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3294e-04 - val_loss: 2.5138e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3167e-04 - val_loss: 2.4964e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3041e-04 - val_loss: 2.4789e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2917e-04 - val_loss: 2.4618e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2795e-04 - val_loss: 2.4448e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2675e-04 - val_loss: 2.4279e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2555e-04 - val_loss: 2.4112e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2438e-04 - val_loss: 2.3948e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2322e-04 - val_loss: 2.3784e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2208e-04 - val_loss: 2.3621e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2095e-04 - val_loss: 2.3463e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1983e-04 - val_loss: 2.3304e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1873e-04 - val_loss: 2.3147e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1765e-04 - val_loss: 2.2993e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1658e-04 - val_loss: 2.2839e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1552e-04 - val_loss: 2.2688e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1448e-04 - val_loss: 2.2536e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1345e-04 - val_loss: 2.2388e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1243e-04 - val_loss: 2.2240e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1143e-04 - val_loss: 2.2093e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1044e-04 - val_loss: 2.1949e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0947e-04 - val_loss: 2.1806e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0850e-04 - val_loss: 2.1665e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0755e-04 - val_loss: 2.1524e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0661e-04 - val_loss: 2.1385e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0568e-04 - val_loss: 2.1248e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.0476e-04 - val_loss: 2.1111e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0386e-04 - val_loss: 2.0976e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0296e-04 - val_loss: 2.0843e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0208e-04 - val_loss: 2.0711e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0121e-04 - val_loss: 2.0580e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0035e-04 - val_loss: 2.0449e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9502e-05 - val_loss: 2.0321e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8660e-05 - val_loss: 2.0194e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7836e-05 - val_loss: 2.0067e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.7016e-05 - val_loss: 1.9942e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6207e-05 - val_loss: 1.9819e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5410e-05 - val_loss: 1.9696e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 9.4624e-05 - val_loss: 1.9575e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3845e-05 - val_loss: 1.9454e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3076e-05 - val_loss: 1.9335e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2317e-05 - val_loss: 1.9217e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1566e-05 - val_loss: 1.9100e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0830e-05 - val_loss: 1.8983e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0093e-05 - val_loss: 1.8869e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.9372e-05 - val_loss: 1.8755e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8657e-05 - val_loss: 1.8641e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7951e-05 - val_loss: 1.8530e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7254e-05 - val_loss: 1.8418e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6565e-05 - val_loss: 1.8310e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5885e-05 - val_loss: 1.8199e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5210e-05 - val_loss: 1.8091e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4545e-05 - val_loss: 1.7985e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3890e-05 - val_loss: 1.7878e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.3241e-05 - val_loss: 1.7774e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2599e-05 - val_loss: 1.7670e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1964e-05 - val_loss: 1.7566e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1337e-05 - val_loss: 1.7463e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.0718e-05 - val_loss: 1.7361e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0105e-05 - val_loss: 1.7261e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9500e-05 - val_loss: 1.7162e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.8903e-05 - val_loss: 1.7063e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8311e-05 - val_loss: 1.6965e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.7727e-05 - val_loss: 1.6866e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7149e-05 - val_loss: 1.6770e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6579e-05 - val_loss: 1.6675e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6014e-05 - val_loss: 1.6580e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5453e-05 - val_loss: 1.6486e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 7.4902e-05 - val_loss: 1.6393e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4358e-05 - val_loss: 1.6301e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3818e-05 - val_loss: 1.6208e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3283e-05 - val_loss: 1.6117e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2752e-05 - val_loss: 1.6027e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2232e-05 - val_loss: 1.5938e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1717e-05 - val_loss: 1.5848e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1206e-05 - val_loss: 1.5760e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0701e-05 - val_loss: 1.5673e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0202e-05 - val_loss: 1.5586e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9712e-05 - val_loss: 1.5501e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9219e-05 - val_loss: 1.5415e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.8735e-05 - val_loss: 1.5330e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8257e-05 - val_loss: 1.5246e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7786e-05 - val_loss: 1.5163e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7316e-05 - val_loss: 1.5081e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6852e-05 - val_loss: 1.4999e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6396e-05 - val_loss: 1.4918e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5943e-05 - val_loss: 1.4836e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5496e-05 - val_loss: 1.4756e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5050e-05 - val_loss: 1.4677e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4609e-05 - val_loss: 1.4598e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4176e-05 - val_loss: 1.4519e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3745e-05 - val_loss: 1.4442e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3320e-05 - val_loss: 1.4364e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2899e-05 - val_loss: 1.4288e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2484e-05 - val_loss: 1.4211e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2068e-05 - val_loss: 1.4137e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1661e-05 - val_loss: 1.4061e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1257e-05 - val_loss: 1.3987e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0856e-05 - val_loss: 1.3913e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 6.0459e-05 - val_loss: 1.3841e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0070e-05 - val_loss: 1.3768e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9679e-05 - val_loss: 1.3696e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9295e-05 - val_loss: 1.3624e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8913e-05 - val_loss: 1.3553e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8537e-05 - val_loss: 1.3483e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8166e-05 - val_loss: 1.3411e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7794e-05 - val_loss: 1.3342e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7429e-05 - val_loss: 1.3273e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7066e-05 - val_loss: 1.3204e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.6706e-05 - val_loss: 1.3137e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6352e-05 - val_loss: 1.3069e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5998e-05 - val_loss: 1.3002e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5650e-05 - val_loss: 1.2935e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5306e-05 - val_loss: 1.2869e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4963e-05 - val_loss: 1.2803e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4624e-05 - val_loss: 1.2737e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4288e-05 - val_loss: 1.2672e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3955e-05 - val_loss: 1.2608e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3629e-05 - val_loss: 1.2544e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.3301e-05 - val_loss: 1.2481e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.2978e-05 - val_loss: 1.2418e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2658e-05 - val_loss: 1.2355e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2339e-05 - val_loss: 1.2293e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2025e-05 - val_loss: 1.2231e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1714e-05 - val_loss: 1.2170e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1405e-05 - val_loss: 1.2109e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1099e-05 - val_loss: 1.2048e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0794e-05 - val_loss: 1.1987e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0496e-05 - val_loss: 1.1928e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0198e-05 - val_loss: 1.1868e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9901e-05 - val_loss: 1.1809e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9608e-05 - val_loss: 1.1751e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9318e-05 - val_loss: 1.1693e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9031e-05 - val_loss: 1.1634e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8746e-05 - val_loss: 1.1576e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8464e-05 - val_loss: 1.1518e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8181e-05 - val_loss: 1.1462e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.7906e-05 - val_loss: 1.1406e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7630e-05 - val_loss: 1.1349e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7357e-05 - val_loss: 1.1294e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 4.7086e-05 - val_loss: 1.1238e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6818e-05 - val_loss: 1.1183e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6551e-05 - val_loss: 1.1130e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6287e-05 - val_loss: 1.1074e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6024e-05 - val_loss: 1.1020e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5765e-05 - val_loss: 1.0966e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5508e-05 - val_loss: 1.0913e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5250e-05 - val_loss: 1.0860e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5000e-05 - val_loss: 1.0807e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.4747e-05 - val_loss: 1.0755e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4498e-05 - val_loss: 1.0702e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.4251e-05 - val_loss: 1.0651e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4009e-05 - val_loss: 1.0599e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3761e-05 - val_loss: 1.0548e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3522e-05 - val_loss: 1.0497e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3282e-05 - val_loss: 1.0447e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3044e-05 - val_loss: 1.0396e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2809e-05 - val_loss: 1.0347e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2576e-05 - val_loss: 1.0297e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2343e-05 - val_loss: 1.0247e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2113e-05 - val_loss: 1.0198e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1883e-05 - val_loss: 1.0149e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1656e-05 - val_loss: 1.0100e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1432e-05 - val_loss: 1.0052e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1209e-05 - val_loss: 1.0004e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0988e-05 - val_loss: 9.9571e-05\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0767e-05 - val_loss: 9.9091e-05\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0549e-05 - val_loss: 9.8624e-05\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0332e-05 - val_loss: 9.8150e-05\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.0118e-05 - val_loss: 9.7684e-05\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9902e-05 - val_loss: 9.7220e-05\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9693e-05 - val_loss: 9.6758e-05\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9481e-05 - val_loss: 9.6300e-05\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9274e-05 - val_loss: 9.5843e-05\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9065e-05 - val_loss: 9.5390e-05\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8859e-05 - val_loss: 9.4936e-05\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8655e-05 - val_loss: 9.4495e-05\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 3.8452e-05 - val_loss: 9.4045e-05\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8249e-05 - val_loss: 9.3605e-05\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.8050e-05 - val_loss: 9.3164e-05\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 3.7853e-05 - val_loss: 9.2724e-05\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7655e-05 - val_loss: 9.2283e-05\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7459e-05 - val_loss: 9.1854e-05\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7264e-05 - val_loss: 9.1412e-05\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7071e-05 - val_loss: 9.0990e-05\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6879e-05 - val_loss: 9.0564e-05\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6689e-05 - val_loss: 9.0141e-05\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6501e-05 - val_loss: 8.9718e-05\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6313e-05 - val_loss: 8.9290e-05\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.6125e-05 - val_loss: 8.8875e-05\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5939e-05 - val_loss: 8.8458e-05\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5756e-05 - val_loss: 8.8049e-05\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5574e-05 - val_loss: 8.7636e-05\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.5393e-05 - val_loss: 8.7226e-05\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5212e-05 - val_loss: 8.6819e-05\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5033e-05 - val_loss: 8.6414e-05\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4855e-05 - val_loss: 8.6010e-05\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4676e-05 - val_loss: 8.5613e-05\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4502e-05 - val_loss: 8.5213e-05\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.4327e-05 - val_loss: 8.4812e-05\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4155e-05 - val_loss: 8.4421e-05\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3982e-05 - val_loss: 8.4025e-05\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3811e-05 - val_loss: 8.3635e-05\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3641e-05 - val_loss: 8.3257e-05\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3473e-05 - val_loss: 8.2863e-05\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3303e-05 - val_loss: 8.2477e-05\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3138e-05 - val_loss: 8.2093e-05\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2972e-05 - val_loss: 8.1712e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2806e-05 - val_loss: 8.1332e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2643e-05 - val_loss: 8.0958e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.2480e-05 - val_loss: 8.0582e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2319e-05 - val_loss: 8.0213e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2159e-05 - val_loss: 7.9845e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2000e-05 - val_loss: 7.9471e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1840e-05 - val_loss: 7.9096e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1681e-05 - val_loss: 7.8734e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1525e-05 - val_loss: 7.8371e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1369e-05 - val_loss: 7.8006e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1215e-05 - val_loss: 7.7649e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1060e-05 - val_loss: 7.7294e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0907e-05 - val_loss: 7.6936e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0755e-05 - val_loss: 7.6580e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0605e-05 - val_loss: 7.6219e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0453e-05 - val_loss: 7.5873e-05\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0304e-05 - val_loss: 7.5526e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0157e-05 - val_loss: 7.5172e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0008e-05 - val_loss: 7.4828e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9861e-05 - val_loss: 7.4483e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9715e-05 - val_loss: 7.4139e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9571e-05 - val_loss: 7.3799e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9426e-05 - val_loss: 7.3456e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9283e-05 - val_loss: 7.3118e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9141e-05 - val_loss: 7.2781e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8998e-05 - val_loss: 7.2446e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8857e-05 - val_loss: 7.2114e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8718e-05 - val_loss: 7.1780e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8578e-05 - val_loss: 7.1449e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8440e-05 - val_loss: 7.1118e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.8301e-05 - val_loss: 7.0793e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8164e-05 - val_loss: 7.0470e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8028e-05 - val_loss: 7.0147e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7893e-05 - val_loss: 6.9826e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7760e-05 - val_loss: 6.9502e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7625e-05 - val_loss: 6.9182e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7490e-05 - val_loss: 6.8862e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7359e-05 - val_loss: 6.8547e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7227e-05 - val_loss: 6.8233e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7097e-05 - val_loss: 6.7916e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6965e-05 - val_loss: 6.7601e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6836e-05 - val_loss: 6.7298e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6708e-05 - val_loss: 6.6989e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6578e-05 - val_loss: 6.6681e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6451e-05 - val_loss: 6.6377e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6325e-05 - val_loss: 6.6067e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6198e-05 - val_loss: 6.5763e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6073e-05 - val_loss: 6.5456e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.5947e-05 - val_loss: 6.5158e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5824e-05 - val_loss: 6.4859e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5701e-05 - val_loss: 6.4562e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5578e-05 - val_loss: 6.4267e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5456e-05 - val_loss: 6.3971e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5335e-05 - val_loss: 6.3676e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5213e-05 - val_loss: 6.3385e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5094e-05 - val_loss: 6.3092e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4973e-05 - val_loss: 6.2806e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4855e-05 - val_loss: 6.2511e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4736e-05 - val_loss: 6.2229e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4618e-05 - val_loss: 6.1938e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4501e-05 - val_loss: 6.1658e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4386e-05 - val_loss: 6.1369e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4269e-05 - val_loss: 6.1091e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4153e-05 - val_loss: 6.0809e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4038e-05 - val_loss: 6.0530e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3925e-05 - val_loss: 6.0249e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3811e-05 - val_loss: 5.9977e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3699e-05 - val_loss: 5.9699e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3586e-05 - val_loss: 5.9421e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3475e-05 - val_loss: 5.9150e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3364e-05 - val_loss: 5.8878e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3253e-05 - val_loss: 5.8609e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3143e-05 - val_loss: 5.8334e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3033e-05 - val_loss: 5.8066e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2923e-05 - val_loss: 5.7797e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2815e-05 - val_loss: 5.7533e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2708e-05 - val_loss: 5.7268e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2600e-05 - val_loss: 5.7005e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2493e-05 - val_loss: 5.6744e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2386e-05 - val_loss: 5.6483e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2281e-05 - val_loss: 5.6224e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2176e-05 - val_loss: 5.5961e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2070e-05 - val_loss: 5.5709e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1967e-05 - val_loss: 5.5448e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1863e-05 - val_loss: 5.5189e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1760e-05 - val_loss: 5.4933e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1657e-05 - val_loss: 5.4685e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1555e-05 - val_loss: 5.4431e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1453e-05 - val_loss: 5.4180e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1353e-05 - val_loss: 5.3929e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1251e-05 - val_loss: 5.3683e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1151e-05 - val_loss: 5.3427e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1052e-05 - val_loss: 5.3181e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0952e-05 - val_loss: 5.2938e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0854e-05 - val_loss: 5.2695e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0755e-05 - val_loss: 5.2446e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0657e-05 - val_loss: 5.2212e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0561e-05 - val_loss: 5.1970e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0463e-05 - val_loss: 5.1723e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0366e-05 - val_loss: 5.1491e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0271e-05 - val_loss: 5.1244e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0176e-05 - val_loss: 5.1008e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0081e-05 - val_loss: 5.0776e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9987e-05 - val_loss: 5.0538e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9893e-05 - val_loss: 5.0304e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9798e-05 - val_loss: 5.0074e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.9705e-05 - val_loss: 4.9836e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9613e-05 - val_loss: 4.9613e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9521e-05 - val_loss: 4.9377e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9428e-05 - val_loss: 4.9154e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9338e-05 - val_loss: 4.8928e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9247e-05 - val_loss: 4.8696e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9157e-05 - val_loss: 4.8476e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9067e-05 - val_loss: 4.8247e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8976e-05 - val_loss: 4.8019e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8887e-05 - val_loss: 4.7801e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.8798e-05 - val_loss: 4.7577e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8710e-05 - val_loss: 4.7356e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8622e-05 - val_loss: 4.7139e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8534e-05 - val_loss: 4.6915e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8447e-05 - val_loss: 4.6701e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 191us/step - loss: 1.8361e-05 - val_loss: 4.6484e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8274e-05 - val_loss: 4.6264e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8188e-05 - val_loss: 4.6051e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8102e-05 - val_loss: 4.5834e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8017e-05 - val_loss: 4.5624e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7933e-05 - val_loss: 4.5412e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7849e-05 - val_loss: 4.5194e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7765e-05 - val_loss: 4.4987e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7681e-05 - val_loss: 4.4777e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7599e-05 - val_loss: 4.4565e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7515e-05 - val_loss: 4.4357e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7433e-05 - val_loss: 4.4153e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.7350e-05 - val_loss: 4.3950e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7269e-05 - val_loss: 4.3742e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7189e-05 - val_loss: 4.3540e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7108e-05 - val_loss: 4.3337e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7028e-05 - val_loss: 4.3132e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6947e-05 - val_loss: 4.2928e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.6867e-05 - val_loss: 4.2726e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6788e-05 - val_loss: 4.2529e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6709e-05 - val_loss: 4.2333e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6631e-05 - val_loss: 4.2136e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6553e-05 - val_loss: 4.1936e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.6475e-05 - val_loss: 4.1739e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6397e-05 - val_loss: 4.1542e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6319e-05 - val_loss: 4.1345e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6242e-05 - val_loss: 4.1155e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.6166e-05 - val_loss: 4.0959e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6091e-05 - val_loss: 4.0772e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6016e-05 - val_loss: 4.0576e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5939e-05 - val_loss: 4.0387e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5865e-05 - val_loss: 4.0195e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5789e-05 - val_loss: 4.0008e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5715e-05 - val_loss: 3.9816e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5641e-05 - val_loss: 3.9633e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5568e-05 - val_loss: 3.9446e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5495e-05 - val_loss: 3.9263e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5421e-05 - val_loss: 3.9075e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5348e-05 - val_loss: 3.8891e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5276e-05 - val_loss: 3.8710e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5205e-05 - val_loss: 3.8529e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5133e-05 - val_loss: 3.8346e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5061e-05 - val_loss: 3.8168e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4991e-05 - val_loss: 3.7986e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4920e-05 - val_loss: 3.7806e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4850e-05 - val_loss: 3.7627e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4780e-05 - val_loss: 3.7452e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4710e-05 - val_loss: 3.7272e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4641e-05 - val_loss: 3.7096e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4572e-05 - val_loss: 3.6920e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4503e-05 - val_loss: 3.6747e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4435e-05 - val_loss: 3.6571e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4367e-05 - val_loss: 3.6402e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4300e-05 - val_loss: 3.6226e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4231e-05 - val_loss: 3.6055e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4164e-05 - val_loss: 3.5886e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4098e-05 - val_loss: 3.5715e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4031e-05 - val_loss: 3.5545e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3964e-05 - val_loss: 3.5380e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3899e-05 - val_loss: 3.5210e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3834e-05 - val_loss: 3.5045e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3769e-05 - val_loss: 3.4876e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.3703e-05 - val_loss: 3.4713e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3639e-05 - val_loss: 3.4548e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3574e-05 - val_loss: 3.4384e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3510e-05 - val_loss: 3.4215e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3445e-05 - val_loss: 3.4055e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3382e-05 - val_loss: 3.3891e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3319e-05 - val_loss: 3.3734e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3256e-05 - val_loss: 3.3571e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3194e-05 - val_loss: 3.3411e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3130e-05 - val_loss: 3.3250e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3068e-05 - val_loss: 3.3094e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3007e-05 - val_loss: 3.2936e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2945e-05 - val_loss: 3.2782e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.2884e-05 - val_loss: 3.2624e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2824e-05 - val_loss: 3.2470e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2763e-05 - val_loss: 3.2315e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2703e-05 - val_loss: 3.2158e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2642e-05 - val_loss: 3.2005e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2583e-05 - val_loss: 3.1853e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 1.2522e-05 - val_loss: 3.1700e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2464e-05 - val_loss: 3.1550e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.2404e-05 - val_loss: 3.1397e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2345e-05 - val_loss: 3.1249e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2288e-05 - val_loss: 3.1100e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2229e-05 - val_loss: 3.0952e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2170e-05 - val_loss: 3.0804e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2113e-05 - val_loss: 3.0657e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2056e-05 - val_loss: 3.0508e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1999e-05 - val_loss: 3.0361e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1942e-05 - val_loss: 3.0216e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1886e-05 - val_loss: 3.0069e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1829e-05 - val_loss: 2.9927e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1774e-05 - val_loss: 2.9782e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1717e-05 - val_loss: 2.9637e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1661e-05 - val_loss: 2.9498e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1606e-05 - val_loss: 2.9355e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.1551e-05 - val_loss: 2.9214e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.1496e-05 - val_loss: 2.9074e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1441e-05 - val_loss: 2.8937e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1387e-05 - val_loss: 2.8798e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1333e-05 - val_loss: 2.8659e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1279e-05 - val_loss: 2.8519e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1226e-05 - val_loss: 2.8380e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1172e-05 - val_loss: 2.8243e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1120e-05 - val_loss: 2.8106e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1066e-05 - val_loss: 2.7969e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1013e-05 - val_loss: 2.7841e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0962e-05 - val_loss: 2.7706e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0909e-05 - val_loss: 2.7570e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0857e-05 - val_loss: 2.7436e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0805e-05 - val_loss: 2.7306e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0755e-05 - val_loss: 2.7173e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0702e-05 - val_loss: 2.7043e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0652e-05 - val_loss: 2.6908e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0601e-05 - val_loss: 2.6777e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0550e-05 - val_loss: 2.6651e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0500e-05 - val_loss: 2.6521e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0451e-05 - val_loss: 2.6392e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0400e-05 - val_loss: 2.6269e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0351e-05 - val_loss: 2.6139e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0302e-05 - val_loss: 2.6016e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0253e-05 - val_loss: 2.5888e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0204e-05 - val_loss: 2.5760e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0156e-05 - val_loss: 2.5633e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0107e-05 - val_loss: 2.5510e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0059e-05 - val_loss: 2.5388e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0011e-05 - val_loss: 2.5264e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 9.9631e-06 - val_loss: 2.5139e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9153e-06 - val_loss: 2.5019e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8683e-06 - val_loss: 2.4893e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8203e-06 - val_loss: 2.4774e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7735e-06 - val_loss: 2.4655e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7267e-06 - val_loss: 2.4535e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6807e-06 - val_loss: 2.4415e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6341e-06 - val_loss: 2.4298e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5882e-06 - val_loss: 2.4175e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5416e-06 - val_loss: 2.4061e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4971e-06 - val_loss: 2.3942e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4515e-06 - val_loss: 2.3824e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4057e-06 - val_loss: 2.3712e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3617e-06 - val_loss: 2.3594e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3162e-06 - val_loss: 2.3480e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2720e-06 - val_loss: 2.3366e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2271e-06 - val_loss: 2.3248e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1830e-06 - val_loss: 2.3140e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1396e-06 - val_loss: 2.3024e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0961e-06 - val_loss: 2.2909e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0521e-06 - val_loss: 2.2799e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0085e-06 - val_loss: 2.2685e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9649e-06 - val_loss: 2.2576e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 8.9231e-06 - val_loss: 2.2468e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8795e-06 - val_loss: 2.2353e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.8369e-06 - val_loss: 2.2247e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7950e-06 - val_loss: 2.2139e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7533e-06 - val_loss: 2.2028e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7111e-06 - val_loss: 2.1923e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6696e-06 - val_loss: 2.1810e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6268e-06 - val_loss: 2.1703e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5850e-06 - val_loss: 2.1598e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5445e-06 - val_loss: 2.1490e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5029e-06 - val_loss: 2.1386e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4626e-06 - val_loss: 2.1281e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4224e-06 - val_loss: 2.1174e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3810e-06 - val_loss: 2.1072e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3414e-06 - val_loss: 2.0966e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3011e-06 - val_loss: 2.0868e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2615e-06 - val_loss: 2.0764e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2217e-06 - val_loss: 2.0660e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1820e-06 - val_loss: 2.0559e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 8.1426e-06 - val_loss: 2.0459e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1041e-06 - val_loss: 2.0358e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0647e-06 - val_loss: 2.0262e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0266e-06 - val_loss: 2.0157e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9875e-06 - val_loss: 2.0058e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9490e-06 - val_loss: 1.9958e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9109e-06 - val_loss: 1.9856e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8725e-06 - val_loss: 1.9758e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8342e-06 - val_loss: 1.9664e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7971e-06 - val_loss: 1.9567e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7594e-06 - val_loss: 1.9472e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7219e-06 - val_loss: 1.9378e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6856e-06 - val_loss: 1.9281e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6478e-06 - val_loss: 1.9184e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6106e-06 - val_loss: 1.9089e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5744e-06 - val_loss: 1.8993e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5372e-06 - val_loss: 1.8898e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5017e-06 - val_loss: 1.8801e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 7.4646e-06 - val_loss: 1.8709e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4291e-06 - val_loss: 1.8616e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3932e-06 - val_loss: 1.8526e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3579e-06 - val_loss: 1.8437e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3229e-06 - val_loss: 1.8342e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2868e-06 - val_loss: 1.8251e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2512e-06 - val_loss: 1.8159e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2165e-06 - val_loss: 1.8069e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1813e-06 - val_loss: 1.7980e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1474e-06 - val_loss: 1.7889e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1124e-06 - val_loss: 1.7799e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0779e-06 - val_loss: 1.7713e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0436e-06 - val_loss: 1.7626e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0097e-06 - val_loss: 1.7539e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9758e-06 - val_loss: 1.7455e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9428e-06 - val_loss: 1.7364e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9089e-06 - val_loss: 1.7278e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 170us/step - loss: 6.8755e-06 - val_loss: 1.7188e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8417e-06 - val_loss: 1.7105e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.8086e-06 - val_loss: 1.7021e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7766e-06 - val_loss: 1.6932e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7437e-06 - val_loss: 1.6849e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.7096e-06 - val_loss: 1.6766e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6780e-06 - val_loss: 1.6683e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6459e-06 - val_loss: 1.6599e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6130e-06 - val_loss: 1.6514e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5815e-06 - val_loss: 1.6432e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5488e-06 - val_loss: 1.6352e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5175e-06 - val_loss: 1.6268e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4861e-06 - val_loss: 1.6186e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4545e-06 - val_loss: 1.6103e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4229e-06 - val_loss: 1.6023e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3913e-06 - val_loss: 1.5946e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3610e-06 - val_loss: 1.5863e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3300e-06 - val_loss: 1.5783e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2989e-06 - val_loss: 1.5707e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2686e-06 - val_loss: 1.5627e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2379e-06 - val_loss: 1.5547e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2079e-06 - val_loss: 1.5470e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1777e-06 - val_loss: 1.5394e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1477e-06 - val_loss: 1.5317e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1175e-06 - val_loss: 1.5236e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0883e-06 - val_loss: 1.5161e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.0585e-06 - val_loss: 1.5085e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0291e-06 - val_loss: 1.5008e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.9997e-06 - val_loss: 1.4935e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9701e-06 - val_loss: 1.4857e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9413e-06 - val_loss: 1.4786e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9127e-06 - val_loss: 1.4710e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8837e-06 - val_loss: 1.4636e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8556e-06 - val_loss: 1.4562e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8259e-06 - val_loss: 1.4489e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7979e-06 - val_loss: 1.4416e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7703e-06 - val_loss: 1.4340e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7417e-06 - val_loss: 1.4269e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7136e-06 - val_loss: 1.4196e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.6861e-06 - val_loss: 1.4127e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6584e-06 - val_loss: 1.4055e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6311e-06 - val_loss: 1.3983e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6028e-06 - val_loss: 1.3913e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5752e-06 - val_loss: 1.3844e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5486e-06 - val_loss: 1.3773e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5217e-06 - val_loss: 1.3700e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4937e-06 - val_loss: 1.3632e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4679e-06 - val_loss: 1.3563e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4407e-06 - val_loss: 1.3493e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4147e-06 - val_loss: 1.3426e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3888e-06 - val_loss: 1.3359e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3620e-06 - val_loss: 1.3290e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3357e-06 - val_loss: 1.3223e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3093e-06 - val_loss: 1.3155e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2839e-06 - val_loss: 1.3088e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2577e-06 - val_loss: 1.3024e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2319e-06 - val_loss: 1.2956e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2069e-06 - val_loss: 1.2893e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1812e-06 - val_loss: 1.2827e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1557e-06 - val_loss: 1.2759e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1302e-06 - val_loss: 1.2696e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1051e-06 - val_loss: 1.2630e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0803e-06 - val_loss: 1.2567e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0560e-06 - val_loss: 1.2502e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0306e-06 - val_loss: 1.2437e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0060e-06 - val_loss: 1.2375e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9813e-06 - val_loss: 1.2311e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9570e-06 - val_loss: 1.2249e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9330e-06 - val_loss: 1.2186e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9083e-06 - val_loss: 1.2124e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8845e-06 - val_loss: 1.2062e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.8609e-06 - val_loss: 1.2000e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8370e-06 - val_loss: 1.1938e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8131e-06 - val_loss: 1.1879e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7897e-06 - val_loss: 1.1818e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7659e-06 - val_loss: 1.1758e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7427e-06 - val_loss: 1.1699e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7190e-06 - val_loss: 1.1637e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6962e-06 - val_loss: 1.1577e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6729e-06 - val_loss: 1.1518e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6501e-06 - val_loss: 1.1457e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6271e-06 - val_loss: 1.1401e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6051e-06 - val_loss: 1.1343e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5822e-06 - val_loss: 1.1282e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5594e-06 - val_loss: 1.1225e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5367e-06 - val_loss: 1.1168e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5145e-06 - val_loss: 1.1109e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4925e-06 - val_loss: 1.1054e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4701e-06 - val_loss: 1.0997e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4486e-06 - val_loss: 1.0938e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4258e-06 - val_loss: 1.0884e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4046e-06 - val_loss: 1.0829e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3826e-06 - val_loss: 1.0775e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3617e-06 - val_loss: 1.0717e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3402e-06 - val_loss: 1.0662e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3183e-06 - val_loss: 1.0607e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2973e-06 - val_loss: 1.0553e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2763e-06 - val_loss: 1.0498e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2553e-06 - val_loss: 1.0444e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2341e-06 - val_loss: 1.0391e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2132e-06 - val_loss: 1.0334e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1918e-06 - val_loss: 1.0283e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1716e-06 - val_loss: 1.0230e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1510e-06 - val_loss: 1.0178e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1310e-06 - val_loss: 1.0124e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1104e-06 - val_loss: 1.0071e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0903e-06 - val_loss: 1.0021e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0698e-06 - val_loss: 9.9686e-06\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0493e-06 - val_loss: 9.9164e-06\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0298e-06 - val_loss: 9.8655e-06\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0099e-06 - val_loss: 9.8144e-06\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9900e-06 - val_loss: 9.7637e-06\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9701e-06 - val_loss: 9.7128e-06\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9503e-06 - val_loss: 9.6630e-06\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9312e-06 - val_loss: 9.6112e-06\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9117e-06 - val_loss: 9.5626e-06\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8923e-06 - val_loss: 9.5098e-06\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8723e-06 - val_loss: 9.4643e-06\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8544e-06 - val_loss: 9.4145e-06\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8347e-06 - val_loss: 9.3672e-06\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8160e-06 - val_loss: 9.3179e-06\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7970e-06 - val_loss: 9.2689e-06\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7783e-06 - val_loss: 9.2220e-06\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7595e-06 - val_loss: 9.1728e-06\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7407e-06 - val_loss: 9.1259e-06\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7227e-06 - val_loss: 9.0777e-06\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7040e-06 - val_loss: 9.0293e-06\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6853e-06 - val_loss: 8.9834e-06\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6670e-06 - val_loss: 8.9370e-06\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6491e-06 - val_loss: 8.8887e-06\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6306e-06 - val_loss: 8.8440e-06\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6130e-06 - val_loss: 8.7978e-06\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5952e-06 - val_loss: 8.7537e-06\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5776e-06 - val_loss: 8.7044e-06\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5593e-06 - val_loss: 8.6600e-06\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5417e-06 - val_loss: 8.6171e-06\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5244e-06 - val_loss: 8.5721e-06\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5071e-06 - val_loss: 8.5251e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4894e-06 - val_loss: 8.4802e-06\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4719e-06 - val_loss: 8.4381e-06\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4548e-06 - val_loss: 8.3927e-06\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4376e-06 - val_loss: 8.3484e-06\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4207e-06 - val_loss: 8.3052e-06\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4040e-06 - val_loss: 8.2617e-06\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 3.3869e-06 - val_loss: 8.2168e-06\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3695e-06 - val_loss: 8.1745e-06\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3531e-06 - val_loss: 8.1334e-06\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3368e-06 - val_loss: 8.0912e-06\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3195e-06 - val_loss: 8.0491e-06\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3038e-06 - val_loss: 8.0059e-06\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2871e-06 - val_loss: 7.9637e-06\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2706e-06 - val_loss: 7.9224e-06\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2541e-06 - val_loss: 7.8785e-06\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2379e-06 - val_loss: 7.8380e-06\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2217e-06 - val_loss: 7.7968e-06\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2058e-06 - val_loss: 7.7568e-06\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1902e-06 - val_loss: 7.7149e-06\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1742e-06 - val_loss: 7.6744e-06\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1578e-06 - val_loss: 7.6364e-06\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1425e-06 - val_loss: 7.5943e-06\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1269e-06 - val_loss: 7.5544e-06\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1109e-06 - val_loss: 7.5144e-06\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0960e-06 - val_loss: 7.4759e-06\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0801e-06 - val_loss: 7.4364e-06\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0648e-06 - val_loss: 7.3966e-06\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0496e-06 - val_loss: 7.3573e-06\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0343e-06 - val_loss: 7.3196e-06\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0189e-06 - val_loss: 7.2818e-06\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0044e-06 - val_loss: 7.2410e-06\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.9890e-06 - val_loss: 7.2037e-06\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9747e-06 - val_loss: 7.1641e-06\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9593e-06 - val_loss: 7.1262e-06\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9444e-06 - val_loss: 7.0884e-06\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9301e-06 - val_loss: 7.0504e-06\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9156e-06 - val_loss: 7.0131e-06\n",
      "3.569559339666739e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.43277976,  0.5842029 ,  0.00405372, -0.5412941 , -0.31406018],\n",
       "        [-0.55985063,  0.9260914 ,  0.01659894,  0.5019482 , -1.6639794 ],\n",
       "        [ 1.2616568 , -0.6892476 , -0.00565319, -1.0591496 , -0.29088014]],\n",
       "       dtype=float32),\n",
       " array([ 0.52637666,  0.4641526 , -1.3117716 , -0.42193818,  0.24976149],\n",
       "       dtype=float32),\n",
       " array([[-0.75932926,  0.44334045,  0.30992565, -0.01941523, -0.32403326,\n",
       "         -0.13429241,  0.34395573, -0.03084253,  0.50738853, -0.26844323],\n",
       "        [ 0.15393709, -0.41384408, -0.33616948, -0.09497733,  0.05799925,\n",
       "          0.630289  , -0.32495   , -0.17590581,  0.45425513, -0.3623913 ],\n",
       "        [-0.16806865, -0.5526574 ,  0.7500082 ,  0.8811873 ,  0.59315205,\n",
       "         -0.23122375,  0.6575235 ,  0.01753535,  0.15160047, -0.6194696 ],\n",
       "        [ 0.5004605 ,  0.2643687 , -0.17202382,  0.44999266, -0.63657767,\n",
       "          0.26908907, -0.36026922, -0.0829896 , -0.37456656, -0.24528025],\n",
       "        [-0.5667133 ,  0.20257173, -0.4271303 , -0.3303391 , -0.06327017,\n",
       "          0.3603425 , -0.3976913 , -0.24726135, -0.13390674, -0.48663518]],\n",
       "       dtype=float32),\n",
       " array([ 0.5149865 ,  0.643612  , -0.66190445, -0.72203785, -0.69304556,\n",
       "        -0.7512954 , -0.76548797,  0.66051114,  0.7591577 ,  0.7085953 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.21635363],\n",
       "        [ 0.33560592],\n",
       "        [-0.37425867],\n",
       "        [-0.50696224],\n",
       "        [-0.4282888 ],\n",
       "        [-0.69406277],\n",
       "        [-0.9285566 ],\n",
       "        [ 0.3267059 ],\n",
       "        [ 0.7459824 ],\n",
       "        [ 0.48810807]], dtype=float32),\n",
       " array([0.80777884], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_linear(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_linear.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 33.5098 - val_loss: 31.7095\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6700 - val_loss: 29.0128\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9551 - val_loss: 25.4308\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 25.2612 - val_loss: 20.8567\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 20.5385 - val_loss: 15.3263\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 14.8785 - val_loss: 9.1775\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7563 - val_loss: 3.4117\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3876 - val_loss: 0.4212\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0837 - val_loss: 2.8604\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0100 - val_loss: 6.6112\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7701 - val_loss: 6.5918\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9495 - val_loss: 4.1010\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5495 - val_loss: 1.6463\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8716 - val_loss: 0.5318\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2858 - val_loss: 0.5467\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.8540 - val_loss: 1.2038\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1849 - val_loss: 1.9922\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8009 - val_loss: 2.6089\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3655 - val_loss: 2.9020\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6904 - val_loss: 2.8593\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6957 - val_loss: 2.5129\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4140 - val_loss: 1.9545\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9277 - val_loss: 1.3054\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3494 - val_loss: 0.7008\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8061 - val_loss: 0.2671\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4211 - val_loss: 0.0888\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2946 - val_loss: 0.1684\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4115 - val_loss: 0.4107\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6593 - val_loss: 0.6608\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8760 - val_loss: 0.7853\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.9398 - val_loss: 0.7383\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.8290 - val_loss: 0.5654\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.6112 - val_loss: 0.3562\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3850 - val_loss: 0.1903\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2256 - val_loss: 0.1076\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1631 - val_loss: 0.1061\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1764 - val_loss: 0.1587\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2323 - val_loss: 0.2298\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2977 - val_loss: 0.2877\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3451 - val_loss: 0.3130\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3587 - val_loss: 0.2992\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3350 - val_loss: 0.2521\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2812 - val_loss: 0.1855\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2116 - val_loss: 0.1169\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1430 - val_loss: 0.0622\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0903 - val_loss: 0.0319\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0654 - val_loss: 0.0279\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0690 - val_loss: 0.0436\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0919 - val_loss: 0.0676\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1216 - val_loss: 0.0866\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1404 - val_loss: 0.0928\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1399 - val_loss: 0.0854\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1209 - val_loss: 0.0698\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0921 - val_loss: 0.0535\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0642 - val_loss: 0.0419\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0454 - val_loss: 0.0378\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0388 - val_loss: 0.0403\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0424 - val_loss: 0.0463\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0512 - val_loss: 0.0523\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0595 - val_loss: 0.0555\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0641 - val_loss: 0.0547\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0636 - val_loss: 0.0503\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0583 - val_loss: 0.0434\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0500 - val_loss: 0.0362\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0408 - val_loss: 0.0302\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0329 - val_loss: 0.0265\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0277 - val_loss: 0.0250\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0260 - val_loss: 0.0253\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0273 - val_loss: 0.0260\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0300 - val_loss: 0.0261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0322 - val_loss: 0.0248\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0328 - val_loss: 0.0223\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0313 - val_loss: 0.0190\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0282 - val_loss: 0.0160\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0246 - val_loss: 0.0139\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0215 - val_loss: 0.0130\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0195 - val_loss: 0.0134\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0189 - val_loss: 0.0144\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0192 - val_loss: 0.0156\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0199 - val_loss: 0.0163\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0204 - val_loss: 0.0164\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0204 - val_loss: 0.0156\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0196 - val_loss: 0.0144\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0184 - val_loss: 0.0129\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0170 - val_loss: 0.0116\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0157 - val_loss: 0.0107\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0143 - val_loss: 0.0100\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0142 - val_loss: 0.0098\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.0093\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0137 - val_loss: 0.0088\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0132 - val_loss: 0.0082\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0126 - val_loss: 0.0077\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0120 - val_loss: 0.0073\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0071\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0112 - val_loss: 0.0070\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0111 - val_loss: 0.0070\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0110 - val_loss: 0.0069\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0110 - val_loss: 0.0068\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0109 - val_loss: 0.0066\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0063\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0105 - val_loss: 0.0060\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0102 - val_loss: 0.0057\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0100 - val_loss: 0.0054\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0098 - val_loss: 0.0051\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0096 - val_loss: 0.0049\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.0048\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0094 - val_loss: 0.0047\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0047\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0085 - val_loss: 0.0039\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.0038\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0037\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0082 - val_loss: 0.0036\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0081 - val_loss: 0.0034\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0033\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0078 - val_loss: 0.0030\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0077 - val_loss: 0.0029\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0027\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0026\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0075 - val_loss: 0.0026\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0025\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0074 - val_loss: 0.0024\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 0.0023\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0023\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0022\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0022\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0021\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0070 - val_loss: 0.0021\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0021\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0020\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0020\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0020\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0020\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0019\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0019\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0019\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0064 - val_loss: 0.0019\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0019\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0016\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0016\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0058 - val_loss: 0.0016\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0014\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0049 - val_loss: 0.0014\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0042 - val_loss: 0.0014\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0033 - val_loss: 9.9615e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 9.9150e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0032 - val_loss: 9.8718e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 9.8303e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 9.7906e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 9.7516e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 9.7123e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 9.6687e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 9.6184e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 9.5663e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 9.5151e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 9.4653e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 9.4170e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 9.3701e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 9.3253e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 9.2777e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 9.2288e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0031 - val_loss: 9.1827e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 9.1369e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 9.0947e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 9.0554e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 9.0168e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 8.9813e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 8.9483e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 8.9134e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 8.8767e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 8.8420e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 8.8094e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 8.7759e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 8.7433e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 8.7111e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 8.6771e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 8.6392e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 8.6011e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 8.5635e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 8.5255e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0029 - val_loss: 8.4837e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 8.4427e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 8.4000e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 8.3581e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 8.3133e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 8.2704e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 8.2268e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 8.1853e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0028 - val_loss: 8.1459e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 8.1047e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0028 - val_loss: 8.0658e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 8.0291e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 7.9920e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 7.9546e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 7.9156e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 7.8754e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 7.8377e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 7.8027e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 7.7703e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0027 - val_loss: 7.7393e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 7.7100e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 7.6819e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 7.6541e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 7.6243e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 7.5892e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 7.5547e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 7.5169e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 7.4806e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 7.4455e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 7.4113e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 7.3781e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 7.3452e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 7.3104e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 7.2710e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0025 - val_loss: 7.2324e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 7.1949e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.1553e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 7.1173e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.0808e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 7.0458e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 7.0124e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 6.9798e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 6.9435e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 6.9069e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 6.8725e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 6.8406e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 6.8074e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 6.7769e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 6.7488e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 6.7223e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 6.6975e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 6.6685e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 6.6389e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 6.6107e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 6.5838e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 6.5578e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 6.5293e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.5016e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 6.4741e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.4473e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 6.4159e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 6.3833e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.3524e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.3225e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0023 - val_loss: 6.2944e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.2673e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.2384e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 6.2106e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 6.1841e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 6.1571e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 6.1281e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 6.0991e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 6.0714e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 6.0455e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 6.0207e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 5.9940e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 5.9688e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.9444e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 5.9192e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 5.8932e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.8655e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.8392e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 5.8143e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0021 - val_loss: 5.7907e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.7681e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.7434e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 5.7196e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.6949e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.6697e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 5.6453e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.6189e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.5939e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 5.5699e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.5471e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 5.5251e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 5.4994e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 5.4747e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 5.4511e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.4269e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 5.4009e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.3764e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0020 - val_loss: 5.3533e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 5.3314e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 5.3093e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.2883e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.2655e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.2441e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.2223e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 5.2015e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.1791e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 5.1579e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 5.1364e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 5.1159e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 5.0964e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 5.0775e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 5.0565e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 5.0343e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 5.0115e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 4.9897e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.9685e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 4.9456e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.9234e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.9022e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 4.8818e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 4.8617e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 4.8381e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 4.8142e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 4.7915e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.7697e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.7493e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.7272e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.7067e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.6873e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.6676e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.6478e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.6267e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.6072e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.5892e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 4.5721e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 4.5561e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.5382e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.5198e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 4.5010e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.4830e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.4656e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.4465e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.4281e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.4106e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.3936e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.3758e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0017 - val_loss: 4.3573e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.3369e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.3155e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.2953e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 4.2768e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 4.2595e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.2435e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.2275e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 4.2114e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 4.1967e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 4.1829e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 4.1701e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 4.1554e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 4.1388e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 4.1229e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 4.1064e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 4.0889e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 4.0724e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 4.0563e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 4.0407e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 4.0255e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 4.0103e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.9938e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 3.9739e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 3.9520e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.9312e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 3.9115e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 3.8928e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0016 - val_loss: 3.8753e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0015 - val_loss: 3.8584e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 3.8414e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.8241e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.8079e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 3.7906e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7724e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7557e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7405e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7257e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.7109e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.6973e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 3.6850e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.6736e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 3.6627e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 3.6498e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0015 - val_loss: 3.6372e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 3.6234e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.6086e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.5918e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 3.5753e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.5592e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.5436e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.5271e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.5113e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 3.4938e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.4764e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 3.4595e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.4437e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 3.4288e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 3.4119e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 3.3962e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 3.3817e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.3682e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 3.3548e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.3414e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.3270e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.3121e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 3.2986e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.2865e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 3.2755e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 3.2653e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 3.2551e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.2446e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.2349e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 3.2257e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.2168e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 3.2079e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 3.1969e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.1830e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 3.1683e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 374us/step - loss: 0.0013 - val_loss: 3.1540e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0013 - val_loss: 3.1403e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.1269e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.1138e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 3.1001e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 3.0856e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 3.0719e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 3.0580e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 3.0430e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 3.0268e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0013 - val_loss: 3.0112e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 2.9966e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.9821e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.9676e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.9544e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 196us/step - loss: 0.0012 - val_loss: 2.9426e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.9318e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.9223e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.9128e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.9013e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.8891e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.8780e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.8680e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.8585e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.8493e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.8397e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.8289e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.8183e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.8078e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.7973e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0012 - val_loss: 2.7848e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.7709e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.7566e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.7419e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.7275e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.7143e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 2.7024e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.6917e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.6823e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.6738e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.6656e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.6563e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.6455e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.6341e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.6220e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.6094e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.5978e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.5871e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.5774e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.5686e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 2.5605e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.5523e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.5422e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.5312e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.5210e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.5113e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.5020e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.4930e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.4831e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.4727e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.4618e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.4516e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.4420e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.4331e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 2.4231e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.4120e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 2.4016e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 2.3918e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 2.3814e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.3702e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.3588e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 2.3479e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0010 - val_loss: 2.3380e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0010 - val_loss: 2.3286e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.3200e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 2.3103e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.3000e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0010 - val_loss: 2.2895e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.2789e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.2685e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.2591e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.2508e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.2433e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.2366e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 2.2304e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9765e-04 - val_loss: 2.2246e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9433e-04 - val_loss: 2.2181e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9221e-04 - val_loss: 2.2093e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8865e-04 - val_loss: 2.1988e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8512e-04 - val_loss: 2.1886e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8235e-04 - val_loss: 2.1790e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 9.7947e-04 - val_loss: 2.1696e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7648e-04 - val_loss: 2.1604e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7336e-04 - val_loss: 2.1516e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 9.7015e-04 - val_loss: 2.1428e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6701e-04 - val_loss: 2.1335e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6388e-04 - val_loss: 2.1237e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6054e-04 - val_loss: 2.1137e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5762e-04 - val_loss: 2.1030e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5465e-04 - val_loss: 2.0932e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5171e-04 - val_loss: 2.1259e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.4932e-04 - val_loss: 2.1817e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4792e-04 - val_loss: 2.2278e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4623e-04 - val_loss: 2.2640e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4478e-04 - val_loss: 2.2901e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4326e-04 - val_loss: 2.3072e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4168e-04 - val_loss: 2.3158e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4005e-04 - val_loss: 2.3174e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3836e-04 - val_loss: 2.3138e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3668e-04 - val_loss: 2.3068e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3536e-04 - val_loss: 2.2962e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3350e-04 - val_loss: 2.2848e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 9.3197e-04 - val_loss: 2.2731e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3041e-04 - val_loss: 2.2619e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2883e-04 - val_loss: 2.2513e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2726e-04 - val_loss: 2.2410e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2567e-04 - val_loss: 2.2313e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2410e-04 - val_loss: 2.2212e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2272e-04 - val_loss: 2.2114e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2135e-04 - val_loss: 2.2017e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.1997e-04 - val_loss: 2.1911e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1856e-04 - val_loss: 2.1794e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1714e-04 - val_loss: 2.1674e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1574e-04 - val_loss: 2.1561e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1432e-04 - val_loss: 2.1456e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1287e-04 - val_loss: 2.1360e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1142e-04 - val_loss: 2.1277e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1063e-04 - val_loss: 2.1201e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0870e-04 - val_loss: 2.1131e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0744e-04 - val_loss: 2.1065e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0616e-04 - val_loss: 2.1000e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0487e-04 - val_loss: 2.0940e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0343e-04 - val_loss: 2.0884e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0191e-04 - val_loss: 2.0837e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0034e-04 - val_loss: 2.0793e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9928e-04 - val_loss: 2.0746e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9725e-04 - val_loss: 2.0704e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9574e-04 - val_loss: 2.0667e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9420e-04 - val_loss: 2.0636e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9261e-04 - val_loss: 2.0610e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9098e-04 - val_loss: 2.0590e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8932e-04 - val_loss: 2.0577e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8762e-04 - val_loss: 2.0575e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8611e-04 - val_loss: 2.0570e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8442e-04 - val_loss: 2.0574e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8290e-04 - val_loss: 2.0589e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8134e-04 - val_loss: 2.0611e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7976e-04 - val_loss: 2.0639e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7816e-04 - val_loss: 2.0675e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7656e-04 - val_loss: 2.0716e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7496e-04 - val_loss: 2.0764e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7374e-04 - val_loss: 2.0802e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7196e-04 - val_loss: 2.0843e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7053e-04 - val_loss: 2.0890e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6910e-04 - val_loss: 2.0949e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6767e-04 - val_loss: 2.1017e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6623e-04 - val_loss: 2.1090e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6477e-04 - val_loss: 2.1165e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6331e-04 - val_loss: 2.1241e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6186e-04 - val_loss: 2.1318e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6041e-04 - val_loss: 2.1400e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5897e-04 - val_loss: 2.1467e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5828e-04 - val_loss: 2.1508e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5627e-04 - val_loss: 2.1538e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5498e-04 - val_loss: 2.1561e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5368e-04 - val_loss: 2.1574e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5238e-04 - val_loss: 2.1584e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5106e-04 - val_loss: 2.1600e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4974e-04 - val_loss: 2.1630e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4842e-04 - val_loss: 2.1675e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4709e-04 - val_loss: 2.1736e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4575e-04 - val_loss: 2.1810e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.4443e-04 - val_loss: 2.1894e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4359e-04 - val_loss: 2.1972e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4191e-04 - val_loss: 2.2056e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4070e-04 - val_loss: 2.2140e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3951e-04 - val_loss: 2.2221e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3829e-04 - val_loss: 2.2302e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3706e-04 - val_loss: 2.2365e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3581e-04 - val_loss: 2.2414e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3455e-04 - val_loss: 2.2454e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3329e-04 - val_loss: 2.2502e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3202e-04 - val_loss: 2.2560e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3078e-04 - val_loss: 2.2629e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2952e-04 - val_loss: 2.2710e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2851e-04 - val_loss: 2.2787e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2714e-04 - val_loss: 2.2873e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2600e-04 - val_loss: 2.2963e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2486e-04 - val_loss: 2.3053e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2371e-04 - val_loss: 2.3127e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2254e-04 - val_loss: 2.3182e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2136e-04 - val_loss: 2.3237e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2016e-04 - val_loss: 2.3294e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1896e-04 - val_loss: 2.3351e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1776e-04 - val_loss: 2.3411e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1656e-04 - val_loss: 2.3477e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1536e-04 - val_loss: 2.3550e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1417e-04 - val_loss: 2.3630e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1298e-04 - val_loss: 2.3720e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1231e-04 - val_loss: 2.3804e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1070e-04 - val_loss: 2.3880e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0961e-04 - val_loss: 2.3943e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0851e-04 - val_loss: 2.4011e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0742e-04 - val_loss: 2.4075e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0632e-04 - val_loss: 2.4139e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0519e-04 - val_loss: 2.4200e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0406e-04 - val_loss: 2.4261e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0290e-04 - val_loss: 2.4322e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0174e-04 - val_loss: 2.4384e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0058e-04 - val_loss: 2.4452e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9943e-04 - val_loss: 2.4522e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9829e-04 - val_loss: 2.4601e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9739e-04 - val_loss: 2.4671e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9610e-04 - val_loss: 2.4746e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9506e-04 - val_loss: 2.4824e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9402e-04 - val_loss: 2.4900e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9296e-04 - val_loss: 2.4962e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9190e-04 - val_loss: 2.5022e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9081e-04 - val_loss: 2.5082e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.8971e-04 - val_loss: 2.5141e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 7.8861e-04 - val_loss: 2.5201e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8749e-04 - val_loss: 2.5264e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8639e-04 - val_loss: 2.5331e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8529e-04 - val_loss: 2.5401e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8419e-04 - val_loss: 2.5474e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8310e-04 - val_loss: 2.5554e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8205e-04 - val_loss: 2.5623e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8098e-04 - val_loss: 2.5694e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7998e-04 - val_loss: 2.5749e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7898e-04 - val_loss: 2.5801e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7799e-04 - val_loss: 2.5845e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7695e-04 - val_loss: 2.5884e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7591e-04 - val_loss: 2.5922e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7485e-04 - val_loss: 2.5956e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7379e-04 - val_loss: 2.5990e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7271e-04 - val_loss: 2.6029e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7164e-04 - val_loss: 2.6072e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7058e-04 - val_loss: 2.6124e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6953e-04 - val_loss: 2.6182e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6848e-04 - val_loss: 2.6250e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6743e-04 - val_loss: 2.6325e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6658e-04 - val_loss: 2.6393e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6537e-04 - val_loss: 2.6462e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6440e-04 - val_loss: 2.6528e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6345e-04 - val_loss: 2.6585e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6248e-04 - val_loss: 2.6635e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.6151e-04 - val_loss: 2.6671e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6051e-04 - val_loss: 2.6699e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5948e-04 - val_loss: 2.6720e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5845e-04 - val_loss: 2.6740e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5741e-04 - val_loss: 2.6759e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.5637e-04 - val_loss: 2.6783e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5534e-04 - val_loss: 2.6815e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5433e-04 - val_loss: 2.6856e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5332e-04 - val_loss: 2.6906e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5229e-04 - val_loss: 2.6968e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5148e-04 - val_loss: 2.7025e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5033e-04 - val_loss: 2.7087e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4939e-04 - val_loss: 2.7145e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4845e-04 - val_loss: 2.7198e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4753e-04 - val_loss: 2.7242e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4659e-04 - val_loss: 2.7276e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4563e-04 - val_loss: 2.7299e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4464e-04 - val_loss: 2.7315e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4364e-04 - val_loss: 2.7327e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4264e-04 - val_loss: 2.7338e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.4164e-04 - val_loss: 2.7351e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.4064e-04 - val_loss: 2.7371e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3967e-04 - val_loss: 2.7399e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3868e-04 - val_loss: 2.7438e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3772e-04 - val_loss: 2.7486e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3673e-04 - val_loss: 2.7544e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 7.3585e-04 - val_loss: 2.7595e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3481e-04 - val_loss: 2.7649e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3392e-04 - val_loss: 2.7699e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3303e-04 - val_loss: 2.7738e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.3214e-04 - val_loss: 2.7767e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3124e-04 - val_loss: 2.7784e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3031e-04 - val_loss: 2.7788e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2934e-04 - val_loss: 2.7786e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2838e-04 - val_loss: 2.7780e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2740e-04 - val_loss: 2.7774e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2643e-04 - val_loss: 2.7774e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2547e-04 - val_loss: 2.7786e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2452e-04 - val_loss: 2.7805e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2358e-04 - val_loss: 2.7839e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2265e-04 - val_loss: 2.7885e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2171e-04 - val_loss: 2.7942e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.2075e-04 - val_loss: 2.8006e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1991e-04 - val_loss: 2.8064e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1889e-04 - val_loss: 2.8119e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1803e-04 - val_loss: 2.8166e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1719e-04 - val_loss: 2.8200e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1634e-04 - val_loss: 2.8214e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1547e-04 - val_loss: 2.8213e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1457e-04 - val_loss: 2.8200e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1364e-04 - val_loss: 2.8176e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 7.1268e-04 - val_loss: 2.8149e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.1173e-04 - val_loss: 2.8126e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.1079e-04 - val_loss: 2.8110e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0987e-04 - val_loss: 2.8107e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0895e-04 - val_loss: 2.8119e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0806e-04 - val_loss: 2.8147e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0716e-04 - val_loss: 2.8192e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.0625e-04 - val_loss: 2.8250e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0532e-04 - val_loss: 2.8316e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0439e-04 - val_loss: 2.8390e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.0355e-04 - val_loss: 2.8452e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0259e-04 - val_loss: 2.8506e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0179e-04 - val_loss: 2.8546e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0099e-04 - val_loss: 2.8565e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0018e-04 - val_loss: 2.8564e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9933e-04 - val_loss: 2.8543e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.9845e-04 - val_loss: 2.8505e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9754e-04 - val_loss: 2.8459e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9660e-04 - val_loss: 2.8412e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.9567e-04 - val_loss: 2.8372e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9477e-04 - val_loss: 2.8344e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9389e-04 - val_loss: 2.8334e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9302e-04 - val_loss: 2.8342e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9216e-04 - val_loss: 2.8371e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9128e-04 - val_loss: 2.8418e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9040e-04 - val_loss: 2.8482e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8950e-04 - val_loss: 2.8556e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8860e-04 - val_loss: 2.8634e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8771e-04 - val_loss: 2.8712e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8681e-04 - val_loss: 2.8783e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8615e-04 - val_loss: 2.8831e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8513e-04 - val_loss: 2.8860e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8438e-04 - val_loss: 2.8864e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8363e-04 - val_loss: 2.8842e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8284e-04 - val_loss: 2.8798e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8199e-04 - val_loss: 2.8735e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8110e-04 - val_loss: 2.8664e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8020e-04 - val_loss: 2.8592e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7930e-04 - val_loss: 2.8529e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7842e-04 - val_loss: 2.8483e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7757e-04 - val_loss: 2.8459e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7674e-04 - val_loss: 2.8459e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7589e-04 - val_loss: 2.8484e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7507e-04 - val_loss: 2.8533e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7422e-04 - val_loss: 2.8601e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7335e-04 - val_loss: 2.8683e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7248e-04 - val_loss: 2.8772e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7161e-04 - val_loss: 2.8859e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7075e-04 - val_loss: 2.8939e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6989e-04 - val_loss: 2.9005e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6908e-04 - val_loss: 2.9042e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6830e-04 - val_loss: 2.9055e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6758e-04 - val_loss: 2.9037e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6685e-04 - val_loss: 2.8994e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6608e-04 - val_loss: 2.8927e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6525e-04 - val_loss: 2.8843e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.6438e-04 - val_loss: 2.8754e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6350e-04 - val_loss: 2.8671e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6264e-04 - val_loss: 2.8600e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6180e-04 - val_loss: 2.8551e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6098e-04 - val_loss: 2.8527e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6018e-04 - val_loss: 2.8532e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5938e-04 - val_loss: 2.8563e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5856e-04 - val_loss: 2.8618e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5774e-04 - val_loss: 2.8692e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5690e-04 - val_loss: 2.8778e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5605e-04 - val_loss: 2.8869e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5522e-04 - val_loss: 2.8957e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5438e-04 - val_loss: 2.9033e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5356e-04 - val_loss: 2.9093e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5276e-04 - val_loss: 2.9133e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5194e-04 - val_loss: 2.9150e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5113e-04 - val_loss: 2.9144e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5048e-04 - val_loss: 2.9108e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4959e-04 - val_loss: 2.9052e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 6.4888e-04 - val_loss: 2.8979e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4813e-04 - val_loss: 2.8897e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4736e-04 - val_loss: 2.8810e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4655e-04 - val_loss: 2.8726e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4573e-04 - val_loss: 2.8650e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4492e-04 - val_loss: 2.8594e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4412e-04 - val_loss: 2.8558e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4332e-04 - val_loss: 2.8549e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4253e-04 - val_loss: 2.8565e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4175e-04 - val_loss: 2.8604e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4097e-04 - val_loss: 2.8661e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4017e-04 - val_loss: 2.8734e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3938e-04 - val_loss: 2.8816e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3856e-04 - val_loss: 2.8899e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3777e-04 - val_loss: 2.8975e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3697e-04 - val_loss: 2.9039e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3619e-04 - val_loss: 2.9088e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3540e-04 - val_loss: 2.9114e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3462e-04 - val_loss: 2.9120e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3383e-04 - val_loss: 2.9105e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.3305e-04 - val_loss: 2.9074e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3239e-04 - val_loss: 2.9020e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3155e-04 - val_loss: 2.8954e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 6.3085e-04 - val_loss: 2.8880e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3014e-04 - val_loss: 2.8799e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2939e-04 - val_loss: 2.8718e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2863e-04 - val_loss: 2.8644e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2786e-04 - val_loss: 2.8580e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2708e-04 - val_loss: 2.8535e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2629e-04 - val_loss: 2.8510e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2553e-04 - val_loss: 2.8507e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2477e-04 - val_loss: 2.8525e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2401e-04 - val_loss: 2.8564e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2325e-04 - val_loss: 2.8621e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2248e-04 - val_loss: 2.8688e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2172e-04 - val_loss: 2.8760e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2095e-04 - val_loss: 2.8834e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2018e-04 - val_loss: 2.8899e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1942e-04 - val_loss: 2.8954e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1866e-04 - val_loss: 2.8990e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1790e-04 - val_loss: 2.9007e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1714e-04 - val_loss: 2.9007e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1639e-04 - val_loss: 2.8987e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1562e-04 - val_loss: 2.8952e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1487e-04 - val_loss: 2.8905e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1410e-04 - val_loss: 2.8853e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1339e-04 - val_loss: 2.8788e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1265e-04 - val_loss: 2.8723e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1197e-04 - val_loss: 2.8659e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1129e-04 - val_loss: 2.8595e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1059e-04 - val_loss: 2.8536e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0987e-04 - val_loss: 2.8485e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0912e-04 - val_loss: 2.8446e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0837e-04 - val_loss: 2.8419e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0761e-04 - val_loss: 2.8409e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0687e-04 - val_loss: 2.8417e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0613e-04 - val_loss: 2.8438e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.0539e-04 - val_loss: 2.8476e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0467e-04 - val_loss: 2.8522e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0393e-04 - val_loss: 2.8577e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0320e-04 - val_loss: 2.8634e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0247e-04 - val_loss: 2.8688e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0173e-04 - val_loss: 2.8734e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0101e-04 - val_loss: 2.8769e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0027e-04 - val_loss: 2.8790e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9953e-04 - val_loss: 2.8794e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9880e-04 - val_loss: 2.8782e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9807e-04 - val_loss: 2.8757e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9734e-04 - val_loss: 2.8717e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9660e-04 - val_loss: 2.8671e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9587e-04 - val_loss: 2.8619e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9515e-04 - val_loss: 2.8568e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9441e-04 - val_loss: 2.8520e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9369e-04 - val_loss: 2.8471e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9303e-04 - val_loss: 2.8426e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9238e-04 - val_loss: 2.8384e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9172e-04 - val_loss: 2.8346e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9105e-04 - val_loss: 2.8311e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9035e-04 - val_loss: 2.8279e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8963e-04 - val_loss: 2.8255e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8890e-04 - val_loss: 2.8238e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8818e-04 - val_loss: 2.8231e-04\n",
      "0.0002592635864857584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.1458988 , -0.5899072 , -0.2745419 ,  1.0234659 , -0.33376804],\n",
       "        [ 0.26189268, -0.11217483, -0.01563064, -0.26661938,  0.34715974],\n",
       "        [ 0.5946551 ,  0.8034794 , -1.026427  ,  0.40073776, -0.17398515]],\n",
       "       dtype=float32),\n",
       " array([ 0.8353526 ,  0.8665859 ,  0.60436904,  0.7796149 , -0.6698942 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.05092111,  1.0691646 , -0.51231647, -0.16163026,  0.04896908,\n",
       "          0.07909614, -0.38759553, -0.13486281, -0.49247372,  0.10743948],\n",
       "        [ 0.06066146,  0.6558995 , -0.163974  , -0.61565864,  0.69866294,\n",
       "         -0.33831778, -0.31277996, -0.40008193,  0.09695971, -0.2860785 ],\n",
       "        [ 0.31886762,  0.87989986, -0.12935871, -0.5806706 ,  0.6557538 ,\n",
       "         -0.34455892, -0.3134157 , -0.26400518, -0.4048357 ,  0.42535308],\n",
       "        [ 1.0172966 , -0.17985043, -0.21797007,  0.23885295,  0.21102197,\n",
       "         -0.54621863, -0.5317763 , -0.51337403, -0.19861239,  0.43791297],\n",
       "        [ 0.22499785, -0.10830597, -0.38696364, -0.12863925, -0.08368927,\n",
       "          0.30949455, -0.6151181 ,  0.36991876, -0.33700606, -0.09346897]],\n",
       "       dtype=float32),\n",
       " array([ 0.7254207 ,  0.7935021 , -0.31765798,  0.01932238,  0.71491086,\n",
       "         0.        ,  0.        , -0.3176593 ,  0.        ,  0.32241365],\n",
       "       dtype=float32),\n",
       " array([[ 0.6129121 ],\n",
       "        [ 0.9188997 ],\n",
       "        [ 0.20328997],\n",
       "        [ 0.03735686],\n",
       "        [ 0.5296628 ],\n",
       "        [-0.18147582],\n",
       "        [-0.6792117 ],\n",
       "        [ 0.07344438],\n",
       "        [ 0.16528141],\n",
       "        [ 0.25126317]], dtype=float32),\n",
       " array([0.8753427], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_relu(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 32.9246 - val_loss: 29.0180\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.0029 - val_loss: 25.4862\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 26.3554 - val_loss: 21.6762\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 22.4643 - val_loss: 17.8347\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 18.5597 - val_loss: 14.1376\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 14.8159 - val_loss: 10.7166\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 11.3520 - val_loss: 7.6827\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2542 - val_loss: 5.1237\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6014 - val_loss: 3.1004\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4516 - val_loss: 1.6244\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8430 - val_loss: 0.6698\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7766 - val_loss: 0.1662\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2012 - val_loss: 0.0183\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0237 - val_loss: 0.1220\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1300 - val_loss: 0.3798\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4059 - val_loss: 0.7071\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7541 - val_loss: 1.0364\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0992 - val_loss: 1.3197\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3897 - val_loss: 1.5279\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5968 - val_loss: 1.6484\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7100 - val_loss: 1.6814\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7321 - val_loss: 1.6358\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6749 - val_loss: 1.5261\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 1.5543 - val_loss: 1.3691\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3880 - val_loss: 1.1821\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1936 - val_loss: 0.9814\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.9873 - val_loss: 0.7812\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7831 - val_loss: 0.5931\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5923 - val_loss: 0.4257\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4233 - val_loss: 0.2847\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2816 - val_loss: 0.1731\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1700 - val_loss: 0.0912\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0885 - val_loss: 0.0374\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0356 - val_loss: 0.0085\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 1.6237e-04\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0344e-04 - val_loss: 0.0075\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0254\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0281 - val_loss: 0.0493\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0531 - val_loss: 0.0750\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0796 - val_loss: 0.0991\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1044 - val_loss: 0.1190\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1249 - val_loss: 0.1332\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1394 - val_loss: 0.1409\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1473 - val_loss: 0.1420\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1485 - val_loss: 0.1372\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1436 - val_loss: 0.1274\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1336 - val_loss: 0.1139\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1196 - val_loss: 0.0979\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1032 - val_loss: 0.0808\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0856 - val_loss: 0.0638\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0681 - val_loss: 0.0479\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0516 - val_loss: 0.0338\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0369 - val_loss: 0.0221\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0246 - val_loss: 0.0129\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0150 - val_loss: 0.0064\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0079 - val_loss: 0.0023\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 4.3326e-04\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 2.9933e-04\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.0606e-04 - val_loss: 0.0015\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0086\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0077 - val_loss: 0.0110\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0099 - val_loss: 0.0129\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0117 - val_loss: 0.0142\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0130 - val_loss: 0.0149\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0137 - val_loss: 0.0144\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0132 - val_loss: 0.0135\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0123 - val_loss: 0.0121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 5.8622e-04\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2553e-04 - val_loss: 2.8688e-04\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3842e-04 - val_loss: 1.5738e-04\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1065e-04 - val_loss: 1.5796e-04\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0134e-04 - val_loss: 2.4821e-04\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 6.6935e-04 - val_loss: 3.9027e-04\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7643e-04 - val_loss: 5.5116e-04\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.0433e-04\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 8.3038e-04\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.1703e-04\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 9.5874e-04\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 9.5565e-04\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.1240e-04\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 8.3677e-04\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 7.3838e-04\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 6.2752e-04\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 5.1405e-04\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 4.0658e-04\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6140e-04 - val_loss: 3.1204e-04\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2668e-04 - val_loss: 2.3529e-04\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0909e-04 - val_loss: 1.7910e-04\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1228e-04 - val_loss: 1.4418e-04\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3778e-04 - val_loss: 1.2954e-04\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8527e-04 - val_loss: 1.3279e-04\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5297e-04 - val_loss: 1.5058e-04\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3796e-04 - val_loss: 1.7897e-04\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 3.3668e-04 - val_loss: 2.1384e-04\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4527e-04 - val_loss: 2.5128e-04\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5996e-04 - val_loss: 2.8774e-04\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7728e-04 - val_loss: 3.2035e-04\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9433e-04 - val_loss: 3.4695e-04\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0885e-04 - val_loss: 3.6611e-04\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1930e-04 - val_loss: 3.7719e-04\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2478e-04 - val_loss: 3.8020e-04\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 4.2507e-04 - val_loss: 3.7566e-04\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2041e-04 - val_loss: 3.6455e-04\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1149e-04 - val_loss: 3.4812e-04\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9919e-04 - val_loss: 3.2773e-04\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8458e-04 - val_loss: 3.0480e-04\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6874e-04 - val_loss: 2.8065e-04\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5267e-04 - val_loss: 2.5646e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3722e-04 - val_loss: 2.3320e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.2309e-04 - val_loss: 2.1161e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1075e-04 - val_loss: 1.9218e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0045e-04 - val_loss: 1.7523e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9228e-04 - val_loss: 1.6081e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8613e-04 - val_loss: 1.4888e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8180e-04 - val_loss: 1.3925e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7898e-04 - val_loss: 1.3167e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 2.7730e-04 - val_loss: 1.2582e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.7641e-04 - val_loss: 1.2140e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7595e-04 - val_loss: 1.1810e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7564e-04 - val_loss: 1.1567e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7520e-04 - val_loss: 1.1389e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7446e-04 - val_loss: 1.1260e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7330e-04 - val_loss: 1.1167e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7167e-04 - val_loss: 1.1103e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6957e-04 - val_loss: 1.1066e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6704e-04 - val_loss: 1.1051e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6416e-04 - val_loss: 1.1061e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6102e-04 - val_loss: 1.1096e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5774e-04 - val_loss: 1.1156e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5440e-04 - val_loss: 1.1242e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5110e-04 - val_loss: 1.1353e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4791e-04 - val_loss: 1.1485e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4489e-04 - val_loss: 1.1636e-04\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4206e-04 - val_loss: 1.1799e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3946e-04 - val_loss: 1.1970e-04\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3706e-04 - val_loss: 1.2142e-04\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3487e-04 - val_loss: 1.2308e-04\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3285e-04 - val_loss: 1.2463e-04\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3096e-04 - val_loss: 1.2600e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2918e-04 - val_loss: 1.2715e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2747e-04 - val_loss: 1.2804e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2579e-04 - val_loss: 1.2865e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2413e-04 - val_loss: 1.2895e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2245e-04 - val_loss: 1.2896e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2076e-04 - val_loss: 1.2867e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1903e-04 - val_loss: 1.2812e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1727e-04 - val_loss: 1.2731e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1548e-04 - val_loss: 1.2630e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1367e-04 - val_loss: 1.2511e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1184e-04 - val_loss: 1.2376e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1000e-04 - val_loss: 1.2232e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0818e-04 - val_loss: 1.2080e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0636e-04 - val_loss: 1.1926e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0457e-04 - val_loss: 1.1770e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0280e-04 - val_loss: 1.1615e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0106e-04 - val_loss: 1.1465e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9936e-04 - val_loss: 1.1320e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9769e-04 - val_loss: 1.1183e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9605e-04 - val_loss: 1.1052e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9444e-04 - val_loss: 1.0931e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9286e-04 - val_loss: 1.0819e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9129e-04 - val_loss: 1.0714e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8975e-04 - val_loss: 1.0619e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8823e-04 - val_loss: 1.0533e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8671e-04 - val_loss: 1.0455e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8522e-04 - val_loss: 1.0385e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8373e-04 - val_loss: 1.0322e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8225e-04 - val_loss: 1.0266e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8077e-04 - val_loss: 1.0216e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.7930e-04 - val_loss: 1.0171e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7785e-04 - val_loss: 1.0130e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7640e-04 - val_loss: 1.0094e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7496e-04 - val_loss: 1.0062e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7354e-04 - val_loss: 1.0032e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7212e-04 - val_loss: 1.0003e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7072e-04 - val_loss: 9.9762e-05\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6933e-04 - val_loss: 9.9500e-05\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6796e-04 - val_loss: 9.9238e-05\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6659e-04 - val_loss: 9.8979e-05\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6525e-04 - val_loss: 9.8703e-05\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6391e-04 - val_loss: 9.8425e-05\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6259e-04 - val_loss: 9.8132e-05\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6129e-04 - val_loss: 9.7820e-05\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5999e-04 - val_loss: 9.7486e-05\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 1.5871e-04 - val_loss: 9.7135e-05\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5744e-04 - val_loss: 9.6764e-05\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5618e-04 - val_loss: 9.6374e-05\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5493e-04 - val_loss: 9.5962e-05\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5369e-04 - val_loss: 9.5531e-05\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5247e-04 - val_loss: 9.5086e-05\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 1.5125e-04 - val_loss: 9.4627e-05\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5004e-04 - val_loss: 9.4159e-05\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4885e-04 - val_loss: 9.3672e-05\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4766e-04 - val_loss: 9.3181e-05\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.4649e-04 - val_loss: 9.2682e-05\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4532e-04 - val_loss: 9.2182e-05\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4417e-04 - val_loss: 9.1675e-05\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4302e-04 - val_loss: 9.1169e-05\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4189e-04 - val_loss: 9.0671e-05\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4077e-04 - val_loss: 9.0176e-05\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3966e-04 - val_loss: 8.9688e-05\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3855e-04 - val_loss: 8.9203e-05\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 1.3746e-04 - val_loss: 8.8730e-05\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3638e-04 - val_loss: 8.8261e-05\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3531e-04 - val_loss: 8.7801e-05\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3425e-04 - val_loss: 8.7354e-05\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3320e-04 - val_loss: 8.6916e-05\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3216e-04 - val_loss: 8.6489e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3113e-04 - val_loss: 8.6070e-05\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3011e-04 - val_loss: 8.5661e-05\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2910e-04 - val_loss: 8.5263e-05\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2809e-04 - val_loss: 8.4870e-05\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2710e-04 - val_loss: 8.4489e-05\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2612e-04 - val_loss: 8.4110e-05\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2514e-04 - val_loss: 8.3740e-05\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2417e-04 - val_loss: 8.3372e-05\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2322e-04 - val_loss: 8.3017e-05\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2227e-04 - val_loss: 8.2663e-05\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2133e-04 - val_loss: 8.2315e-05\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2040e-04 - val_loss: 8.1964e-05\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1948e-04 - val_loss: 8.1622e-05\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1857e-04 - val_loss: 8.1281e-05\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1767e-04 - val_loss: 8.0939e-05\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1677e-04 - val_loss: 8.0604e-05\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1589e-04 - val_loss: 8.0266e-05\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1501e-04 - val_loss: 7.9929e-05\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1414e-04 - val_loss: 7.9595e-05\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1328e-04 - val_loss: 7.9264e-05\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1243e-04 - val_loss: 7.8927e-05\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1159e-04 - val_loss: 7.8592e-05\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1075e-04 - val_loss: 7.8259e-05\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0993e-04 - val_loss: 7.7921e-05\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0911e-04 - val_loss: 7.7594e-05\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.0830e-04 - val_loss: 7.7261e-05\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0750e-04 - val_loss: 7.6931e-05\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0670e-04 - val_loss: 7.6602e-05\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0592e-04 - val_loss: 7.6268e-05\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0514e-04 - val_loss: 7.5943e-05\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0437e-04 - val_loss: 7.5616e-05\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0360e-04 - val_loss: 7.5292e-05\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0285e-04 - val_loss: 7.4970e-05\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0210e-04 - val_loss: 7.4646e-05\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0136e-04 - val_loss: 7.4329e-05\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 1.0063e-04 - val_loss: 7.4015e-05\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9906e-05 - val_loss: 7.3703e-05\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9189e-05 - val_loss: 7.3390e-05\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8476e-05 - val_loss: 7.3086e-05\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7772e-05 - val_loss: 7.2774e-05\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7074e-05 - val_loss: 7.2474e-05\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6387e-05 - val_loss: 7.2175e-05\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5706e-05 - val_loss: 7.1875e-05\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5032e-05 - val_loss: 7.1583e-05\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.4363e-05 - val_loss: 7.1289e-05\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3701e-05 - val_loss: 7.1000e-05\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3046e-05 - val_loss: 7.0712e-05\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2398e-05 - val_loss: 7.0427e-05\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1757e-05 - val_loss: 7.0145e-05\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1126e-05 - val_loss: 6.9863e-05\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0494e-05 - val_loss: 6.9584e-05\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 8.9876e-05 - val_loss: 6.9309e-05\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.9261e-05 - val_loss: 6.9040e-05\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 8.8653e-05 - val_loss: 6.8766e-05\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8051e-05 - val_loss: 6.8495e-05\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7454e-05 - val_loss: 6.8233e-05\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 8.6867e-05 - val_loss: 6.7969e-05\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6286e-05 - val_loss: 6.7703e-05\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5708e-05 - val_loss: 6.7440e-05\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5136e-05 - val_loss: 6.7185e-05\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4573e-05 - val_loss: 6.6920e-05\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4012e-05 - val_loss: 6.6665e-05\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3460e-05 - val_loss: 6.6409e-05\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2911e-05 - val_loss: 6.6159e-05\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2373e-05 - val_loss: 6.5900e-05\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1834e-05 - val_loss: 6.5654e-05\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.1304e-05 - val_loss: 6.5406e-05\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0782e-05 - val_loss: 6.5161e-05\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 8.0263e-05 - val_loss: 6.4911e-05\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9751e-05 - val_loss: 6.4672e-05\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9243e-05 - val_loss: 6.4425e-05\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8741e-05 - val_loss: 6.4184e-05\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8243e-05 - val_loss: 6.3948e-05\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7753e-05 - val_loss: 6.3711e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7269e-05 - val_loss: 6.3474e-05\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6786e-05 - val_loss: 6.3234e-05\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 7.6308e-05 - val_loss: 6.3009e-05\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5872e-05 - val_loss: 6.2774e-05\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5465e-05 - val_loss: 6.2544e-05\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.5061e-05 - val_loss: 6.2313e-05\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.4658e-05 - val_loss: 6.2092e-05\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4258e-05 - val_loss: 6.1870e-05\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.3864e-05 - val_loss: 6.1647e-05\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3474e-05 - val_loss: 6.1430e-05\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3085e-05 - val_loss: 6.1216e-05\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2699e-05 - val_loss: 6.1001e-05\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2318e-05 - val_loss: 6.0788e-05\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1935e-05 - val_loss: 6.0581e-05\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1562e-05 - val_loss: 6.0378e-05\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1190e-05 - val_loss: 6.0177e-05\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0820e-05 - val_loss: 5.9973e-05\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0450e-05 - val_loss: 5.9776e-05\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0085e-05 - val_loss: 5.9578e-05\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9725e-05 - val_loss: 5.9386e-05\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.9366e-05 - val_loss: 5.9189e-05\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 6.9010e-05 - val_loss: 5.9001e-05\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8655e-05 - val_loss: 5.8809e-05\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8304e-05 - val_loss: 5.8620e-05\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.7960e-05 - val_loss: 5.8427e-05\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.7613e-05 - val_loss: 5.8241e-05\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7272e-05 - val_loss: 5.8054e-05\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6931e-05 - val_loss: 5.7869e-05\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6595e-05 - val_loss: 5.7681e-05\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 6.6259e-05 - val_loss: 5.7497e-05\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5927e-05 - val_loss: 5.7314e-05\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5598e-05 - val_loss: 5.7130e-05\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5271e-05 - val_loss: 5.6945e-05\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4947e-05 - val_loss: 5.6764e-05\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4626e-05 - val_loss: 5.6585e-05\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4305e-05 - val_loss: 5.6403e-05\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3989e-05 - val_loss: 5.6225e-05\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3673e-05 - val_loss: 5.6044e-05\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3362e-05 - val_loss: 5.5865e-05\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3052e-05 - val_loss: 5.5688e-05\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2744e-05 - val_loss: 5.5510e-05\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2441e-05 - val_loss: 5.5334e-05\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2136e-05 - val_loss: 5.5158e-05\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1836e-05 - val_loss: 5.4987e-05\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 6.1538e-05 - val_loss: 5.4811e-05\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1243e-05 - val_loss: 5.4635e-05\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0948e-05 - val_loss: 5.4464e-05\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 6.0658e-05 - val_loss: 5.4296e-05\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0366e-05 - val_loss: 5.4123e-05\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 6.0079e-05 - val_loss: 5.3954e-05\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9797e-05 - val_loss: 5.3788e-05\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9514e-05 - val_loss: 5.3619e-05\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9233e-05 - val_loss: 5.3453e-05\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.8956e-05 - val_loss: 5.3285e-05\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8678e-05 - val_loss: 5.3121e-05\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8404e-05 - val_loss: 5.2958e-05\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8132e-05 - val_loss: 5.2796e-05\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7863e-05 - val_loss: 5.2631e-05\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7595e-05 - val_loss: 5.2473e-05\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7330e-05 - val_loss: 5.2313e-05\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7067e-05 - val_loss: 5.2147e-05\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6802e-05 - val_loss: 5.1997e-05\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6544e-05 - val_loss: 5.1840e-05\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6287e-05 - val_loss: 5.1686e-05\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6031e-05 - val_loss: 5.1528e-05\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5777e-05 - val_loss: 5.1373e-05\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.5525e-05 - val_loss: 5.1221e-05\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5276e-05 - val_loss: 5.1068e-05\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5026e-05 - val_loss: 5.0915e-05\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4780e-05 - val_loss: 5.0768e-05\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4537e-05 - val_loss: 5.0618e-05\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4295e-05 - val_loss: 5.0466e-05\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4052e-05 - val_loss: 5.0314e-05\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3812e-05 - val_loss: 5.0168e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3575e-05 - val_loss: 5.0022e-05\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3340e-05 - val_loss: 4.9878e-05\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3107e-05 - val_loss: 4.9729e-05\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2874e-05 - val_loss: 4.9587e-05\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2645e-05 - val_loss: 4.9440e-05\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2417e-05 - val_loss: 4.9299e-05\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2191e-05 - val_loss: 4.9159e-05\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1967e-05 - val_loss: 4.9016e-05\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1744e-05 - val_loss: 4.8873e-05\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1522e-05 - val_loss: 4.8732e-05\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1300e-05 - val_loss: 4.8594e-05\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1083e-05 - val_loss: 4.8451e-05\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0867e-05 - val_loss: 4.8313e-05\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0652e-05 - val_loss: 4.8174e-05\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0439e-05 - val_loss: 4.8035e-05\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0229e-05 - val_loss: 4.7902e-05\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0018e-05 - val_loss: 4.7766e-05\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9811e-05 - val_loss: 4.7631e-05\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9601e-05 - val_loss: 4.7495e-05\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9397e-05 - val_loss: 4.7361e-05\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9193e-05 - val_loss: 4.7228e-05\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8990e-05 - val_loss: 4.7097e-05\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8790e-05 - val_loss: 4.6962e-05\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8592e-05 - val_loss: 4.6832e-05\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8394e-05 - val_loss: 4.6704e-05\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8198e-05 - val_loss: 4.6578e-05\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8005e-05 - val_loss: 4.6446e-05\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7811e-05 - val_loss: 4.6314e-05\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7618e-05 - val_loss: 4.6188e-05\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 4.7430e-05 - val_loss: 4.6061e-05\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.7240e-05 - val_loss: 4.5933e-05\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7052e-05 - val_loss: 4.5809e-05\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6866e-05 - val_loss: 4.5684e-05\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6682e-05 - val_loss: 4.5556e-05\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.6497e-05 - val_loss: 4.5436e-05\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6318e-05 - val_loss: 4.5308e-05\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6137e-05 - val_loss: 4.5187e-05\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5956e-05 - val_loss: 4.5069e-05\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5780e-05 - val_loss: 4.4946e-05\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5602e-05 - val_loss: 4.4822e-05\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5428e-05 - val_loss: 4.4703e-05\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5252e-05 - val_loss: 4.4582e-05\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5082e-05 - val_loss: 4.4462e-05\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4909e-05 - val_loss: 4.4345e-05\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4740e-05 - val_loss: 4.4227e-05\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4571e-05 - val_loss: 4.4107e-05\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4403e-05 - val_loss: 4.3992e-05\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4239e-05 - val_loss: 4.3875e-05\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4075e-05 - val_loss: 4.3759e-05\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3909e-05 - val_loss: 4.3641e-05\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3747e-05 - val_loss: 4.3525e-05\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3586e-05 - val_loss: 4.3413e-05\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3424e-05 - val_loss: 4.3299e-05\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3267e-05 - val_loss: 4.3185e-05\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3109e-05 - val_loss: 4.3070e-05\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2948e-05 - val_loss: 4.2961e-05\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2797e-05 - val_loss: 4.2850e-05\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2642e-05 - val_loss: 4.2739e-05\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2489e-05 - val_loss: 4.2631e-05\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2338e-05 - val_loss: 4.2521e-05\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2188e-05 - val_loss: 4.2411e-05\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2037e-05 - val_loss: 4.2304e-05\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1890e-05 - val_loss: 4.2192e-05\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1739e-05 - val_loss: 4.2086e-05\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1594e-05 - val_loss: 4.1978e-05\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.1451e-05 - val_loss: 4.1871e-05\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1306e-05 - val_loss: 4.1766e-05\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1161e-05 - val_loss: 4.1662e-05\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1022e-05 - val_loss: 4.1553e-05\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0877e-05 - val_loss: 4.1450e-05\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0738e-05 - val_loss: 4.1345e-05\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0598e-05 - val_loss: 4.1241e-05\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0463e-05 - val_loss: 4.1138e-05\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0325e-05 - val_loss: 4.1036e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0191e-05 - val_loss: 4.0937e-05\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0056e-05 - val_loss: 4.0832e-05\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9922e-05 - val_loss: 4.0732e-05\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9790e-05 - val_loss: 4.0628e-05\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9657e-05 - val_loss: 4.0529e-05\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9525e-05 - val_loss: 4.0429e-05\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9395e-05 - val_loss: 4.0324e-05\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9267e-05 - val_loss: 4.0227e-05\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9139e-05 - val_loss: 4.0130e-05\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9011e-05 - val_loss: 4.0031e-05\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8886e-05 - val_loss: 3.9936e-05\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8761e-05 - val_loss: 3.9835e-05\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8636e-05 - val_loss: 3.9743e-05\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8512e-05 - val_loss: 3.9648e-05\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8391e-05 - val_loss: 3.9551e-05\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 3.8270e-05 - val_loss: 3.9456e-05\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8150e-05 - val_loss: 3.9356e-05\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8027e-05 - val_loss: 3.9264e-05\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7909e-05 - val_loss: 3.9170e-05\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7792e-05 - val_loss: 3.9075e-05\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 3.7672e-05 - val_loss: 3.8983e-05\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7558e-05 - val_loss: 3.8894e-05\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7442e-05 - val_loss: 3.8799e-05\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7328e-05 - val_loss: 3.8706e-05\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7213e-05 - val_loss: 3.8616e-05\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7101e-05 - val_loss: 3.8526e-05\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.6989e-05 - val_loss: 3.8431e-05\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6878e-05 - val_loss: 3.8341e-05\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6768e-05 - val_loss: 3.8255e-05\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6658e-05 - val_loss: 3.8164e-05\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6549e-05 - val_loss: 3.8074e-05\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6440e-05 - val_loss: 3.7985e-05\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6333e-05 - val_loss: 3.7898e-05\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6227e-05 - val_loss: 3.7808e-05\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6120e-05 - val_loss: 3.7718e-05\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6016e-05 - val_loss: 3.7631e-05\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5912e-05 - val_loss: 3.7545e-05\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5808e-05 - val_loss: 3.7461e-05\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5704e-05 - val_loss: 3.7370e-05\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5601e-05 - val_loss: 3.7287e-05\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5502e-05 - val_loss: 3.7204e-05\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5403e-05 - val_loss: 3.7118e-05\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5299e-05 - val_loss: 3.7034e-05\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5202e-05 - val_loss: 3.6949e-05\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5104e-05 - val_loss: 3.6867e-05\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5007e-05 - val_loss: 3.6785e-05\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4910e-05 - val_loss: 3.6703e-05\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4813e-05 - val_loss: 3.6618e-05\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4715e-05 - val_loss: 3.6534e-05\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.4622e-05 - val_loss: 3.6452e-05\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4527e-05 - val_loss: 3.6371e-05\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4433e-05 - val_loss: 3.6292e-05\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4342e-05 - val_loss: 3.6208e-05\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4248e-05 - val_loss: 3.6129e-05\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4156e-05 - val_loss: 3.6053e-05\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4067e-05 - val_loss: 3.5968e-05\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3975e-05 - val_loss: 3.5893e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3886e-05 - val_loss: 3.5812e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3796e-05 - val_loss: 3.5731e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3707e-05 - val_loss: 3.5654e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3621e-05 - val_loss: 3.5576e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3533e-05 - val_loss: 3.5498e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3446e-05 - val_loss: 3.5422e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3361e-05 - val_loss: 3.5344e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3275e-05 - val_loss: 3.5271e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3192e-05 - val_loss: 3.5192e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3107e-05 - val_loss: 3.5113e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3023e-05 - val_loss: 3.5037e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2940e-05 - val_loss: 3.4960e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2857e-05 - val_loss: 3.4888e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2777e-05 - val_loss: 3.4812e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2696e-05 - val_loss: 3.4740e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2615e-05 - val_loss: 3.4664e-05\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2534e-05 - val_loss: 3.4588e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2454e-05 - val_loss: 3.4516e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2375e-05 - val_loss: 3.4443e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2296e-05 - val_loss: 3.4370e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2219e-05 - val_loss: 3.4296e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2141e-05 - val_loss: 3.4224e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2064e-05 - val_loss: 3.4153e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1988e-05 - val_loss: 3.4082e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1913e-05 - val_loss: 3.4010e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1837e-05 - val_loss: 3.3937e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1761e-05 - val_loss: 3.3868e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1689e-05 - val_loss: 3.3796e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1615e-05 - val_loss: 3.3726e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1540e-05 - val_loss: 3.3658e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1468e-05 - val_loss: 3.3590e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1395e-05 - val_loss: 3.3518e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1324e-05 - val_loss: 3.3451e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1254e-05 - val_loss: 3.3383e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1183e-05 - val_loss: 3.3317e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1112e-05 - val_loss: 3.3245e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1043e-05 - val_loss: 3.3176e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0973e-05 - val_loss: 3.3110e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0905e-05 - val_loss: 3.3042e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0836e-05 - val_loss: 3.2977e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0768e-05 - val_loss: 3.2911e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0701e-05 - val_loss: 3.2843e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0633e-05 - val_loss: 3.2776e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0566e-05 - val_loss: 3.2709e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0500e-05 - val_loss: 3.2647e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0436e-05 - val_loss: 3.2580e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0369e-05 - val_loss: 3.2512e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0304e-05 - val_loss: 3.2449e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0242e-05 - val_loss: 3.2383e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0177e-05 - val_loss: 3.2321e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0114e-05 - val_loss: 3.2256e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0050e-05 - val_loss: 3.2193e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9988e-05 - val_loss: 3.2128e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9926e-05 - val_loss: 3.2066e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9864e-05 - val_loss: 3.2001e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9803e-05 - val_loss: 3.1939e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9743e-05 - val_loss: 3.1876e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 2.9680e-05 - val_loss: 3.1815e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9622e-05 - val_loss: 3.1754e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 2.9562e-05 - val_loss: 3.1691e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 2.9503e-05 - val_loss: 3.1629e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9443e-05 - val_loss: 3.1567e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9382e-05 - val_loss: 3.1504e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.9326e-05 - val_loss: 3.1446e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.9269e-05 - val_loss: 3.1385e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9211e-05 - val_loss: 3.1323e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9154e-05 - val_loss: 3.1267e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9096e-05 - val_loss: 3.1206e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9040e-05 - val_loss: 3.1144e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 2.8984e-05 - val_loss: 3.1085e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8928e-05 - val_loss: 3.1027e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8874e-05 - val_loss: 3.0967e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8818e-05 - val_loss: 3.0907e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8763e-05 - val_loss: 3.0852e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8708e-05 - val_loss: 3.0793e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 2.8656e-05 - val_loss: 3.0735e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8603e-05 - val_loss: 3.0677e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8548e-05 - val_loss: 3.0619e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8495e-05 - val_loss: 3.0563e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8444e-05 - val_loss: 3.0504e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8391e-05 - val_loss: 3.0445e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8338e-05 - val_loss: 3.0386e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8286e-05 - val_loss: 3.0334e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8237e-05 - val_loss: 3.0277e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8186e-05 - val_loss: 3.0221e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8135e-05 - val_loss: 3.0166e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8084e-05 - val_loss: 3.0109e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8033e-05 - val_loss: 3.0052e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7985e-05 - val_loss: 2.9998e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7936e-05 - val_loss: 2.9944e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7887e-05 - val_loss: 2.9889e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7839e-05 - val_loss: 2.9833e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7789e-05 - val_loss: 2.9779e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7744e-05 - val_loss: 2.9727e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7695e-05 - val_loss: 2.9672e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7646e-05 - val_loss: 2.9620e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7600e-05 - val_loss: 2.9565e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7553e-05 - val_loss: 2.9514e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7505e-05 - val_loss: 2.9461e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7460e-05 - val_loss: 2.9408e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7414e-05 - val_loss: 2.9358e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.7368e-05 - val_loss: 2.9306e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7323e-05 - val_loss: 2.9252e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7277e-05 - val_loss: 2.9200e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7232e-05 - val_loss: 2.9145e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7187e-05 - val_loss: 2.9095e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.7143e-05 - val_loss: 2.9043e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7099e-05 - val_loss: 2.8989e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7053e-05 - val_loss: 2.8940e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7011e-05 - val_loss: 2.8892e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6966e-05 - val_loss: 2.8839e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6925e-05 - val_loss: 2.8789e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 2.6881e-05 - val_loss: 2.8738e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 2.6838e-05 - val_loss: 2.8688e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6795e-05 - val_loss: 2.8638e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6754e-05 - val_loss: 2.8588e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6711e-05 - val_loss: 2.8538e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6671e-05 - val_loss: 2.8491e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6630e-05 - val_loss: 2.8442e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6589e-05 - val_loss: 2.8391e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6547e-05 - val_loss: 2.8342e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6507e-05 - val_loss: 2.8294e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6467e-05 - val_loss: 2.8246e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6426e-05 - val_loss: 2.8197e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6385e-05 - val_loss: 2.8150e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6347e-05 - val_loss: 2.8100e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6306e-05 - val_loss: 2.8053e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6268e-05 - val_loss: 2.8006e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6229e-05 - val_loss: 2.7959e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6190e-05 - val_loss: 2.7910e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6152e-05 - val_loss: 2.7865e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6113e-05 - val_loss: 2.7817e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6074e-05 - val_loss: 2.7771e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6037e-05 - val_loss: 2.7723e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5999e-05 - val_loss: 2.7678e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5962e-05 - val_loss: 2.7629e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5924e-05 - val_loss: 2.7585e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5886e-05 - val_loss: 2.7539e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5850e-05 - val_loss: 2.7492e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5814e-05 - val_loss: 2.7445e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5776e-05 - val_loss: 2.7399e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5740e-05 - val_loss: 2.7355e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5703e-05 - val_loss: 2.7311e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5669e-05 - val_loss: 2.7266e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5633e-05 - val_loss: 2.7222e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5598e-05 - val_loss: 2.7177e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5563e-05 - val_loss: 2.7128e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5526e-05 - val_loss: 2.7085e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 2.5492e-05 - val_loss: 2.7043e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5456e-05 - val_loss: 2.6999e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5422e-05 - val_loss: 2.6954e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5388e-05 - val_loss: 2.6909e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5353e-05 - val_loss: 2.6866e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5320e-05 - val_loss: 2.6823e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 2.5287e-05 - val_loss: 2.6777e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5252e-05 - val_loss: 2.6736e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5219e-05 - val_loss: 2.6691e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 2.5185e-05 - val_loss: 2.6650e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5151e-05 - val_loss: 2.6608e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5118e-05 - val_loss: 2.6564e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5086e-05 - val_loss: 2.6522e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.5053e-05 - val_loss: 2.6479e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5020e-05 - val_loss: 2.6439e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4990e-05 - val_loss: 2.6397e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4957e-05 - val_loss: 2.6355e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4925e-05 - val_loss: 2.6316e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4893e-05 - val_loss: 2.6276e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4862e-05 - val_loss: 2.6234e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4830e-05 - val_loss: 2.6192e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4799e-05 - val_loss: 2.6154e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4769e-05 - val_loss: 2.6109e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4737e-05 - val_loss: 2.6070e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4706e-05 - val_loss: 2.6029e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4674e-05 - val_loss: 2.5989e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4645e-05 - val_loss: 2.5950e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.4615e-05 - val_loss: 2.5909e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4585e-05 - val_loss: 2.5869e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4553e-05 - val_loss: 2.5826e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4524e-05 - val_loss: 2.5787e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4493e-05 - val_loss: 2.5749e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 342us/step - loss: 2.4466e-05 - val_loss: 2.5708e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 215us/step - loss: 2.4434e-05 - val_loss: 2.5668e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.4405e-05 - val_loss: 2.5628e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4375e-05 - val_loss: 2.5592e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4349e-05 - val_loss: 2.5553e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4319e-05 - val_loss: 2.5513e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4290e-05 - val_loss: 2.5474e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4261e-05 - val_loss: 2.5435e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4232e-05 - val_loss: 2.5397e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4204e-05 - val_loss: 2.5359e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.4177e-05 - val_loss: 2.5319e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4149e-05 - val_loss: 2.5282e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.4120e-05 - val_loss: 2.5245e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4091e-05 - val_loss: 2.5209e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4063e-05 - val_loss: 2.5169e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4036e-05 - val_loss: 2.5132e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4009e-05 - val_loss: 2.5096e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3981e-05 - val_loss: 2.5058e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3955e-05 - val_loss: 2.5019e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3928e-05 - val_loss: 2.4985e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3900e-05 - val_loss: 2.4945e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3874e-05 - val_loss: 2.4909e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3847e-05 - val_loss: 2.4871e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3820e-05 - val_loss: 2.4835e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3793e-05 - val_loss: 2.4799e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3768e-05 - val_loss: 2.4763e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3740e-05 - val_loss: 2.4726e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3716e-05 - val_loss: 2.4688e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3691e-05 - val_loss: 2.4656e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 2.3663e-05 - val_loss: 2.4619e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3637e-05 - val_loss: 2.4584e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3610e-05 - val_loss: 2.4548e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3586e-05 - val_loss: 2.4511e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3560e-05 - val_loss: 2.4477e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3534e-05 - val_loss: 2.4438e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3510e-05 - val_loss: 2.4408e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3485e-05 - val_loss: 2.4372e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3460e-05 - val_loss: 2.4334e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3435e-05 - val_loss: 2.4301e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3410e-05 - val_loss: 2.4266e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3384e-05 - val_loss: 2.4229e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3360e-05 - val_loss: 2.4195e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3335e-05 - val_loss: 2.4159e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3310e-05 - val_loss: 2.4127e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3289e-05 - val_loss: 2.4093e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3263e-05 - val_loss: 2.4061e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3240e-05 - val_loss: 2.4024e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3213e-05 - val_loss: 2.3990e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3190e-05 - val_loss: 2.3957e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3169e-05 - val_loss: 2.3920e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3143e-05 - val_loss: 2.3888e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3120e-05 - val_loss: 2.3854e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3096e-05 - val_loss: 2.3820e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3074e-05 - val_loss: 2.3789e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3050e-05 - val_loss: 2.3753e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3026e-05 - val_loss: 2.3723e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3003e-05 - val_loss: 2.3689e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2980e-05 - val_loss: 2.3659e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2959e-05 - val_loss: 2.3622e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2934e-05 - val_loss: 2.3593e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2912e-05 - val_loss: 2.3560e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2890e-05 - val_loss: 2.3527e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2867e-05 - val_loss: 2.3496e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2844e-05 - val_loss: 2.3463e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2821e-05 - val_loss: 2.3433e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2800e-05 - val_loss: 2.3399e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2776e-05 - val_loss: 2.3368e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2755e-05 - val_loss: 2.3334e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2733e-05 - val_loss: 2.3306e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2711e-05 - val_loss: 2.3273e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2688e-05 - val_loss: 2.3244e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2667e-05 - val_loss: 2.3213e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2647e-05 - val_loss: 2.3179e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2624e-05 - val_loss: 2.3147e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2601e-05 - val_loss: 2.3119e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2581e-05 - val_loss: 2.3086e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2559e-05 - val_loss: 2.3058e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2538e-05 - val_loss: 2.3025e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2517e-05 - val_loss: 2.2995e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2495e-05 - val_loss: 2.2964e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2474e-05 - val_loss: 2.2933e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2454e-05 - val_loss: 2.2903e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2432e-05 - val_loss: 2.2872e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2412e-05 - val_loss: 2.2842e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2390e-05 - val_loss: 2.2811e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2370e-05 - val_loss: 2.2781e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2350e-05 - val_loss: 2.2752e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2328e-05 - val_loss: 2.2722e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2308e-05 - val_loss: 2.2692e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2289e-05 - val_loss: 2.2659e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2267e-05 - val_loss: 2.2631e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2246e-05 - val_loss: 2.2603e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2226e-05 - val_loss: 2.2572e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2205e-05 - val_loss: 2.2541e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2187e-05 - val_loss: 2.2515e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2166e-05 - val_loss: 2.2483e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2146e-05 - val_loss: 2.2455e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2125e-05 - val_loss: 2.2425e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2105e-05 - val_loss: 2.2396e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2086e-05 - val_loss: 2.2366e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2066e-05 - val_loss: 2.2340e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2046e-05 - val_loss: 2.2311e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2026e-05 - val_loss: 2.2282e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2007e-05 - val_loss: 2.2256e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1989e-05 - val_loss: 2.2223e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1968e-05 - val_loss: 2.2198e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1949e-05 - val_loss: 2.2170e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1931e-05 - val_loss: 2.2140e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1911e-05 - val_loss: 2.2112e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1893e-05 - val_loss: 2.2084e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1872e-05 - val_loss: 2.2056e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1854e-05 - val_loss: 2.2031e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1834e-05 - val_loss: 2.2003e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1817e-05 - val_loss: 2.1974e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1797e-05 - val_loss: 2.1946e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1777e-05 - val_loss: 2.1919e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1759e-05 - val_loss: 2.1893e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 2.1741e-05 - val_loss: 2.1866e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1723e-05 - val_loss: 2.1838e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1702e-05 - val_loss: 2.1811e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1685e-05 - val_loss: 2.1784e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1664e-05 - val_loss: 2.1756e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1648e-05 - val_loss: 2.1729e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1629e-05 - val_loss: 2.1700e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1611e-05 - val_loss: 2.1675e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1593e-05 - val_loss: 2.1649e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1575e-05 - val_loss: 2.1621e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1557e-05 - val_loss: 2.1595e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1539e-05 - val_loss: 2.1569e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.1520e-05 - val_loss: 2.1541e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1503e-05 - val_loss: 2.1516e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1485e-05 - val_loss: 2.1487e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1466e-05 - val_loss: 2.1465e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1449e-05 - val_loss: 2.1438e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1431e-05 - val_loss: 2.1412e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1413e-05 - val_loss: 2.1386e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1395e-05 - val_loss: 2.1361e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1378e-05 - val_loss: 2.1335e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1361e-05 - val_loss: 2.1308e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1344e-05 - val_loss: 2.1282e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1325e-05 - val_loss: 2.1257e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1307e-05 - val_loss: 2.1234e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1291e-05 - val_loss: 2.1206e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1273e-05 - val_loss: 2.1180e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1256e-05 - val_loss: 2.1157e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 2.1239e-05 - val_loss: 2.1130e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1221e-05 - val_loss: 2.1103e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1205e-05 - val_loss: 2.1079e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1187e-05 - val_loss: 2.1054e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1171e-05 - val_loss: 2.1030e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 2.1153e-05 - val_loss: 2.1004e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1135e-05 - val_loss: 2.0981e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1119e-05 - val_loss: 2.0956e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 2.1102e-05 - val_loss: 2.0930e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1087e-05 - val_loss: 2.0904e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1068e-05 - val_loss: 2.0879e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1052e-05 - val_loss: 2.0856e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1035e-05 - val_loss: 2.0832e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1019e-05 - val_loss: 2.0807e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1002e-05 - val_loss: 2.0784e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0985e-05 - val_loss: 2.0760e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0969e-05 - val_loss: 2.0734e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 2.0952e-05 - val_loss: 2.0710e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0935e-05 - val_loss: 2.0687e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0920e-05 - val_loss: 2.0660e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0901e-05 - val_loss: 2.0639e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0887e-05 - val_loss: 2.0616e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0871e-05 - val_loss: 2.0590e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0853e-05 - val_loss: 2.0568e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0837e-05 - val_loss: 2.0544e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0822e-05 - val_loss: 2.0520e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0806e-05 - val_loss: 2.0498e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0789e-05 - val_loss: 2.0474e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0772e-05 - val_loss: 2.0450e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0757e-05 - val_loss: 2.0428e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0741e-05 - val_loss: 2.0404e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0726e-05 - val_loss: 2.0379e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0709e-05 - val_loss: 2.0357e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0693e-05 - val_loss: 2.0335e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.0678e-05 - val_loss: 2.0315e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0662e-05 - val_loss: 2.0289e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0645e-05 - val_loss: 2.0268e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0631e-05 - val_loss: 2.0244e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0614e-05 - val_loss: 2.0222e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0599e-05 - val_loss: 2.0199e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0583e-05 - val_loss: 2.0176e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0567e-05 - val_loss: 2.0152e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0552e-05 - val_loss: 2.0128e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0535e-05 - val_loss: 2.0106e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0520e-05 - val_loss: 2.0083e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0506e-05 - val_loss: 2.0062e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0491e-05 - val_loss: 2.0038e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0474e-05 - val_loss: 2.0015e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0458e-05 - val_loss: 1.9994e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 2.0443e-05 - val_loss: 1.9974e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0428e-05 - val_loss: 1.9951e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0414e-05 - val_loss: 1.9927e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0398e-05 - val_loss: 1.9907e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0382e-05 - val_loss: 1.9884e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0367e-05 - val_loss: 1.9864e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0352e-05 - val_loss: 1.9841e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0338e-05 - val_loss: 1.9820e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0322e-05 - val_loss: 1.9798e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0307e-05 - val_loss: 1.9775e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0291e-05 - val_loss: 1.9755e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0277e-05 - val_loss: 1.9733e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 2.0263e-05 - val_loss: 1.9712e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0247e-05 - val_loss: 1.9694e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0232e-05 - val_loss: 1.9668e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0217e-05 - val_loss: 1.9648e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0203e-05 - val_loss: 1.9627e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0187e-05 - val_loss: 1.9604e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0172e-05 - val_loss: 1.9583e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0158e-05 - val_loss: 1.9562e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 2.0143e-05 - val_loss: 1.9542e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0129e-05 - val_loss: 1.9520e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0114e-05 - val_loss: 1.9500e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0098e-05 - val_loss: 1.9480e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0085e-05 - val_loss: 1.9458e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0070e-05 - val_loss: 1.9437e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0055e-05 - val_loss: 1.9418e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0042e-05 - val_loss: 1.9394e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0026e-05 - val_loss: 1.9375e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0013e-05 - val_loss: 1.9356e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9998e-05 - val_loss: 1.9337e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9984e-05 - val_loss: 1.9316e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9969e-05 - val_loss: 1.9294e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9953e-05 - val_loss: 1.9275e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9941e-05 - val_loss: 1.9254e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9925e-05 - val_loss: 1.9233e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9910e-05 - val_loss: 1.9215e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.9898e-05 - val_loss: 1.9192e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9883e-05 - val_loss: 1.9173e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9869e-05 - val_loss: 1.9153e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9854e-05 - val_loss: 1.9131e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9841e-05 - val_loss: 1.9111e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9826e-05 - val_loss: 1.9094e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9812e-05 - val_loss: 1.9073e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9799e-05 - val_loss: 1.9053e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9784e-05 - val_loss: 1.9035e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9771e-05 - val_loss: 1.9015e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9757e-05 - val_loss: 1.8993e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9741e-05 - val_loss: 1.8977e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9730e-05 - val_loss: 1.8958e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9715e-05 - val_loss: 1.8936e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 1.9701e-05 - val_loss: 1.8918e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9687e-05 - val_loss: 1.8897e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 1.9674e-05 - val_loss: 1.8878e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9659e-05 - val_loss: 1.8857e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9645e-05 - val_loss: 1.8837e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9631e-05 - val_loss: 1.8821e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9618e-05 - val_loss: 1.8801e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 1.9604e-05 - val_loss: 1.8779e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 1.9591e-05 - val_loss: 1.8760e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9577e-05 - val_loss: 1.8743e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9564e-05 - val_loss: 1.8723e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9550e-05 - val_loss: 1.8706e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9537e-05 - val_loss: 1.8688e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9523e-05 - val_loss: 1.8668e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9508e-05 - val_loss: 1.8646e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9494e-05 - val_loss: 1.8630e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9482e-05 - val_loss: 1.8612e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9468e-05 - val_loss: 1.8592e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9455e-05 - val_loss: 1.8572e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9440e-05 - val_loss: 1.8556e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9429e-05 - val_loss: 1.8538e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9415e-05 - val_loss: 1.8520e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9401e-05 - val_loss: 1.8502e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9389e-05 - val_loss: 1.8482e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9374e-05 - val_loss: 1.8463e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 1.9361e-05 - val_loss: 1.8446e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9348e-05 - val_loss: 1.8429e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9335e-05 - val_loss: 1.8411e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9322e-05 - val_loss: 1.8392e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9308e-05 - val_loss: 1.8373e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9295e-05 - val_loss: 1.8355e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9281e-05 - val_loss: 1.8336e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9268e-05 - val_loss: 1.8319e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9255e-05 - val_loss: 1.8302e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 1.9242e-05 - val_loss: 1.8281e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 1.9228e-05 - val_loss: 1.8265e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9216e-05 - val_loss: 1.8247e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9203e-05 - val_loss: 1.8229e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9189e-05 - val_loss: 1.8210e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9176e-05 - val_loss: 1.8193e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9163e-05 - val_loss: 1.8175e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9150e-05 - val_loss: 1.8160e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9137e-05 - val_loss: 1.8141e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9125e-05 - val_loss: 1.8121e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9111e-05 - val_loss: 1.8106e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9100e-05 - val_loss: 1.8088e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9086e-05 - val_loss: 1.8070e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9073e-05 - val_loss: 1.8053e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9060e-05 - val_loss: 1.8036e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9048e-05 - val_loss: 1.8020e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9035e-05 - val_loss: 1.8002e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.9022e-05 - val_loss: 1.7985e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9009e-05 - val_loss: 1.7966e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8996e-05 - val_loss: 1.7950e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8984e-05 - val_loss: 1.7933e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8971e-05 - val_loss: 1.7913e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8958e-05 - val_loss: 1.7898e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8946e-05 - val_loss: 1.7881e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8933e-05 - val_loss: 1.7863e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8920e-05 - val_loss: 1.7847e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8907e-05 - val_loss: 1.7831e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8894e-05 - val_loss: 1.7815e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8882e-05 - val_loss: 1.7798e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8870e-05 - val_loss: 1.7781e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8857e-05 - val_loss: 1.7766e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8845e-05 - val_loss: 1.7747e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 1.8832e-05 - val_loss: 1.7730e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8819e-05 - val_loss: 1.7712e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8806e-05 - val_loss: 1.7696e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8794e-05 - val_loss: 1.7680e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8782e-05 - val_loss: 1.7661e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8769e-05 - val_loss: 1.7648e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8757e-05 - val_loss: 1.7629e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.8744e-05 - val_loss: 1.7616e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8733e-05 - val_loss: 1.7598e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 1.8719e-05 - val_loss: 1.7581e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8707e-05 - val_loss: 1.7566e-05\n",
      "8.048046765907202e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.8918452 ,  0.25393698, -0.48617345,  1.198117  , -0.07844995],\n",
       "        [ 1.5344194 ,  0.08692843,  0.65626544, -1.7280511 ,  0.55390495],\n",
       "        [ 1.6001542 ,  0.2996489 , -1.1430048 , -1.3854852 , -1.0204697 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.147418  , -0.65423316,  0.5197399 ,  1.1482992 ,  0.5118166 ],\n",
       "       dtype=float32),\n",
       " array([[-0.9820842 ,  0.94922674, -1.0035353 ,  1.2967627 ,  1.2518846 ,\n",
       "         -1.3865746 , -1.180907  , -1.1982257 ,  0.9547164 ,  1.1117517 ],\n",
       "        [-0.44277748,  0.61768883, -0.42992672,  0.3776626 ,  0.33599237,\n",
       "         -0.31577316, -0.03054678, -0.860149  ,  0.7554583 ,  0.18814555],\n",
       "        [-0.9728291 ,  0.88570344, -0.9274815 ,  1.2117773 ,  0.47634143,\n",
       "         -0.67252845, -1.0076011 , -0.85222983,  0.37117428,  0.6725402 ],\n",
       "        [-1.1400762 ,  1.4912661 , -0.97500193,  1.3306795 ,  1.5142491 ,\n",
       "         -0.9904476 , -0.8736902 , -1.2985238 ,  1.0973003 ,  0.51126975],\n",
       "        [-0.94106185, -0.11268448, -1.2013247 ,  1.153765  ,  0.52838475,\n",
       "         -0.16463871, -1.4210376 , -0.5275375 ,  0.37313527,  0.3526092 ]],\n",
       "       dtype=float32),\n",
       " array([-0.60545105,  1.0887636 , -0.6624043 ,  1.0683398 ,  1.0599316 ,\n",
       "        -0.84892577, -0.8226039 , -0.6353867 ,  1.0906888 ,  1.1367005 ],\n",
       "       dtype=float32),\n",
       " array([[0.6678502 ],\n",
       "        [1.0800245 ],\n",
       "        [0.6571411 ],\n",
       "        [1.153199  ],\n",
       "        [1.1959804 ],\n",
       "        [0.42071116],\n",
       "        [0.63421226],\n",
       "        [0.6481345 ],\n",
       "        [1.1330156 ],\n",
       "        [0.6700855 ]], dtype=float32),\n",
       " array([0.7746929], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_sigmoid(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_sigmoid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 37.1205 - val_loss: 33.7541\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.8104 - val_loss: 28.8853\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.7282 - val_loss: 23.7390\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 22.4084 - val_loss: 18.5389\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 17.1266 - val_loss: 13.4422\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 12.1181 - val_loss: 8.8972\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7456 - val_loss: 5.1736\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2942 - val_loss: 2.4599\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8952 - val_loss: 0.7986\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5263 - val_loss: 0.1090\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0740 - val_loss: 0.2067\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3408 - val_loss: 0.7948\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0140 - val_loss: 1.4820\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 1.7181 - val_loss: 1.9604\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1730 - val_loss: 2.1149\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2837 - val_loss: 1.9723\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0936 - val_loss: 1.6357\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7101 - val_loss: 1.2039\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2473 - val_loss: 0.7740\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8000 - val_loss: 0.4151\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.4325 - val_loss: 0.1659\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1780 - val_loss: 0.0380\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0437 - val_loss: 0.0210\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0172 - val_loss: 0.0887\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0723 - val_loss: 0.2056\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1746 - val_loss: 0.3345\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2888 - val_loss: 0.4439\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3849 - val_loss: 0.5131\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4436 - val_loss: 0.5340\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.4579 - val_loss: 0.5103\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4320 - val_loss: 0.4535\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3776 - val_loss: 0.3783\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3093 - val_loss: 0.2992\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2408 - val_loss: 0.2273\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1822 - val_loss: 0.1693\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1386 - val_loss: 0.1278\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1112 - val_loss: 0.1020\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0976 - val_loss: 0.0888\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0939 - val_loss: 0.0841\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0955 - val_loss: 0.0835\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0983 - val_loss: 0.0837\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0991 - val_loss: 0.0819\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0961 - val_loss: 0.0769\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0886 - val_loss: 0.0684\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0772 - val_loss: 0.0571\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0629 - val_loss: 0.0444\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0475 - val_loss: 0.0315\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0327 - val_loss: 0.0199\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0198 - val_loss: 0.0107\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0043\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0010\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 2.9681e-04\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0118 - val_loss: 0.0089\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0151 - val_loss: 0.0103\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0172 - val_loss: 0.0108\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0180 - val_loss: 0.0103\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0175 - val_loss: 0.0090\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0160 - val_loss: 0.0074\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0139 - val_loss: 0.0057\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0044\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0094 - val_loss: 0.0034\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0030\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 8.2809e-04\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0011 - val_loss: 4.0651e-04\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1575e-04 - val_loss: 1.7526e-04\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8707e-04 - val_loss: 1.1308e-04\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1122e-04 - val_loss: 1.7956e-04\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4896e-04 - val_loss: 3.2532e-04\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5340e-04 - val_loss: 5.0134e-04\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7897e-04 - val_loss: 6.6676e-04\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8851e-04 - val_loss: 7.9339e-04\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5754e-04 - val_loss: 8.6755e-04\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7572e-04 - val_loss: 8.8872e-04\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4528e-04 - val_loss: 8.6666e-04\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7793e-04 - val_loss: 8.1695e-04\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9043e-04 - val_loss: 7.5672e-04\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0037e-04 - val_loss: 7.0107e-04\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2262e-04 - val_loss: 6.6054e-04\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6699e-04 - val_loss: 6.3997e-04\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3728e-04 - val_loss: 6.3872e-04\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3171e-04 - val_loss: 6.5192e-04\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4422e-04 - val_loss: 6.7214e-04\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6635e-04 - val_loss: 6.9127e-04\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8927e-04 - val_loss: 7.0237e-04\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0544e-04 - val_loss: 7.0060e-04\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0976e-04 - val_loss: 6.8389e-04\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0012e-04 - val_loss: 6.5287e-04\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7726e-04 - val_loss: 6.1038e-04\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4414e-04 - val_loss: 5.6058e-04\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0511e-04 - val_loss: 5.0804e-04\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6486e-04 - val_loss: 4.5699e-04\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2761e-04 - val_loss: 4.1063e-04\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9644e-04 - val_loss: 3.7086e-04\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7301e-04 - val_loss: 3.3824e-04\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5749e-04 - val_loss: 3.1221e-04\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4889e-04 - val_loss: 2.9145e-04\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4536e-04 - val_loss: 2.7431e-04\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4479e-04 - val_loss: 2.5919e-04\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4511e-04 - val_loss: 2.4488e-04\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4474e-04 - val_loss: 2.3067e-04\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4268e-04 - val_loss: 2.1640e-04\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3864e-04 - val_loss: 2.0238e-04\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3285e-04 - val_loss: 1.8919e-04\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2598e-04 - val_loss: 1.7754e-04\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1884e-04 - val_loss: 1.6801e-04\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1227e-04 - val_loss: 1.6098e-04\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0686e-04 - val_loss: 1.5649e-04\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0298e-04 - val_loss: 1.5430e-04\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0066e-04 - val_loss: 1.5394e-04\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9968e-04 - val_loss: 1.5476e-04\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9963e-04 - val_loss: 1.5608e-04\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0001e-04 - val_loss: 1.5727e-04\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0034e-04 - val_loss: 1.5786e-04\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0025e-04 - val_loss: 1.5756e-04\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 1.9950e-04 - val_loss: 1.5629e-04\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9800e-04 - val_loss: 1.5415e-04\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9583e-04 - val_loss: 1.5135e-04\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9316e-04 - val_loss: 1.4820e-04\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9021e-04 - val_loss: 1.4500e-04\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8722e-04 - val_loss: 1.4204e-04\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8438e-04 - val_loss: 1.3954e-04\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8182e-04 - val_loss: 1.3759e-04\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7960e-04 - val_loss: 1.3626e-04\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7771e-04 - val_loss: 1.3551e-04\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7609e-04 - val_loss: 1.3528e-04\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7465e-04 - val_loss: 1.3544e-04\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7328e-04 - val_loss: 1.3591e-04\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7190e-04 - val_loss: 1.3658e-04\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7046e-04 - val_loss: 1.3739e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6893e-04 - val_loss: 1.3828e-04\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6730e-04 - val_loss: 1.3921e-04\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6562e-04 - val_loss: 1.4019e-04\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6393e-04 - val_loss: 1.4118e-04\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6227e-04 - val_loss: 1.4219e-04\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.6068e-04 - val_loss: 1.4316e-04\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5919e-04 - val_loss: 1.4408e-04\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5781e-04 - val_loss: 1.4490e-04\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5652e-04 - val_loss: 1.4559e-04\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5532e-04 - val_loss: 1.4609e-04\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5418e-04 - val_loss: 1.4638e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5306e-04 - val_loss: 1.4644e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5196e-04 - val_loss: 1.4625e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5083e-04 - val_loss: 1.4581e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4969e-04 - val_loss: 1.4515e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4852e-04 - val_loss: 1.4429e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4734e-04 - val_loss: 1.4327e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4614e-04 - val_loss: 1.4212e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4495e-04 - val_loss: 1.4088e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4377e-04 - val_loss: 1.3956e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4262e-04 - val_loss: 1.3823e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4149e-04 - val_loss: 1.3688e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4038e-04 - val_loss: 1.3553e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3930e-04 - val_loss: 1.3419e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3822e-04 - val_loss: 1.3288e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3716e-04 - val_loss: 1.3159e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3611e-04 - val_loss: 1.3034e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3507e-04 - val_loss: 1.2912e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3402e-04 - val_loss: 1.2793e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3298e-04 - val_loss: 1.2678e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3194e-04 - val_loss: 1.2565e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.3091e-04 - val_loss: 1.2456e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2988e-04 - val_loss: 1.2350e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2887e-04 - val_loss: 1.2247e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2787e-04 - val_loss: 1.2146e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2689e-04 - val_loss: 1.2046e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2591e-04 - val_loss: 1.1947e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 1.2495e-04 - val_loss: 1.1850e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2400e-04 - val_loss: 1.1753e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2306e-04 - val_loss: 1.1656e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2213e-04 - val_loss: 1.1560e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2121e-04 - val_loss: 1.1463e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2029e-04 - val_loss: 1.1367e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1938e-04 - val_loss: 1.1272e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1848e-04 - val_loss: 1.1179e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1758e-04 - val_loss: 1.1086e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1670e-04 - val_loss: 1.0995e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1581e-04 - val_loss: 1.0906e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1494e-04 - val_loss: 1.0820e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 1.1408e-04 - val_loss: 1.0735e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1322e-04 - val_loss: 1.0654e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1237e-04 - val_loss: 1.0574e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 1.1153e-04 - val_loss: 1.0498e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1070e-04 - val_loss: 1.0425e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0987e-04 - val_loss: 1.0353e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0905e-04 - val_loss: 1.0285e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0824e-04 - val_loss: 1.0218e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0743e-04 - val_loss: 1.0152e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0663e-04 - val_loss: 1.0089e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0584e-04 - val_loss: 1.0027e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0505e-04 - val_loss: 9.9658e-05\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0427e-04 - val_loss: 9.9062e-05\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0349e-04 - val_loss: 9.8470e-05\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0273e-04 - val_loss: 9.7876e-05\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0196e-04 - val_loss: 9.7296e-05\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0121e-04 - val_loss: 9.6712e-05\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.0046e-04 - val_loss: 9.6127e-05\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9722e-05 - val_loss: 9.5533e-05\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8986e-05 - val_loss: 9.4950e-05\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8256e-05 - val_loss: 9.4360e-05\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7532e-05 - val_loss: 9.3780e-05\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6816e-05 - val_loss: 9.3188e-05\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6105e-05 - val_loss: 9.2598e-05\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.5399e-05 - val_loss: 9.2009e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4697e-05 - val_loss: 9.1420e-05\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4006e-05 - val_loss: 9.0832e-05\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3318e-05 - val_loss: 9.0248e-05\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2634e-05 - val_loss: 8.9666e-05\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1959e-05 - val_loss: 8.9083e-05\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1287e-05 - val_loss: 8.8503e-05\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0617e-05 - val_loss: 8.7935e-05\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9959e-05 - val_loss: 8.7365e-05\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9305e-05 - val_loss: 8.6800e-05\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8654e-05 - val_loss: 8.6234e-05\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 8.8008e-05 - val_loss: 8.5680e-05\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7371e-05 - val_loss: 8.5131e-05\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6736e-05 - val_loss: 8.4581e-05\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6107e-05 - val_loss: 8.4032e-05\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5483e-05 - val_loss: 8.3493e-05\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4865e-05 - val_loss: 8.2946e-05\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4248e-05 - val_loss: 8.2415e-05\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3640e-05 - val_loss: 8.1878e-05\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3034e-05 - val_loss: 8.1346e-05\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2437e-05 - val_loss: 8.0816e-05\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1843e-05 - val_loss: 8.0300e-05\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1253e-05 - val_loss: 7.9775e-05\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0665e-05 - val_loss: 7.9254e-05\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0087e-05 - val_loss: 7.8736e-05\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9512e-05 - val_loss: 7.8222e-05\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8941e-05 - val_loss: 7.7712e-05\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8373e-05 - val_loss: 7.7202e-05\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7811e-05 - val_loss: 7.6702e-05\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7254e-05 - val_loss: 7.6207e-05\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6699e-05 - val_loss: 7.5709e-05\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6148e-05 - val_loss: 7.5219e-05\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5605e-05 - val_loss: 7.4734e-05\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5066e-05 - val_loss: 7.4249e-05\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4527e-05 - val_loss: 7.3771e-05\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3998e-05 - val_loss: 7.3298e-05\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3470e-05 - val_loss: 7.2831e-05\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2946e-05 - val_loss: 7.2369e-05\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2429e-05 - val_loss: 7.1903e-05\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1912e-05 - val_loss: 7.1448e-05\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1402e-05 - val_loss: 7.0990e-05\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0894e-05 - val_loss: 7.0547e-05\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0390e-05 - val_loss: 7.0101e-05\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9891e-05 - val_loss: 6.9660e-05\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9395e-05 - val_loss: 6.9223e-05\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8902e-05 - val_loss: 6.8788e-05\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8415e-05 - val_loss: 6.8354e-05\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.7931e-05 - val_loss: 6.7926e-05\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7450e-05 - val_loss: 6.7500e-05\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6973e-05 - val_loss: 6.7084e-05\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6503e-05 - val_loss: 6.6661e-05\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6032e-05 - val_loss: 6.6251e-05\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5567e-05 - val_loss: 6.5835e-05\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5104e-05 - val_loss: 6.5425e-05\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4644e-05 - val_loss: 6.5022e-05\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.4192e-05 - val_loss: 6.4612e-05\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3740e-05 - val_loss: 6.4212e-05\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3290e-05 - val_loss: 6.3818e-05\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2848e-05 - val_loss: 6.3423e-05\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2407e-05 - val_loss: 6.3033e-05\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1970e-05 - val_loss: 6.2641e-05\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1534e-05 - val_loss: 6.2254e-05\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.1103e-05 - val_loss: 6.1876e-05\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0674e-05 - val_loss: 6.1491e-05\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 6.0249e-05 - val_loss: 6.1116e-05\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9831e-05 - val_loss: 6.0737e-05\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9412e-05 - val_loss: 6.0365e-05\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8998e-05 - val_loss: 5.9995e-05\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8583e-05 - val_loss: 5.9630e-05\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8175e-05 - val_loss: 5.9268e-05\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7773e-05 - val_loss: 5.8901e-05\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7368e-05 - val_loss: 5.8543e-05\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6969e-05 - val_loss: 5.8183e-05\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 5.6574e-05 - val_loss: 5.7833e-05\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6181e-05 - val_loss: 5.7479e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5791e-05 - val_loss: 5.7129e-05\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5403e-05 - val_loss: 5.6781e-05\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5019e-05 - val_loss: 5.6437e-05\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4636e-05 - val_loss: 5.6094e-05\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4257e-05 - val_loss: 5.5757e-05\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3882e-05 - val_loss: 5.5416e-05\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3510e-05 - val_loss: 5.5082e-05\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3141e-05 - val_loss: 5.4746e-05\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2772e-05 - val_loss: 5.4419e-05\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2408e-05 - val_loss: 5.4092e-05\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2045e-05 - val_loss: 5.3763e-05\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1686e-05 - val_loss: 5.3440e-05\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.1330e-05 - val_loss: 5.3117e-05\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0976e-05 - val_loss: 5.2796e-05\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0625e-05 - val_loss: 5.2481e-05\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 5.0277e-05 - val_loss: 5.2162e-05\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9928e-05 - val_loss: 5.1855e-05\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9588e-05 - val_loss: 5.1543e-05\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9248e-05 - val_loss: 5.1231e-05\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.8908e-05 - val_loss: 5.0929e-05\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.8574e-05 - val_loss: 5.0624e-05\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8241e-05 - val_loss: 5.0322e-05\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7909e-05 - val_loss: 5.0023e-05\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7581e-05 - val_loss: 4.9727e-05\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7256e-05 - val_loss: 4.9432e-05\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6932e-05 - val_loss: 4.9140e-05\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6612e-05 - val_loss: 4.8845e-05\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6292e-05 - val_loss: 4.8555e-05\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5978e-05 - val_loss: 4.8268e-05\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5665e-05 - val_loss: 4.7982e-05\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5351e-05 - val_loss: 4.7699e-05\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5041e-05 - val_loss: 4.7421e-05\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4735e-05 - val_loss: 4.7140e-05\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4430e-05 - val_loss: 4.6862e-05\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4127e-05 - val_loss: 4.6585e-05\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3828e-05 - val_loss: 4.6311e-05\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3529e-05 - val_loss: 4.6039e-05\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3235e-05 - val_loss: 4.5773e-05\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2941e-05 - val_loss: 4.5501e-05\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2649e-05 - val_loss: 4.5235e-05\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2359e-05 - val_loss: 4.4972e-05\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2071e-05 - val_loss: 4.4709e-05\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1789e-05 - val_loss: 4.4446e-05\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1505e-05 - val_loss: 4.4190e-05\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1225e-05 - val_loss: 4.3931e-05\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0945e-05 - val_loss: 4.3677e-05\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0669e-05 - val_loss: 4.3422e-05\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 4.0393e-05 - val_loss: 4.3172e-05\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0121e-05 - val_loss: 4.2923e-05\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9850e-05 - val_loss: 4.2671e-05\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9582e-05 - val_loss: 4.2425e-05\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9314e-05 - val_loss: 4.2181e-05\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9050e-05 - val_loss: 4.1941e-05\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8788e-05 - val_loss: 4.1699e-05\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8527e-05 - val_loss: 4.1458e-05\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8268e-05 - val_loss: 4.1219e-05\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8009e-05 - val_loss: 4.0983e-05\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7755e-05 - val_loss: 4.0747e-05\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7500e-05 - val_loss: 4.0514e-05\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7251e-05 - val_loss: 4.0282e-05\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7001e-05 - val_loss: 4.0051e-05\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6752e-05 - val_loss: 3.9823e-05\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6506e-05 - val_loss: 3.9596e-05\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6264e-05 - val_loss: 3.9372e-05\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6020e-05 - val_loss: 3.9144e-05\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5778e-05 - val_loss: 3.8919e-05\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.5538e-05 - val_loss: 3.8700e-05\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5303e-05 - val_loss: 3.8478e-05\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5068e-05 - val_loss: 3.8263e-05\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4834e-05 - val_loss: 3.8043e-05\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4601e-05 - val_loss: 3.7828e-05\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4372e-05 - val_loss: 3.7618e-05\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4141e-05 - val_loss: 3.7403e-05\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3915e-05 - val_loss: 3.7196e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3690e-05 - val_loss: 3.6981e-05\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3466e-05 - val_loss: 3.6775e-05\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3243e-05 - val_loss: 3.6569e-05\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3024e-05 - val_loss: 3.6361e-05\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2803e-05 - val_loss: 3.6160e-05\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 3.2587e-05 - val_loss: 3.5955e-05\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 3.2371e-05 - val_loss: 3.5753e-05\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2156e-05 - val_loss: 3.5554e-05\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1943e-05 - val_loss: 3.5357e-05\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 3.1733e-05 - val_loss: 3.5160e-05\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1524e-05 - val_loss: 3.4963e-05\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1316e-05 - val_loss: 3.4772e-05\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1109e-05 - val_loss: 3.4576e-05\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0904e-05 - val_loss: 3.4383e-05\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 3.0700e-05 - val_loss: 3.4192e-05\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0497e-05 - val_loss: 3.4003e-05\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0297e-05 - val_loss: 3.3815e-05\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0097e-05 - val_loss: 3.3627e-05\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9899e-05 - val_loss: 3.3443e-05\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9703e-05 - val_loss: 3.3258e-05\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9509e-05 - val_loss: 3.3072e-05\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9313e-05 - val_loss: 3.2894e-05\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.9123e-05 - val_loss: 3.2713e-05\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8933e-05 - val_loss: 3.2534e-05\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8743e-05 - val_loss: 3.2353e-05\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8556e-05 - val_loss: 3.2177e-05\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8368e-05 - val_loss: 3.2002e-05\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8183e-05 - val_loss: 3.1828e-05\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7998e-05 - val_loss: 3.1654e-05\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7815e-05 - val_loss: 3.1479e-05\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7634e-05 - val_loss: 3.1307e-05\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7453e-05 - val_loss: 3.1138e-05\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7276e-05 - val_loss: 3.0969e-05\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 2.7098e-05 - val_loss: 3.0801e-05\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6923e-05 - val_loss: 3.0635e-05\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6747e-05 - val_loss: 3.0466e-05\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 2.6572e-05 - val_loss: 3.0304e-05\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6401e-05 - val_loss: 3.0140e-05\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6230e-05 - val_loss: 2.9977e-05\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6059e-05 - val_loss: 2.9816e-05\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.5892e-05 - val_loss: 2.9654e-05\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5722e-05 - val_loss: 2.9497e-05\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5557e-05 - val_loss: 2.9343e-05\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5393e-05 - val_loss: 2.9185e-05\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5227e-05 - val_loss: 2.9024e-05\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5064e-05 - val_loss: 2.8870e-05\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4903e-05 - val_loss: 2.8716e-05\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4743e-05 - val_loss: 2.8561e-05\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4583e-05 - val_loss: 2.8410e-05\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4426e-05 - val_loss: 2.8258e-05\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4267e-05 - val_loss: 2.8110e-05\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4113e-05 - val_loss: 2.7963e-05\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3956e-05 - val_loss: 2.7812e-05\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3804e-05 - val_loss: 2.7665e-05\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3651e-05 - val_loss: 2.7517e-05\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3499e-05 - val_loss: 2.7374e-05\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 2.3350e-05 - val_loss: 2.7228e-05\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3200e-05 - val_loss: 2.7087e-05\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3053e-05 - val_loss: 2.6943e-05\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 2.2904e-05 - val_loss: 2.6800e-05\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2758e-05 - val_loss: 2.6661e-05\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2613e-05 - val_loss: 2.6517e-05\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2468e-05 - val_loss: 2.6382e-05\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2327e-05 - val_loss: 2.6245e-05\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2184e-05 - val_loss: 2.6106e-05\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2043e-05 - val_loss: 2.5972e-05\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1902e-05 - val_loss: 2.5838e-05\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1764e-05 - val_loss: 2.5705e-05\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1625e-05 - val_loss: 2.5571e-05\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1488e-05 - val_loss: 2.5438e-05\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1353e-05 - val_loss: 2.5305e-05\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1218e-05 - val_loss: 2.5173e-05\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1083e-05 - val_loss: 2.5045e-05\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0951e-05 - val_loss: 2.4915e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0817e-05 - val_loss: 2.4788e-05\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0688e-05 - val_loss: 2.4658e-05\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0556e-05 - val_loss: 2.4532e-05\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0427e-05 - val_loss: 2.4408e-05\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0299e-05 - val_loss: 2.4283e-05\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0170e-05 - val_loss: 2.4160e-05\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0045e-05 - val_loss: 2.4034e-05\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9919e-05 - val_loss: 2.3914e-05\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9793e-05 - val_loss: 2.3791e-05\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9670e-05 - val_loss: 2.3674e-05\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9547e-05 - val_loss: 2.3549e-05\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 1.9425e-05 - val_loss: 2.3429e-05\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9303e-05 - val_loss: 2.3313e-05\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9183e-05 - val_loss: 2.3196e-05\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9065e-05 - val_loss: 2.3076e-05\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8944e-05 - val_loss: 2.2961e-05\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8827e-05 - val_loss: 2.2846e-05\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 1.8710e-05 - val_loss: 2.2730e-05\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8593e-05 - val_loss: 2.2617e-05\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8479e-05 - val_loss: 2.2503e-05\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8363e-05 - val_loss: 2.2391e-05\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8250e-05 - val_loss: 2.2276e-05\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8136e-05 - val_loss: 2.2167e-05\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8026e-05 - val_loss: 2.2058e-05\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7913e-05 - val_loss: 2.1950e-05\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7802e-05 - val_loss: 2.1839e-05\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 1.7693e-05 - val_loss: 2.1731e-05\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7584e-05 - val_loss: 2.1623e-05\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7476e-05 - val_loss: 2.1516e-05\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7369e-05 - val_loss: 2.1411e-05\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7263e-05 - val_loss: 2.1305e-05\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7156e-05 - val_loss: 2.1200e-05\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7052e-05 - val_loss: 2.1096e-05\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6947e-05 - val_loss: 2.0993e-05\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6844e-05 - val_loss: 2.0888e-05\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6741e-05 - val_loss: 2.0785e-05\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6638e-05 - val_loss: 2.0686e-05\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6537e-05 - val_loss: 2.0585e-05\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6437e-05 - val_loss: 2.0486e-05\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6337e-05 - val_loss: 2.0384e-05\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6237e-05 - val_loss: 2.0287e-05\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6139e-05 - val_loss: 2.0186e-05\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6040e-05 - val_loss: 2.0092e-05\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 1.5943e-05 - val_loss: 1.9996e-05\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5849e-05 - val_loss: 1.9901e-05\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5752e-05 - val_loss: 1.9803e-05\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5658e-05 - val_loss: 1.9709e-05\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5562e-05 - val_loss: 1.9613e-05\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5468e-05 - val_loss: 1.9518e-05\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5376e-05 - val_loss: 1.9424e-05\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5283e-05 - val_loss: 1.9331e-05\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5192e-05 - val_loss: 1.9238e-05\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5100e-05 - val_loss: 1.9148e-05\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5010e-05 - val_loss: 1.9056e-05\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4920e-05 - val_loss: 1.8966e-05\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4831e-05 - val_loss: 1.8880e-05\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4743e-05 - val_loss: 1.8789e-05\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4656e-05 - val_loss: 1.8698e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.4567e-05 - val_loss: 1.8612e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4481e-05 - val_loss: 1.8525e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4395e-05 - val_loss: 1.8439e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4310e-05 - val_loss: 1.8351e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4225e-05 - val_loss: 1.8266e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4142e-05 - val_loss: 1.8182e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4058e-05 - val_loss: 1.8095e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3975e-05 - val_loss: 1.8012e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3892e-05 - val_loss: 1.7929e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3811e-05 - val_loss: 1.7845e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3730e-05 - val_loss: 1.7763e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3649e-05 - val_loss: 1.7681e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3569e-05 - val_loss: 1.7599e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3489e-05 - val_loss: 1.7518e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3411e-05 - val_loss: 1.7437e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3332e-05 - val_loss: 1.7356e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3254e-05 - val_loss: 1.7280e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3178e-05 - val_loss: 1.7198e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3100e-05 - val_loss: 1.7121e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3024e-05 - val_loss: 1.7044e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2950e-05 - val_loss: 1.6965e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2874e-05 - val_loss: 1.6889e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2800e-05 - val_loss: 1.6810e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2726e-05 - val_loss: 1.6736e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2653e-05 - val_loss: 1.6662e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2580e-05 - val_loss: 1.6587e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2507e-05 - val_loss: 1.6511e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2435e-05 - val_loss: 1.6438e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2365e-05 - val_loss: 1.6365e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2294e-05 - val_loss: 1.6291e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2224e-05 - val_loss: 1.6216e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 1.2154e-05 - val_loss: 1.6145e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2084e-05 - val_loss: 1.6075e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2016e-05 - val_loss: 1.6003e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1948e-05 - val_loss: 1.5933e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1880e-05 - val_loss: 1.5862e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1812e-05 - val_loss: 1.5792e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1746e-05 - val_loss: 1.5724e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1679e-05 - val_loss: 1.5655e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 1.1614e-05 - val_loss: 1.5584e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1548e-05 - val_loss: 1.5518e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1485e-05 - val_loss: 1.5449e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1418e-05 - val_loss: 1.5382e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1354e-05 - val_loss: 1.5315e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1291e-05 - val_loss: 1.5248e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1228e-05 - val_loss: 1.5182e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1166e-05 - val_loss: 1.5117e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1103e-05 - val_loss: 1.5054e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1042e-05 - val_loss: 1.4988e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0981e-05 - val_loss: 1.4923e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0920e-05 - val_loss: 1.4861e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0861e-05 - val_loss: 1.4795e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0800e-05 - val_loss: 1.4733e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0740e-05 - val_loss: 1.4668e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0681e-05 - val_loss: 1.4606e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0622e-05 - val_loss: 1.4545e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0564e-05 - val_loss: 1.4484e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0506e-05 - val_loss: 1.4423e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0449e-05 - val_loss: 1.4361e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0391e-05 - val_loss: 1.4302e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0336e-05 - val_loss: 1.4241e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0278e-05 - val_loss: 1.4181e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0224e-05 - val_loss: 1.4123e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0168e-05 - val_loss: 1.4065e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0113e-05 - val_loss: 1.4007e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0059e-05 - val_loss: 1.3947e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0004e-05 - val_loss: 1.3891e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9509e-06 - val_loss: 1.3834e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8987e-06 - val_loss: 1.3777e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8448e-06 - val_loss: 1.3719e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 9.7920e-06 - val_loss: 1.3663e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7396e-06 - val_loss: 1.3608e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6878e-06 - val_loss: 1.3553e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6371e-06 - val_loss: 1.3495e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5851e-06 - val_loss: 1.3443e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5352e-06 - val_loss: 1.3389e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4847e-06 - val_loss: 1.3334e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4344e-06 - val_loss: 1.3280e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3851e-06 - val_loss: 1.3226e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3355e-06 - val_loss: 1.3172e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2869e-06 - val_loss: 1.3120e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2382e-06 - val_loss: 1.3068e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 9.1906e-06 - val_loss: 1.3016e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1429e-06 - val_loss: 1.2963e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0941e-06 - val_loss: 1.2913e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0472e-06 - val_loss: 1.2861e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0005e-06 - val_loss: 1.2811e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9550e-06 - val_loss: 1.2759e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9084e-06 - val_loss: 1.2708e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8627e-06 - val_loss: 1.2659e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8169e-06 - val_loss: 1.2610e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7715e-06 - val_loss: 1.2561e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7279e-06 - val_loss: 1.2511e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6831e-06 - val_loss: 1.2464e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6386e-06 - val_loss: 1.2414e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5949e-06 - val_loss: 1.2366e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5515e-06 - val_loss: 1.2318e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5080e-06 - val_loss: 1.2272e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4654e-06 - val_loss: 1.2224e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4230e-06 - val_loss: 1.2177e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3803e-06 - val_loss: 1.2133e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3394e-06 - val_loss: 1.2087e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2972e-06 - val_loss: 1.2039e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 8.2560e-06 - val_loss: 1.1994e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2147e-06 - val_loss: 1.1948e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1743e-06 - val_loss: 1.1903e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 8.1338e-06 - val_loss: 1.1855e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0926e-06 - val_loss: 1.1813e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0543e-06 - val_loss: 1.1771e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0147e-06 - val_loss: 1.1724e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9747e-06 - val_loss: 1.1682e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9354e-06 - val_loss: 1.1637e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8977e-06 - val_loss: 1.1595e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8597e-06 - val_loss: 1.1552e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8210e-06 - val_loss: 1.1509e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7833e-06 - val_loss: 1.1466e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7446e-06 - val_loss: 1.1424e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7086e-06 - val_loss: 1.1382e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6713e-06 - val_loss: 1.1340e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6347e-06 - val_loss: 1.1301e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5979e-06 - val_loss: 1.1260e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5621e-06 - val_loss: 1.1218e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5259e-06 - val_loss: 1.1178e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4903e-06 - val_loss: 1.1138e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 7.4555e-06 - val_loss: 1.1097e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4200e-06 - val_loss: 1.1057e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 7.3845e-06 - val_loss: 1.1019e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3506e-06 - val_loss: 1.0978e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3161e-06 - val_loss: 1.0940e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2817e-06 - val_loss: 1.0900e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 7.2473e-06 - val_loss: 1.0863e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2140e-06 - val_loss: 1.0825e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1805e-06 - val_loss: 1.0787e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1485e-06 - val_loss: 1.0747e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1148e-06 - val_loss: 1.0710e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0821e-06 - val_loss: 1.0675e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0499e-06 - val_loss: 1.0636e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0178e-06 - val_loss: 1.0599e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9860e-06 - val_loss: 1.0564e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9546e-06 - val_loss: 1.0526e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9227e-06 - val_loss: 1.0491e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8918e-06 - val_loss: 1.0454e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8606e-06 - val_loss: 1.0420e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8307e-06 - val_loss: 1.0383e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7990e-06 - val_loss: 1.0346e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7688e-06 - val_loss: 1.0313e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7387e-06 - val_loss: 1.0278e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7091e-06 - val_loss: 1.0244e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6797e-06 - val_loss: 1.0208e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6497e-06 - val_loss: 1.0174e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6204e-06 - val_loss: 1.0141e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5919e-06 - val_loss: 1.0108e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5631e-06 - val_loss: 1.0074e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5346e-06 - val_loss: 1.0040e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5069e-06 - val_loss: 1.0008e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4780e-06 - val_loss: 9.9745e-06\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.4504e-06 - val_loss: 9.9426e-06\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4225e-06 - val_loss: 9.9089e-06\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3958e-06 - val_loss: 9.8768e-06\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3679e-06 - val_loss: 9.8441e-06\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 6.3408e-06 - val_loss: 9.8135e-06\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.3133e-06 - val_loss: 9.7808e-06\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2868e-06 - val_loss: 9.7514e-06\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2606e-06 - val_loss: 9.7174e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2343e-06 - val_loss: 9.6884e-06\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 6.2085e-06 - val_loss: 9.6541e-06\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1819e-06 - val_loss: 9.6250e-06\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1564e-06 - val_loss: 9.5935e-06\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1313e-06 - val_loss: 9.5634e-06\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1054e-06 - val_loss: 9.5342e-06\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0811e-06 - val_loss: 9.5044e-06\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 6.0555e-06 - val_loss: 9.4748e-06\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0310e-06 - val_loss: 9.4455e-06\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0062e-06 - val_loss: 9.4149e-06\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9811e-06 - val_loss: 9.3860e-06\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 5.9580e-06 - val_loss: 9.3569e-06\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.9343e-06 - val_loss: 9.3293e-06\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9101e-06 - val_loss: 9.3002e-06\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.8863e-06 - val_loss: 9.2714e-06\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8626e-06 - val_loss: 9.2421e-06\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8394e-06 - val_loss: 9.2139e-06\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8157e-06 - val_loss: 9.1863e-06\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7929e-06 - val_loss: 9.1595e-06\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.7706e-06 - val_loss: 9.1318e-06\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7483e-06 - val_loss: 9.1043e-06\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7256e-06 - val_loss: 9.0763e-06\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7033e-06 - val_loss: 9.0477e-06\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6809e-06 - val_loss: 9.0200e-06\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6589e-06 - val_loss: 8.9966e-06\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6372e-06 - val_loss: 8.9669e-06\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6152e-06 - val_loss: 8.9418e-06\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5942e-06 - val_loss: 8.9158e-06\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5731e-06 - val_loss: 8.8894e-06\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.5522e-06 - val_loss: 8.8629e-06\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5309e-06 - val_loss: 8.8357e-06\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5092e-06 - val_loss: 8.8132e-06\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4893e-06 - val_loss: 8.7862e-06\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4688e-06 - val_loss: 8.7604e-06\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.4482e-06 - val_loss: 8.7360e-06\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4277e-06 - val_loss: 8.7097e-06\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.4078e-06 - val_loss: 8.6857e-06\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3885e-06 - val_loss: 8.6623e-06\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3687e-06 - val_loss: 8.6366e-06\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3486e-06 - val_loss: 8.6115e-06\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3292e-06 - val_loss: 8.5862e-06\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3095e-06 - val_loss: 8.5639e-06\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2913e-06 - val_loss: 8.5401e-06\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2717e-06 - val_loss: 8.5142e-06\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.2527e-06 - val_loss: 8.4907e-06\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2343e-06 - val_loss: 8.4679e-06\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2150e-06 - val_loss: 8.4445e-06\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1975e-06 - val_loss: 8.4211e-06\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1785e-06 - val_loss: 8.3982e-06\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1607e-06 - val_loss: 8.3745e-06\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1420e-06 - val_loss: 8.3524e-06\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1248e-06 - val_loss: 8.3297e-06\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1064e-06 - val_loss: 8.3060e-06\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0891e-06 - val_loss: 8.2855e-06\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.0718e-06 - val_loss: 8.2631e-06\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.0546e-06 - val_loss: 8.2413e-06\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0369e-06 - val_loss: 8.2181e-06\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0199e-06 - val_loss: 8.1970e-06\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0033e-06 - val_loss: 8.1750e-06\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.9859e-06 - val_loss: 8.1516e-06\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.9694e-06 - val_loss: 8.1307e-06\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9524e-06 - val_loss: 8.1092e-06\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 4.9367e-06 - val_loss: 8.0897e-06\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9205e-06 - val_loss: 8.0673e-06\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9041e-06 - val_loss: 8.0474e-06\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8877e-06 - val_loss: 8.0265e-06\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8718e-06 - val_loss: 8.0036e-06\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8555e-06 - val_loss: 7.9848e-06\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 4.8402e-06 - val_loss: 7.9634e-06\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8241e-06 - val_loss: 7.9422e-06\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8093e-06 - val_loss: 7.9220e-06\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7935e-06 - val_loss: 7.9022e-06\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7783e-06 - val_loss: 7.8834e-06\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7631e-06 - val_loss: 7.8642e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7485e-06 - val_loss: 7.8447e-06\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7333e-06 - val_loss: 7.8249e-06\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7187e-06 - val_loss: 7.8063e-06\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 4.7046e-06 - val_loss: 7.7868e-06\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6894e-06 - val_loss: 7.7657e-06\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6745e-06 - val_loss: 7.7503e-06\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6610e-06 - val_loss: 7.7278e-06\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6457e-06 - val_loss: 7.7070e-06\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6327e-06 - val_loss: 7.6902e-06\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6182e-06 - val_loss: 7.6720e-06\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6046e-06 - val_loss: 7.6553e-06\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5911e-06 - val_loss: 7.6362e-06\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5770e-06 - val_loss: 7.6169e-06\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5632e-06 - val_loss: 7.5991e-06\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5498e-06 - val_loss: 7.5809e-06\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5365e-06 - val_loss: 7.5635e-06\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5231e-06 - val_loss: 7.5443e-06\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5098e-06 - val_loss: 7.5282e-06\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4971e-06 - val_loss: 7.5103e-06\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4842e-06 - val_loss: 7.4914e-06\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4710e-06 - val_loss: 7.4747e-06\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.4582e-06 - val_loss: 7.4556e-06\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4451e-06 - val_loss: 7.4400e-06\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4330e-06 - val_loss: 7.4214e-06\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4206e-06 - val_loss: 7.4058e-06\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4083e-06 - val_loss: 7.3864e-06\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3958e-06 - val_loss: 7.3700e-06\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 177us/step - loss: 4.3836e-06 - val_loss: 7.3538e-06\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3709e-06 - val_loss: 7.3377e-06\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 4.3596e-06 - val_loss: 7.3213e-06\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3471e-06 - val_loss: 7.3063e-06\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3357e-06 - val_loss: 7.2883e-06\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3242e-06 - val_loss: 7.2722e-06\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3124e-06 - val_loss: 7.2559e-06\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3005e-06 - val_loss: 7.2397e-06\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2894e-06 - val_loss: 7.2255e-06\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2783e-06 - val_loss: 7.2084e-06\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2664e-06 - val_loss: 7.1909e-06\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2556e-06 - val_loss: 7.1772e-06\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2443e-06 - val_loss: 7.1615e-06\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2330e-06 - val_loss: 7.1457e-06\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2226e-06 - val_loss: 7.1307e-06\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2113e-06 - val_loss: 7.1168e-06\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2007e-06 - val_loss: 7.1005e-06\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1897e-06 - val_loss: 7.0862e-06\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1796e-06 - val_loss: 7.0723e-06\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1692e-06 - val_loss: 7.0576e-06\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1586e-06 - val_loss: 7.0400e-06\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1481e-06 - val_loss: 7.0276e-06\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1379e-06 - val_loss: 7.0136e-06\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1278e-06 - val_loss: 6.9963e-06\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1170e-06 - val_loss: 6.9830e-06\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1075e-06 - val_loss: 6.9674e-06\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.0974e-06 - val_loss: 6.9535e-06\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0874e-06 - val_loss: 6.9402e-06\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0779e-06 - val_loss: 6.9242e-06\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0675e-06 - val_loss: 6.9102e-06\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0583e-06 - val_loss: 6.8973e-06\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0480e-06 - val_loss: 6.8832e-06\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0389e-06 - val_loss: 6.8701e-06\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0296e-06 - val_loss: 6.8553e-06\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0202e-06 - val_loss: 6.8408e-06\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0101e-06 - val_loss: 6.8275e-06\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0017e-06 - val_loss: 6.8172e-06\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9926e-06 - val_loss: 6.8036e-06\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9834e-06 - val_loss: 6.7859e-06\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9735e-06 - val_loss: 6.7755e-06\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9653e-06 - val_loss: 6.7615e-06\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9568e-06 - val_loss: 6.7490e-06\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9481e-06 - val_loss: 6.7360e-06\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9396e-06 - val_loss: 6.7237e-06\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9306e-06 - val_loss: 6.7099e-06\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9217e-06 - val_loss: 6.6972e-06\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9131e-06 - val_loss: 6.6846e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9046e-06 - val_loss: 6.6705e-06\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8959e-06 - val_loss: 6.6605e-06\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8879e-06 - val_loss: 6.6470e-06\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8792e-06 - val_loss: 6.6353e-06\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8712e-06 - val_loss: 6.6223e-06\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8631e-06 - val_loss: 6.6112e-06\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.8554e-06 - val_loss: 6.5972e-06\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.8471e-06 - val_loss: 6.5864e-06\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8396e-06 - val_loss: 6.5740e-06\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8314e-06 - val_loss: 6.5627e-06\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8240e-06 - val_loss: 6.5502e-06\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8158e-06 - val_loss: 6.5379e-06\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8080e-06 - val_loss: 6.5265e-06\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8007e-06 - val_loss: 6.5134e-06\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7928e-06 - val_loss: 6.5031e-06\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.7854e-06 - val_loss: 6.4915e-06\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7778e-06 - val_loss: 6.4807e-06\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7700e-06 - val_loss: 6.4682e-06\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7631e-06 - val_loss: 6.4587e-06\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7559e-06 - val_loss: 6.4473e-06\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7484e-06 - val_loss: 6.4353e-06\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7416e-06 - val_loss: 6.4253e-06\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7343e-06 - val_loss: 6.4131e-06\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.7272e-06 - val_loss: 6.4019e-06\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7204e-06 - val_loss: 6.3914e-06\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7133e-06 - val_loss: 6.3816e-06\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7063e-06 - val_loss: 6.3694e-06\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6996e-06 - val_loss: 6.3571e-06\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6921e-06 - val_loss: 6.3479e-06\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6862e-06 - val_loss: 6.3372e-06\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6788e-06 - val_loss: 6.3260e-06\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6724e-06 - val_loss: 6.3168e-06\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6660e-06 - val_loss: 6.3062e-06\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6596e-06 - val_loss: 6.2939e-06\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6529e-06 - val_loss: 6.2832e-06\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6463e-06 - val_loss: 6.2761e-06\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6403e-06 - val_loss: 6.2643e-06\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6337e-06 - val_loss: 6.2552e-06\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6274e-06 - val_loss: 6.2455e-06\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6212e-06 - val_loss: 6.2359e-06\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6153e-06 - val_loss: 6.2245e-06\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6085e-06 - val_loss: 6.2148e-06\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6028e-06 - val_loss: 6.2057e-06\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5970e-06 - val_loss: 6.1934e-06\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5903e-06 - val_loss: 6.1838e-06\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.5846e-06 - val_loss: 6.1741e-06\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5789e-06 - val_loss: 6.1650e-06\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5728e-06 - val_loss: 6.1555e-06\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5672e-06 - val_loss: 6.1457e-06\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5611e-06 - val_loss: 6.1368e-06\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5555e-06 - val_loss: 6.1276e-06\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5497e-06 - val_loss: 6.1188e-06\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5443e-06 - val_loss: 6.1095e-06\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5386e-06 - val_loss: 6.1009e-06\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5331e-06 - val_loss: 6.0925e-06\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5276e-06 - val_loss: 6.0814e-06\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5220e-06 - val_loss: 6.0717e-06\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5168e-06 - val_loss: 6.0632e-06\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5115e-06 - val_loss: 6.0556e-06\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.5060e-06 - val_loss: 6.0455e-06\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5006e-06 - val_loss: 6.0363e-06\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4955e-06 - val_loss: 6.0282e-06\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4905e-06 - val_loss: 6.0188e-06\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4847e-06 - val_loss: 6.0093e-06\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4797e-06 - val_loss: 6.0010e-06\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4753e-06 - val_loss: 5.9912e-06\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4692e-06 - val_loss: 5.9839e-06\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4649e-06 - val_loss: 5.9753e-06\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4599e-06 - val_loss: 5.9672e-06\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4550e-06 - val_loss: 5.9587e-06\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4501e-06 - val_loss: 5.9505e-06\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4450e-06 - val_loss: 5.9428e-06\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4404e-06 - val_loss: 5.9328e-06\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4353e-06 - val_loss: 5.9255e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4311e-06 - val_loss: 5.9190e-06\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4261e-06 - val_loss: 5.9091e-06\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4217e-06 - val_loss: 5.9008e-06\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4168e-06 - val_loss: 5.8932e-06\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4122e-06 - val_loss: 5.8857e-06\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4075e-06 - val_loss: 5.8776e-06\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4036e-06 - val_loss: 5.8698e-06\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3986e-06 - val_loss: 5.8620e-06\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3946e-06 - val_loss: 5.8552e-06\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3900e-06 - val_loss: 5.8458e-06\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3857e-06 - val_loss: 5.8375e-06\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3813e-06 - val_loss: 5.8305e-06\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3772e-06 - val_loss: 5.8229e-06\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3730e-06 - val_loss: 5.8135e-06\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3685e-06 - val_loss: 5.8076e-06\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3642e-06 - val_loss: 5.7998e-06\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3603e-06 - val_loss: 5.7912e-06\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3555e-06 - val_loss: 5.7833e-06\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3515e-06 - val_loss: 5.7783e-06\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3476e-06 - val_loss: 5.7707e-06\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3439e-06 - val_loss: 5.7641e-06\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3397e-06 - val_loss: 5.7561e-06\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3356e-06 - val_loss: 5.7490e-06\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3316e-06 - val_loss: 5.7423e-06\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3277e-06 - val_loss: 5.7355e-06\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3240e-06 - val_loss: 5.7266e-06\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3202e-06 - val_loss: 5.7216e-06\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3167e-06 - val_loss: 5.7147e-06\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3128e-06 - val_loss: 5.7050e-06\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3083e-06 - val_loss: 5.6983e-06\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3053e-06 - val_loss: 5.6910e-06\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3009e-06 - val_loss: 5.6844e-06\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2975e-06 - val_loss: 5.6790e-06\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2939e-06 - val_loss: 5.6712e-06\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2905e-06 - val_loss: 5.6647e-06\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2865e-06 - val_loss: 5.6577e-06\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2829e-06 - val_loss: 5.6520e-06\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2797e-06 - val_loss: 5.6460e-06\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2763e-06 - val_loss: 5.6395e-06\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2729e-06 - val_loss: 5.6317e-06\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2691e-06 - val_loss: 5.6249e-06\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2651e-06 - val_loss: 5.6191e-06\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2619e-06 - val_loss: 5.6137e-06\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2591e-06 - val_loss: 5.6062e-06\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2553e-06 - val_loss: 5.6002e-06\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2525e-06 - val_loss: 5.5951e-06\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2491e-06 - val_loss: 5.5874e-06\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 185us/step - loss: 3.2451e-06 - val_loss: 5.5817e-06\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2425e-06 - val_loss: 5.5750e-06\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2391e-06 - val_loss: 5.5674e-06\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2358e-06 - val_loss: 5.5625e-06\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2327e-06 - val_loss: 5.5552e-06\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.2298e-06 - val_loss: 5.5496e-06\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2264e-06 - val_loss: 5.5422e-06\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2235e-06 - val_loss: 5.5379e-06\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2208e-06 - val_loss: 5.5294e-06\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2173e-06 - val_loss: 5.5257e-06\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2144e-06 - val_loss: 5.5192e-06\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2111e-06 - val_loss: 5.5126e-06\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2080e-06 - val_loss: 5.5075e-06\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2054e-06 - val_loss: 5.5034e-06\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2024e-06 - val_loss: 5.4977e-06\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1993e-06 - val_loss: 5.4907e-06\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 3.1961e-06 - val_loss: 5.4859e-06\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1939e-06 - val_loss: 5.4795e-06\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1907e-06 - val_loss: 5.4735e-06\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1879e-06 - val_loss: 5.4692e-06\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1853e-06 - val_loss: 5.4619e-06\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1826e-06 - val_loss: 5.4561e-06\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1798e-06 - val_loss: 5.4500e-06\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1771e-06 - val_loss: 5.4442e-06\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1741e-06 - val_loss: 5.4384e-06\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1710e-06 - val_loss: 5.4353e-06\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1691e-06 - val_loss: 5.4308e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1662e-06 - val_loss: 5.4229e-06\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 3.1633e-06 - val_loss: 5.4174e-06\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1608e-06 - val_loss: 5.4139e-06\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 3.1585e-06 - val_loss: 5.4063e-06\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1554e-06 - val_loss: 5.4002e-06\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1529e-06 - val_loss: 5.3969e-06\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1507e-06 - val_loss: 5.3913e-06\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1483e-06 - val_loss: 5.3869e-06\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1458e-06 - val_loss: 5.3804e-06\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1434e-06 - val_loss: 5.3747e-06\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1411e-06 - val_loss: 5.3709e-06\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1386e-06 - val_loss: 5.3652e-06\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1359e-06 - val_loss: 5.3606e-06\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1336e-06 - val_loss: 5.3559e-06\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1314e-06 - val_loss: 5.3495e-06\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1282e-06 - val_loss: 5.3467e-06\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1266e-06 - val_loss: 5.3399e-06\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1238e-06 - val_loss: 5.3359e-06\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1217e-06 - val_loss: 5.3296e-06\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1193e-06 - val_loss: 5.3269e-06\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1169e-06 - val_loss: 5.3226e-06\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.1156e-06 - val_loss: 5.3168e-06\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1127e-06 - val_loss: 5.3128e-06\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1107e-06 - val_loss: 5.3080e-06\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1084e-06 - val_loss: 5.3019e-06\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1060e-06 - val_loss: 5.2973e-06\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1038e-06 - val_loss: 5.2928e-06\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1016e-06 - val_loss: 5.2894e-06\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0999e-06 - val_loss: 5.2836e-06\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0977e-06 - val_loss: 5.2777e-06\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 3.0957e-06 - val_loss: 5.2731e-06\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0932e-06 - val_loss: 5.2697e-06\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0916e-06 - val_loss: 5.2635e-06\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0890e-06 - val_loss: 5.2588e-06\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0874e-06 - val_loss: 5.2537e-06\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0848e-06 - val_loss: 5.2513e-06\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0835e-06 - val_loss: 5.2459e-06\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0812e-06 - val_loss: 5.2418e-06\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0793e-06 - val_loss: 5.2379e-06\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0774e-06 - val_loss: 5.2335e-06\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0747e-06 - val_loss: 5.2303e-06\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0731e-06 - val_loss: 5.2248e-06\n",
      "6.716753432556288e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 9.7789073e-01,  3.1077614e-01,  1.3600473e+00,  3.9376128e-01,\n",
       "         -1.6442481e+00],\n",
       "        [-1.3262837e+00,  1.1190797e-03, -1.2166705e+00, -5.9596807e-01,\n",
       "          1.3270082e+00],\n",
       "        [ 1.2231700e+00,  2.3895773e-01,  4.0979668e-01, -1.0308958e+00,\n",
       "         -7.9593438e-01]], dtype=float32),\n",
       " array([ 0.9002875 , -0.52949697,  0.74071836,  0.16111636,  0.97127897],\n",
       "       dtype=float32),\n",
       " array([[ 0.90178114,  0.6115592 , -1.3764067 , -0.10063545, -1.3784319 ,\n",
       "          0.5929576 , -1.2537191 ,  0.6695224 , -0.48759633, -0.4865871 ],\n",
       "        [ 0.3886523 ,  0.31567824, -1.2302135 , -0.9934611 , -0.22252479,\n",
       "          0.5959271 , -1.2674702 ,  0.5941687 , -0.92638266, -0.3256209 ],\n",
       "        [ 0.8304324 ,  1.4462708 , -0.26950693, -1.0744411 , -0.71184254,\n",
       "          1.110068  , -0.35528132,  1.1418787 , -1.2677557 , -1.0520877 ],\n",
       "        [ 0.46059898,  0.82961637, -1.1993229 ,  0.15102465, -0.71156496,\n",
       "          0.4186685 , -0.7751445 ,  0.3553583 , -0.41250584, -0.89158267],\n",
       "        [ 0.9703865 ,  1.5160241 , -1.1547922 ,  0.65388805, -1.0937434 ,\n",
       "         -0.06142469, -0.76473165,  1.1448317 ,  0.14046064, -1.3352056 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.8339625 ,  0.92443925, -0.83089095, -0.38021812, -0.8431865 ,\n",
       "         0.6260611 , -0.94637203,  0.8448871 , -0.6661375 , -0.89903826],\n",
       "       dtype=float32),\n",
       " array([[ 4.6521899e-01],\n",
       "        [ 7.3247832e-01],\n",
       "        [-1.2347387e+00],\n",
       "        [-6.4937194e-04],\n",
       "        [-1.0533243e+00],\n",
       "        [-2.5036834e-02],\n",
       "        [-5.0458318e-01],\n",
       "        [ 6.1254275e-01],\n",
       "        [-1.3156117e-02],\n",
       "        [-6.6344273e-01]], dtype=float32),\n",
       " array([0.7456394], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_tanh(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_tanh.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
